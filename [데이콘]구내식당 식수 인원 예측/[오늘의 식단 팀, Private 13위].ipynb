{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from konlpy.tag import Mecab\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "rc('font', family='AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "%matplotlib inline\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRFRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from ngboost import NGBRegressor\n",
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 띄어쓰기 및 오타 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.at[1142, '중식메뉴'] = '쌀밥/곤드레밥/찰현미밥 된장찌개 돼지고추장불고기 버섯잡채 삼색물만두무침 겉절이김치/양념장 견과류샐러드*요거트D'\n",
    "\n",
    "train['중식메뉴'] = train['중식메뉴'].str.replace('삽겹', '삼겹')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['일자'] = pd.to_datetime(train['일자'])\n",
    "test['일자'] = pd.to_datetime(test['일자'])\n",
    "\n",
    "train['요일'] = train['일자'].dt.day_name().str[:2].map({'Mo' : 5, 'Tu' : 4, 'We' : 3, 'Th' : 2, 'Fr' : 1})\n",
    "test['요일'] = test['일자'].dt.day_name().str[:2].map({'Mo' : 5, 'Tu' : 4, 'We' : 3, 'Th' : 2, 'Fr' : 1})\n",
    "\n",
    "train['month'] = train['일자'].dt.month\n",
    "test['month'] = test['일자'].dt.month\n",
    "\n",
    "train['corona'] = [1 if x > 0 else 0 for x in train['현본사소속재택근무자수']]\n",
    "test['corona'] = [1 if x > 0 else 0 for x in test['현본사소속재택근무자수']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다음 출근날까지의 일수 차이\n",
    "- ex) 오늘이 12월 31일 목요일인 경우 다음 출근날은 1월 4일이기 때문에 값이 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['shift_1day'] = train.일자.shift(-1)\n",
    "test['shift_1day'] = test.일자.shift(-1)\n",
    "\n",
    "train.at[1204, 'shift_1day'] = datetime(2021,1,27)\n",
    "test.at[49, 'shift_1day'] = datetime(2021,4,12)\n",
    "\n",
    "train['day_gap'] = (train.shift_1day - train.일자).astype(str)\n",
    "test['day_gap'] = (test.shift_1day - test.일자).astype(str)\n",
    "\n",
    "train.at[0, 'day_gap'] = '1 days'\n",
    "test.at[0, 'day_gap'] = '1 days'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holiday_score(x) :\n",
    "    \n",
    "    s = int(re.sub(r'[^0-9]', '', x))\n",
    "    if s == 1 :\n",
    "        return 0\n",
    "    else :\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day_gap'] = train.day_gap.apply(get_holiday_score)\n",
    "test['day_gap'] = test.day_gap.apply(get_holiday_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['야근요일'] = train.요일.apply(lambda x : 1 if (x == 1) or (x == 3) else 0)\n",
    "test['야근요일'] = test.요일.apply(lambda x : 1 if (x == 1) or (x == 3) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['중식메뉴'] = train['중식메뉴'].str.split(' ')\n",
    "train['석식메뉴'] = train['석식메뉴'].str.split(' ')\n",
    "\n",
    "test['중식메뉴'] = test['중식메뉴'].str.split(' ')\n",
    "test['석식메뉴'] = test['석식메뉴'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(data) :\n",
    "    tokens = []\n",
    "    for token in data :\n",
    "        s_list = []\n",
    "        for t in token :\n",
    "            if t.startswith('(N') :\n",
    "                s_list.append(t)\n",
    "            elif (t.startswith('(') == False) & (len(t) > 1) :\n",
    "                s_list.append(t)\n",
    "            else :\n",
    "                pass\n",
    "        tokens.append(s_list)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['중식_토큰'] = get_token(train['중식메뉴'])\n",
    "train['석식_토큰'] = get_token(train['석식메뉴'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['중식_토큰'] = get_token(test['중식메뉴'])\n",
    "test['석식_토큰'] = get_token(test['석식메뉴'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['중식메뉴수'] = train.중식_토큰.apply(len)\n",
    "train['석식메뉴수'] = train.석식_토큰.apply(len)\n",
    "\n",
    "test['중식메뉴수'] = test.중식_토큰.apply(len)\n",
    "test['석식메뉴수'] = test.석식_토큰.apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 식재료\n",
    "- 중식에만 처리함 -> 메뉴가 중식에서 더 중요할 것으로 판단했기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredient(data) :\n",
    "    \n",
    "    ing_df = pd.DataFrame(np.zeros((data.shape[0], 7)), columns = ['해산물', '소', '돼지', '닭', '오리', '채소', '재료_기타'])\n",
    "\n",
    "    for t in range(data.shape[0]) :\n",
    "        token = data.중식_토큰.str[2][t]\n",
    "        if '연어' in token or'골뱅이' in token or'열기' in token or'조기' in token or'탕수어' in token or'양장피' in token or'홍어' in token or'명태' in token or'적어' in token or'장어' in token or'동태' in token or'산슬' in token or'코다리' in token or'가자미' in token or'해물' in token or'생선' in token or'새우' in token or'꽁치' in token or'갈치' in token or'임연수' in token or'삼치' in token or'고등어' in token or'굴비' in token or'오징어' in token or'쭈꾸미' in token or'주꾸미' in token or'낙지' in token or'문어' in token :\n",
    "            ing_df.at[t, '해산물'] = 1\n",
    "        elif '왕갈비' in token or'소갈비' in token or'장조림' in token or'불고기' in token or'차돌' in token or'육전' in token or'너비아니' in token or'떡갈비' in token or(token.startswith('소') & (token.startswith('소세') == False)) or '함박' in token or'쇠고기' in token or'소고기' in token or'쇠' in token :\n",
    "            ing_df.at[t, '소'] = 1\n",
    "        elif '궁보계정' in token or'삼계탕' in token or'윙' in token or'유린기' in token or'깐풍'in token or'닭' in token or'치킨' in token or'후라이드' in token :\n",
    "            ing_df.at[t, '돼지'] = 1\n",
    "        elif '폭립' in token or'오향장육' in token or'동파육' in token or'히레카츠' in token or'순대' in token or'미트볼' in token or'등갈비' in token or'소세지' in token or'목살' in token or'탕수육' in token or'제육' in token or'돈' in token or'돼지' in token or'두루치기' in token or'삼겹' in token or'보쌈' in token or'족발' in token :\n",
    "            ing_df.at[t, '닭'] = 1\n",
    "        elif '오리' in token :\n",
    "            ing_df.at[t, '오리'] = 1\n",
    "        elif token.endswith('두부') or '꼬치산적' in token or '고추' in token or'양파' in token or'부추' in token or'고구마' in token or'감자' in token or'깻잎' in token or'샐러드' in token or'시금치' in token or'야채' in token :\n",
    "            ing_df.at[t, '채소'] = 1\n",
    "        else :\n",
    "            ing_df.at[t, '재료_기타'] = 1\n",
    "            \n",
    "    return ing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, get_ingredient(train)], axis = 1)\n",
    "test = pd.concat([test, get_ingredient(test)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조리법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe(data, col) :\n",
    "    tm = col[:2]\n",
    "    cat = ['전', '무침','튀김', '찜', '볶음', '조림', '구이', '훈제', '조리_기타']\n",
    "    recipe_df = pd.DataFrame(np.zeros((data.shape[0], 9)), columns = [f'{tm}_{x}' for x in cat])\n",
    "\n",
    "    for t in range(data.shape[0]) :\n",
    "        try :\n",
    "            token = data[col][t]\n",
    "            if '고추잡채' in token or '궁보계정' in token or '산슬' in token or token.endswith('잡채') or '마파두부' in token or '두루치기' in token or '닭갈비' in token or token.endswith('볶음') or '볶음' in token :\n",
    "                recipe_df.at[t, f'{tm}_볶음'] = 1 \n",
    "            elif token.endswith('데리야끼') or token.endswith('립') or '함박' in token or '그라탕' in token or token.endswith('갈비') or '주물럭' in token or '스테이크' in token or token.endswith('구이') or '불고기' in token or '구이' in token :\n",
    "                recipe_df.at[t, f'{tm}_구이'] = 1\n",
    "            elif '전병' in token or token.endswith('전') :\n",
    "                recipe_df.at[t, f'{tm}_전'] = 1\n",
    "            elif token.endswith('김치말이') or token.endswith('만두') or '보쌈' in token or '수육' in token or token.endswith('찜') or '찜' in token :\n",
    "                recipe_df.at[t, f'{tm}_찜'] = 1\n",
    "            elif '파채' in token or token.endswith('무침') or token.endswith('샐러드') or '양장피' in token :\n",
    "                recipe_df.at[t, f'{tm}_무침'] = 1\n",
    "            elif '오향장육' in token or '동파육' in token or token.endswith('조림') :\n",
    "                recipe_df.at[t, f'{tm}_조림'] = 1\n",
    "            elif '통닭' in token or token.endswith('새우') or '강정' in token or '미트볼' in token or '프리타타' in token or '카츠' in token or '깐풍' in token or '고로케' in token or '유린기' in token or '탕수' in token or token.endswith('닭') or token.endswith('치킨') or token.endswith('튀김') or '너겟' in token or token.endswith('강정') or '가스' in token or '까스' in token or '핑거' in token or '텐더' in token or '커틀렛' in token or '커틀릿' in token :\n",
    "                recipe_df.at[t, f'{tm}_튀김'] = 1\n",
    "            elif '훈제' in token :\n",
    "                recipe_df.at[t, f'{tm}_훈제'] = 1\n",
    "            else :\n",
    "                recipe_df.at[t, f'{tm}_조리_기타'] = 1\n",
    "        except :\n",
    "            recipe_df.at[t, f'{tm}_조리_기타'] = 1\n",
    "    return recipe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['중식_메인요리'] = train.중식_토큰.str[2]\n",
    "test['중식_메인요리'] = test.중식_토큰.str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['석식_메인요리'] = train.석식_토큰.str[2]\n",
    "test['석식_메인요리'] = test.석식_토큰.str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.concat([train, get_recipe(train, '중식_메인요리')], axis = 1)\n",
    "test = pd.concat([test, get_recipe(test, '중식_메인요리')], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, get_recipe(train, '석식_메인요리')], axis = 1)\n",
    "test = pd.concat([test, get_recipe(test, '석식_메인요리')], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['출근'] = train['본사정원수']-(train['본사휴가자수']+train['본사출장자수']+train['현본사소속재택근무자수'])\n",
    "train['휴가비율'] = train['본사휴가자수']/train['본사정원수']\n",
    "train['출장비율'] = train['본사출장자수']/train['본사정원수']\n",
    "train['야근비율'] = train['본사시간외근무명령서승인건수']/train['출근']\n",
    "train['재택비율'] = train['현본사소속재택근무자수']/train['본사정원수']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['출근'] = test['본사정원수']-(test['본사휴가자수']+test['본사출장자수']+test['현본사소속재택근무자수'])\n",
    "test['휴가비율'] = test['본사휴가자수']/test['본사정원수']\n",
    "test['출장비율'] = test['본사출장자수']/test['본사정원수']\n",
    "test['야근비율'] = test['본사시간외근무명령서승인건수']/test['출근']\n",
    "test['재택비율'] = test['현본사소속재택근무자수']/test['본사정원수']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = train[['요일', '야근요일', '출근', 'day_gap', '휴가비율', '출장비율', '야근비율', 'month',  '중식메뉴수', '해산물', '소', '돼지', '닭', '오리', '채소', '재료_기타', '중식_전', '중식_무침', '중식_튀김', '중식_찜', \n",
    "       '중식_볶음', '중식_조림', '중식_구이', '중식_훈제', '중식_조리_기타']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = test[X1.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = train[['corona', '석식메뉴수', 'month', '야근요일', 'day_gap', '요일', '출근', '휴가비율', '출장비율', '야근비율', '재택비율', '석식_전', '석식_무침', \n",
    "       '석식_튀김', '석식_찜', '석식_볶음', '석식_조림', '석식_구이', '석식_훈제', '석식_조리_기타']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "target2 = test[X2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = train.중식계\n",
    "y2 = train.석식계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 15, random_state = 718, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CatBoostRegressor(iterations = 20000, learning_rate = 0.01, depth = 4, eval_metric = 'MAE', silent = True, loss_function = 'MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 165.7208086\ttest: 174.4951842\tbest: 174.4951842 (0)\ttotal: 62.1ms\tremaining: 20m 41s\n",
      "5000:\tlearn: 44.7818178\ttest: 61.9085747\tbest: 61.8818070 (4932)\ttotal: 5.61s\tremaining: 16.8s\n",
      "10000:\tlearn: 38.2252302\ttest: 61.4473138\tbest: 61.4084062 (9821)\ttotal: 10.3s\tremaining: 10.3s\n",
      "15000:\tlearn: 35.0579376\ttest: 61.4200779\tbest: 61.3247083 (13580)\ttotal: 14.9s\tremaining: 4.97s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 61.32470828\n",
      "bestIteration = 13580\n",
      "\n",
      "Shrink model to first 13581 iterations.\n",
      "FOLD MAE = 61.325879285875395\n",
      "0:\tlearn: 166.7712980\ttest: 162.5986410\tbest: 162.5986410 (0)\ttotal: 2.48ms\tremaining: 49.5s\n",
      "5000:\tlearn: 44.3015596\ttest: 73.9240744\tbest: 73.9210822 (4978)\ttotal: 4.68s\tremaining: 14s\n",
      "10000:\tlearn: 38.2208748\ttest: 73.6280890\tbest: 73.6024269 (8660)\ttotal: 9.4s\tremaining: 9.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 73.43427955\n",
      "bestIteration = 11274\n",
      "\n",
      "Shrink model to first 11275 iterations.\n",
      "FOLD MAE = 73.44116029175416\n",
      "0:\tlearn: 167.5675435\ttest: 150.2908632\tbest: 150.2908632 (0)\ttotal: 2.17ms\tremaining: 43.3s\n",
      "5000:\tlearn: 44.7227380\ttest: 74.5972176\tbest: 74.5828811 (4996)\ttotal: 5.62s\tremaining: 16.9s\n",
      "10000:\tlearn: 38.0116395\ttest: 73.6144847\tbest: 73.6086317 (9954)\ttotal: 10.6s\tremaining: 10.6s\n",
      "15000:\tlearn: 34.5494907\ttest: 73.3208481\tbest: 73.2497922 (14399)\ttotal: 16.3s\tremaining: 5.43s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 73.24979216\n",
      "bestIteration = 14399\n",
      "\n",
      "Shrink model to first 14400 iterations.\n",
      "FOLD MAE = 73.25400931096382\n",
      "0:\tlearn: 165.4556930\ttest: 178.2422212\tbest: 178.2422212 (0)\ttotal: 957us\tremaining: 19.1s\n",
      "5000:\tlearn: 44.7400031\ttest: 71.4169900\tbest: 71.4092342 (4951)\ttotal: 5.75s\tremaining: 17.3s\n",
      "10000:\tlearn: 38.1293262\ttest: 70.1272320\tbest: 70.1219623 (9929)\ttotal: 11.7s\tremaining: 11.7s\n",
      "15000:\tlearn: 34.5660624\ttest: 69.5591275\tbest: 69.5565705 (14521)\ttotal: 18.1s\tremaining: 6.04s\n",
      "19999:\tlearn: 32.1973893\ttest: 69.6201863\tbest: 69.4484143 (18275)\ttotal: 23.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 69.44841431\n",
      "bestIteration = 18275\n",
      "\n",
      "Shrink model to first 18276 iterations.\n",
      "FOLD MAE = 69.44873717484013\n",
      "0:\tlearn: 165.4903905\ttest: 178.1975299\tbest: 178.1975299 (0)\ttotal: 1.59ms\tremaining: 31.8s\n",
      "5000:\tlearn: 44.4355148\ttest: 59.3221024\tbest: 59.0446133 (3194)\ttotal: 4.6s\tremaining: 13.8s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 59.04461333\n",
      "bestIteration = 3194\n",
      "\n",
      "Shrink model to first 3195 iterations.\n",
      "FOLD MAE = 59.045004324345776\n",
      "0:\tlearn: 166.4326657\ttest: 164.6699990\tbest: 164.6699990 (0)\ttotal: 1.56ms\tremaining: 31.1s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 72.19559564\n",
      "bestIteration = 1575\n",
      "\n",
      "Shrink model to first 1576 iterations.\n",
      "FOLD MAE = 72.21113646820054\n",
      "0:\tlearn: 166.8690746\ttest: 158.4353740\tbest: 158.4353740 (0)\ttotal: 1.93ms\tremaining: 38.5s\n",
      "5000:\tlearn: 44.4424223\ttest: 66.9859394\tbest: 66.9494436 (4966)\ttotal: 5.49s\tremaining: 16.5s\n",
      "10000:\tlearn: 37.7448596\ttest: 65.7108187\tbest: 65.7108187 (10000)\ttotal: 11.5s\tremaining: 11.5s\n",
      "15000:\tlearn: 34.0591147\ttest: 65.0380276\tbest: 65.0321017 (14712)\ttotal: 16.3s\tremaining: 5.45s\n",
      "19999:\tlearn: 31.6859908\ttest: 64.7527562\tbest: 64.7433350 (19963)\ttotal: 21.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 64.74333505\n",
      "bestIteration = 19963\n",
      "\n",
      "Shrink model to first 19964 iterations.\n",
      "FOLD MAE = 64.74352050328369\n",
      "0:\tlearn: 165.7627457\ttest: 174.1919990\tbest: 174.1919990 (0)\ttotal: 1.87ms\tremaining: 37.5s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 68.96826999\n",
      "bestIteration = 2329\n",
      "\n",
      "Shrink model to first 2330 iterations.\n",
      "FOLD MAE = 68.97047851319005\n",
      "0:\tlearn: 167.1451368\ttest: 154.5411240\tbest: 154.5411240 (0)\ttotal: 1.78ms\tremaining: 35.5s\n",
      "5000:\tlearn: 44.0941941\ttest: 68.9662231\tbest: 68.9314967 (4974)\ttotal: 6.76s\tremaining: 20.3s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 68.82871343\n",
      "bestIteration = 5785\n",
      "\n",
      "Shrink model to first 5786 iterations.\n",
      "FOLD MAE = 68.83381798863209\n",
      "0:\tlearn: 166.3453679\ttest: 165.9062490\tbest: 165.9062490 (0)\ttotal: 1.19ms\tremaining: 23.9s\n",
      "5000:\tlearn: 44.3907223\ttest: 76.0130723\tbest: 75.9884322 (4367)\ttotal: 5.31s\tremaining: 15.9s\n",
      "10000:\tlearn: 38.2212343\ttest: 75.1329271\tbest: 75.0740639 (9785)\ttotal: 10s\tremaining: 10s\n",
      "15000:\tlearn: 34.9527403\ttest: 74.5769527\tbest: 74.5721508 (14991)\ttotal: 14.7s\tremaining: 4.89s\n",
      "19999:\tlearn: 32.6966922\ttest: 74.4480753\tbest: 74.4277465 (18351)\ttotal: 19.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 74.42774649\n",
      "bestIteration = 18351\n",
      "\n",
      "Shrink model to first 18352 iterations.\n",
      "FOLD MAE = 74.42816472233842\n",
      "0:\tlearn: 166.6481590\ttest: 161.8689990\tbest: 161.8689990 (0)\ttotal: 1.99ms\tremaining: 39.8s\n",
      "5000:\tlearn: 44.1370568\ttest: 74.1716524\tbest: 74.1523410 (4978)\ttotal: 5.96s\tremaining: 17.9s\n",
      "10000:\tlearn: 37.7920561\ttest: 73.8773987\tbest: 73.8671126 (9963)\ttotal: 11.4s\tremaining: 11.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 73.86711265\n",
      "bestIteration = 9963\n",
      "\n",
      "Shrink model to first 9964 iterations.\n",
      "FOLD MAE = 73.86860684644739\n",
      "0:\tlearn: 165.8163546\ttest: 174.8531240\tbest: 174.8531240 (0)\ttotal: 816us\tremaining: 16.3s\n",
      "5000:\tlearn: 44.6813751\ttest: 61.0737143\tbest: 61.0276365 (4522)\ttotal: 5.36s\tremaining: 16.1s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 60.80820691\n",
      "bestIteration = 7357\n",
      "\n",
      "Shrink model to first 7358 iterations.\n",
      "FOLD MAE = 60.810023060525324\n",
      "0:\tlearn: 166.0689235\ttest: 169.8798740\tbest: 169.8798740 (0)\ttotal: 1.61ms\tremaining: 32.2s\n",
      "5000:\tlearn: 44.1200435\ttest: 68.6075689\tbest: 68.5697896 (4787)\ttotal: 4.96s\tremaining: 14.9s\n",
      "10000:\tlearn: 37.4172579\ttest: 67.1965703\tbest: 67.1397400 (9741)\ttotal: 9.95s\tremaining: 9.95s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 67.13787822\n",
      "bestIteration = 11021\n",
      "\n",
      "Shrink model to first 11022 iterations.\n",
      "FOLD MAE = 67.1380187740863\n",
      "0:\tlearn: 166.4346835\ttest: 164.7612490\tbest: 164.7612490 (0)\ttotal: 675us\tremaining: 13.5s\n",
      "5000:\tlearn: 44.2959676\ttest: 74.5449945\tbest: 74.4885937 (4908)\ttotal: 5.67s\tremaining: 17s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 73.91428639\n",
      "bestIteration = 7371\n",
      "\n",
      "Shrink model to first 7372 iterations.\n",
      "FOLD MAE = 73.9143054118516\n",
      "0:\tlearn: 166.3479279\ttest: 166.7234990\tbest: 166.7234990 (0)\ttotal: 972us\tremaining: 19.5s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 60.65441998\n",
      "bestIteration = 1328\n",
      "\n",
      "Shrink model to first 1329 iterations.\n",
      "FOLD MAE = 60.66796634689831\n",
      "\n",
      "CatBoostRegressor MAE = 68.14005526821553\n"
     ]
    }
   ],
   "source": [
    "cb_pred_1 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X1):\n",
    "    tr_x, val_x = X1.iloc[tr_idx], X1.iloc[val_idx]\n",
    "    tr_y, val_y = y1.iloc[tr_idx], y1.iloc[val_idx]\n",
    "    train_data = Pool(data = tr_x, label = tr_y)\n",
    "    val_data = Pool(data = val_x, label = val_y)\n",
    "    cb.fit(train_data, eval_set = val_data, early_stopping_rounds = 2000, use_best_model = True, verbose = 5000)\n",
    "    best = cb.best_iteration_\n",
    "    pred = cb.predict(val_x, ntree_end = best)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = cb.predict(target1, ntree_end = best) / 15\n",
    "    cb_pred_1 += sub_pred\n",
    "print(f'\\n{cb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 99.0269474\ttest: 82.1235793\tbest: 82.1235793 (0)\ttotal: 1.93ms\tremaining: 38.7s\n",
      "5000:\tlearn: 29.9611929\ttest: 41.2941278\tbest: 41.2782356 (4618)\ttotal: 5.36s\tremaining: 16.1s\n",
      "10000:\tlearn: 26.0294826\ttest: 40.8838317\tbest: 40.8610027 (9930)\ttotal: 10.4s\tremaining: 10.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 40.73218658\n",
      "bestIteration = 12930\n",
      "\n",
      "Shrink model to first 12931 iterations.\n",
      "FOLD MAE = 40.734237100833674\n",
      "0:\tlearn: 99.1316182\ttest: 80.7050607\tbest: 80.7050607 (0)\ttotal: 1.82ms\tremaining: 36.4s\n",
      "5000:\tlearn: 29.2048574\ttest: 55.9635529\tbest: 55.9380499 (4861)\ttotal: 5.78s\tremaining: 17.3s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 55.69152869\n",
      "bestIteration = 6972\n",
      "\n",
      "Shrink model to first 6973 iterations.\n",
      "FOLD MAE = 55.693782736123964\n",
      "0:\tlearn: 97.9807641\ttest: 95.7135793\tbest: 95.7135793 (0)\ttotal: 1.73ms\tremaining: 34.6s\n",
      "5000:\tlearn: 29.9661490\ttest: 43.8533080\tbest: 43.8183328 (4000)\ttotal: 5.77s\tremaining: 17.3s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 43.81833281\n",
      "bestIteration = 4000\n",
      "\n",
      "Shrink model to first 4001 iterations.\n",
      "FOLD MAE = 43.81847416008471\n",
      "0:\tlearn: 97.2503193\ttest: 106.4114805\tbest: 106.4114805 (0)\ttotal: 1.32ms\tremaining: 26.4s\n",
      "5000:\tlearn: 29.2829716\ttest: 48.6531338\tbest: 48.6420856 (4852)\ttotal: 5.8s\tremaining: 17.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 48.55078182\n",
      "bestIteration = 5449\n",
      "\n",
      "Shrink model to first 5450 iterations.\n",
      "FOLD MAE = 48.56105595273324\n",
      "0:\tlearn: 97.9254616\ttest: 96.9072830\tbest: 96.9072830 (0)\ttotal: 1.6ms\tremaining: 32.1s\n",
      "5000:\tlearn: 29.7755595\ttest: 40.9053730\tbest: 40.9045719 (4994)\ttotal: 4.97s\tremaining: 14.9s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 40.68681248\n",
      "bestIteration = 6055\n",
      "\n",
      "Shrink model to first 6056 iterations.\n",
      "FOLD MAE = 40.687034835644056\n",
      "0:\tlearn: 96.6489501\ttest: 114.9941240\tbest: 114.9941240 (0)\ttotal: 1.39ms\tremaining: 27.8s\n",
      "5000:\tlearn: 29.9149936\ttest: 39.6928561\tbest: 39.6145600 (4764)\ttotal: 5.63s\tremaining: 16.9s\n",
      "10000:\tlearn: 25.6742804\ttest: 39.1496064\tbest: 39.1394826 (9883)\ttotal: 11.2s\tremaining: 11.2s\n",
      "15000:\tlearn: 23.3712987\ttest: 38.8058028\tbest: 38.7861137 (14971)\ttotal: 16.5s\tremaining: 5.5s\n",
      "19999:\tlearn: 21.8720421\ttest: 38.5076178\tbest: 38.4681175 (18159)\ttotal: 22.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 38.46811754\n",
      "bestIteration = 18159\n",
      "\n",
      "Shrink model to first 18160 iterations.\n",
      "FOLD MAE = 38.46812755239758\n",
      "0:\tlearn: 99.0211279\ttest: 81.7268740\tbest: 81.7268740 (0)\ttotal: 1.1ms\tremaining: 22s\n",
      "5000:\tlearn: 29.9462905\ttest: 41.3362296\tbest: 41.2455382 (4866)\ttotal: 5.24s\tremaining: 15.7s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 41.24553824\n",
      "bestIteration = 4866\n",
      "\n",
      "Shrink model to first 4867 iterations.\n",
      "FOLD MAE = 41.247552445864\n",
      "0:\tlearn: 97.6858212\ttest: 100.2473740\tbest: 100.2473740 (0)\ttotal: 725us\tremaining: 14.5s\n",
      "5000:\tlearn: 30.2407692\ttest: 37.9117371\tbest: 37.9077198 (4449)\ttotal: 5.31s\tremaining: 15.9s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 37.89926049\n",
      "bestIteration = 5035\n",
      "\n",
      "Shrink model to first 5036 iterations.\n",
      "FOLD MAE = 37.89958993783053\n",
      "0:\tlearn: 97.5656523\ttest: 101.6778740\tbest: 101.6778740 (0)\ttotal: 1.31ms\tremaining: 26.3s\n",
      "5000:\tlearn: 29.9099428\ttest: 35.3600070\tbest: 35.2981817 (4787)\ttotal: 5.84s\tremaining: 17.5s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 35.10249116\n",
      "bestIteration = 7675\n",
      "\n",
      "Shrink model to first 7676 iterations.\n",
      "FOLD MAE = 35.10337829912802\n",
      "0:\tlearn: 98.1231546\ttest: 94.2526240\tbest: 94.2526240 (0)\ttotal: 1.27ms\tremaining: 25.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 55.46845858\n",
      "bestIteration = 2962\n",
      "\n",
      "Shrink model to first 2963 iterations.\n",
      "FOLD MAE = 55.47460470572097\n",
      "0:\tlearn: 97.4935190\ttest: 102.8896240\tbest: 102.8896240 (0)\ttotal: 724us\tremaining: 14.5s\n",
      "5000:\tlearn: 29.2080824\ttest: 49.0159199\tbest: 49.0084972 (4985)\ttotal: 4.87s\tremaining: 14.6s\n",
      "10000:\tlearn: 24.9802525\ttest: 48.7781431\tbest: 48.7603686 (9770)\ttotal: 10.4s\tremaining: 10.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 48.73037993\n",
      "bestIteration = 11601\n",
      "\n",
      "Shrink model to first 11602 iterations.\n",
      "FOLD MAE = 48.732675629088526\n",
      "0:\tlearn: 96.6946390\ttest: 114.0312490\tbest: 114.0312490 (0)\ttotal: 1.31ms\tremaining: 26.1s\n",
      "5000:\tlearn: 29.6182705\ttest: 45.7707474\tbest: 45.6233286 (3904)\ttotal: 5.46s\tremaining: 16.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 45.60251848\n",
      "bestIteration = 5895\n",
      "\n",
      "Shrink model to first 5896 iterations.\n",
      "FOLD MAE = 45.60825198850498\n",
      "0:\tlearn: 97.3590301\ttest: 104.4489990\tbest: 104.4489990 (0)\ttotal: 1.32ms\tremaining: 26.3s\n",
      "5000:\tlearn: 29.7349610\ttest: 49.7517662\tbest: 49.7288071 (4984)\ttotal: 5.61s\tremaining: 16.8s\n",
      "10000:\tlearn: 25.5366497\ttest: 48.9319226\tbest: 48.9256055 (9952)\ttotal: 11.2s\tremaining: 11.2s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 48.85807527\n",
      "bestIteration = 10601\n",
      "\n",
      "Shrink model to first 10602 iterations.\n",
      "FOLD MAE = 48.85849588401657\n",
      "0:\tlearn: 98.7323901\ttest: 85.3723740\tbest: 85.3723740 (0)\ttotal: 1.42ms\tremaining: 28.4s\n",
      "Stopped by overfitting detector  (2000 iterations wait)\n",
      "\n",
      "bestTest = 49.23395509\n",
      "bestIteration = 2639\n",
      "\n",
      "Shrink model to first 2640 iterations.\n",
      "FOLD MAE = 49.23448896455727\n",
      "0:\tlearn: 97.1001768\ttest: 108.3168740\tbest: 108.3168740 (0)\ttotal: 1.92ms\tremaining: 38.4s\n",
      "5000:\tlearn: 30.1639453\ttest: 43.4518490\tbest: 43.4398276 (4981)\ttotal: 5.65s\tremaining: 16.9s\n",
      "10000:\tlearn: 26.0803665\ttest: 42.4882093\tbest: 42.4797307 (9950)\ttotal: 10.8s\tremaining: 10.8s\n",
      "15000:\tlearn: 23.8664801\ttest: 41.6126666\tbest: 41.5879812 (14602)\ttotal: 16.5s\tremaining: 5.51s\n",
      "19999:\tlearn: 22.2281418\ttest: 41.4114452\tbest: 41.3722459 (18905)\ttotal: 21.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 41.37224586\n",
      "bestIteration = 18905\n",
      "\n",
      "Shrink model to first 18906 iterations.\n",
      "FOLD MAE = 41.37231341706795\n",
      "\n",
      "CatBoostRegressor MAE = 44.7662709073064\n"
     ]
    }
   ],
   "source": [
    "cb_pred_2 = np.zeros((target2.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X2):\n",
    "    tr_x, val_x = X2.iloc[tr_idx], X2.iloc[val_idx]\n",
    "    tr_y, val_y = y2.iloc[tr_idx], y2.iloc[val_idx]\n",
    "    train_data = Pool(data = tr_x, label = tr_y)\n",
    "    val_data = Pool(data = val_x, label = val_y)\n",
    "    cb.fit(train_data, eval_set = val_data, early_stopping_rounds = 2000, use_best_model = True, verbose = 5000)\n",
    "    best = cb.best_iteration_\n",
    "    pred = cb.predict(val_x, ntree_end = best)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = cb.predict(target2, ntree_end = best) / 15\n",
    "    cb_pred_2 += sub_pred\n",
    "print(f'\\n{cb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb = NGBRegressor(n_estimators = 15000, verbose = 0, random_state = 607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD MAE = 68.93021314897271\n",
      "FOLD MAE = 53.653937044849705\n",
      "FOLD MAE = 46.80557565007274\n",
      "FOLD MAE = 34.015911415767384\n",
      "FOLD MAE = 37.20199168499946\n",
      "FOLD MAE = 43.273489971316806\n",
      "FOLD MAE = 36.701970631269454\n",
      "FOLD MAE = 34.67354770644964\n",
      "FOLD MAE = 40.711893648589694\n",
      "FOLD MAE = 33.73674663410894\n",
      "FOLD MAE = 38.51425002765768\n",
      "FOLD MAE = 27.956151443367055\n",
      "FOLD MAE = 26.57288686138337\n",
      "FOLD MAE = 29.503053690826004\n",
      "FOLD MAE = 27.322885552213812\n",
      "\n",
      "NGBRegressor MAE = 38.63830034078964\n"
     ]
    }
   ],
   "source": [
    "ngb_pred_1 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X1):\n",
    "    tr_x, val_x = X1.iloc[tr_idx], X1.iloc[val_idx]\n",
    "    tr_y, val_y = y1.iloc[tr_idx], y1.iloc[val_idx]\n",
    "    ngb.fit(tr_x, tr_y, val_x, val_y, early_stopping_rounds = 2000)\n",
    "    pred = ngb.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = ngb.predict(target1) / 15\n",
    "    ngb_pred_1 += sub_pred\n",
    "print(f'\\n{ngb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngb = NGBRegressor(n_estimators = 15000, verbose = 0, random_state = 607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD MAE = 44.171664919086936\n",
      "FOLD MAE = 32.868913088772295\n",
      "FOLD MAE = 25.220459787217816\n",
      "FOLD MAE = 21.960386570669062\n",
      "FOLD MAE = 20.040524201800302\n",
      "FOLD MAE = 18.935727713350282\n",
      "FOLD MAE = 18.9116412699365\n",
      "FOLD MAE = 16.29463434135136\n",
      "FOLD MAE = 16.74260426529482\n",
      "FOLD MAE = 20.35581551304555\n",
      "FOLD MAE = 18.07844819538711\n",
      "FOLD MAE = 17.947413300843102\n",
      "FOLD MAE = 17.985124950816843\n",
      "FOLD MAE = 16.079115696458693\n",
      "FOLD MAE = 14.079807129401638\n",
      "\n",
      "NGBRegressor MAE = 21.31148539622882\n"
     ]
    }
   ],
   "source": [
    "ngb_pred_2 = np.zeros((target2.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X2):\n",
    "    tr_x, val_x = X2.iloc[tr_idx], X2.iloc[val_idx]\n",
    "    tr_y, val_y = y2.iloc[tr_idx], y2.iloc[val_idx]\n",
    "    ngb.fit(tr_x,\n",
    "            tr_y, val_x, val_y, early_stopping_rounds = 2000)\n",
    "    pred = ngb.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = ngb.predict(target2) / 15\n",
    "    ngb_pred_2 += sub_pred\n",
    "print(f'\\n{ngb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMRegressor(random_state = 718, max_depth = 5, n_estimators = 20000, learning_rate = .02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[345]\ttraining's l1: 51.583\ttraining's l2: 4678.24\tvalid_1's l1: 68.7999\tvalid_1's l2: 8329.61\n",
      "FOLD MAE = 68.79993446563824\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's l1: 64.893\ttraining's l2: 7288.94\tvalid_1's l1: 73.6322\tvalid_1's l2: 10883.6\n",
      "FOLD MAE = 73.63224306104472\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[565]\ttraining's l1: 46.4971\ttraining's l2: 3842.53\tvalid_1's l1: 72.9292\tvalid_1's l2: 8635.33\n",
      "FOLD MAE = 72.92923548471887\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2014]\ttraining's l1: 30.9305\ttraining's l2: 1698.42\tvalid_1's l1: 64.6994\tvalid_1's l2: 8491.1\n",
      "FOLD MAE = 64.69940192011973\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[521]\ttraining's l1: 47.5238\ttraining's l2: 4014.36\tvalid_1's l1: 68.5236\tvalid_1's l2: 7332.44\n",
      "FOLD MAE = 68.52359588970029\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttraining's l1: 58.6761\ttraining's l2: 5974.16\tvalid_1's l1: 79.8255\tvalid_1's l2: 11674.4\n",
      "FOLD MAE = 79.82554148205263\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[967]\ttraining's l1: 39.7423\ttraining's l2: 2826.4\tvalid_1's l1: 65.7258\tvalid_1's l2: 6962.5\n",
      "FOLD MAE = 65.72582316307815\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[342]\ttraining's l1: 52.4933\ttraining's l2: 4897.05\tvalid_1's l1: 77.173\tvalid_1's l2: 9140.12\n",
      "FOLD MAE = 77.17301997694408\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttraining's l1: 61.2894\ttraining's l2: 6486.59\tvalid_1's l1: 69.7444\tvalid_1's l2: 8627.7\n",
      "FOLD MAE = 69.74440044017858\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1080]\ttraining's l1: 37.6153\ttraining's l2: 2498.45\tvalid_1's l1: 81.0433\tvalid_1's l2: 11140\n",
      "FOLD MAE = 81.04333603138257\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[581]\ttraining's l1: 45.751\ttraining's l2: 3686.17\tvalid_1's l1: 74.1224\tvalid_1's l2: 9800.29\n",
      "FOLD MAE = 74.12238684381184\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2829]\ttraining's l1: 24.9422\ttraining's l2: 1105.2\tvalid_1's l1: 68.4952\tvalid_1's l2: 7479.08\n",
      "FOLD MAE = 68.49515604771106\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[851]\ttraining's l1: 41.8789\ttraining's l2: 3099.2\tvalid_1's l1: 71.8964\tvalid_1's l2: 10647.2\n",
      "FOLD MAE = 71.89640587972679\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1189]\ttraining's l1: 36.0067\ttraining's l2: 2276.66\tvalid_1's l1: 76.0713\tvalid_1's l2: 10106.1\n",
      "FOLD MAE = 76.07131509863788\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[267]\ttraining's l1: 55.7764\ttraining's l2: 5514.64\tvalid_1's l1: 67.7872\tvalid_1's l2: 7868.84\n",
      "FOLD MAE = 67.78715893461836\n",
      "\n",
      "LGBMRegressor MAE = 72.03126364795757\n"
     ]
    }
   ],
   "source": [
    "lgbm_pred_1 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idX1, val_idX1 in kf.split(X1):\n",
    "    tr_X1, val_X1 = X1.iloc[tr_idX1], X1.iloc[val_idX1]\n",
    "    tr_y, val_y = y1.iloc[tr_idX1], y1.iloc[val_idX1]\n",
    "    lgbm.fit(tr_X1, tr_y, eval_set = [(tr_X1, tr_y), (val_X1, val_y)], eval_metric = 'mean_absolute_error', early_stopping_rounds = 2000, verbose = 5000)\n",
    "    pred = lgbm.predict(val_X1)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = lgbm.predict(target1) / 15\n",
    "    lgbm_pred_1 += sub_pred\n",
    "print(f'\\n{lgbm.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1421]\ttraining's l1: 25.1178\ttraining's l2: 1233.21\tvalid_1's l1: 40.5822\tvalid_1's l2: 2528.15\n",
      "FOLD MAE = 40.582210737944386\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[522]\ttraining's l1: 31.882\ttraining's l2: 1998.65\tvalid_1's l1: 54.7419\tvalid_1's l2: 6554.52\n",
      "FOLD MAE = 54.741861447963466\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's l1: 41.0974\ttraining's l2: 3291.3\tvalid_1's l1: 43.4276\tvalid_1's l2: 3314.58\n",
      "FOLD MAE = 43.4275711272845\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[674]\ttraining's l1: 30.7701\ttraining's l2: 1826.08\tvalid_1's l1: 48.9874\tvalid_1's l2: 5498.3\n",
      "FOLD MAE = 48.98741453258124\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[363]\ttraining's l1: 35.4634\ttraining's l2: 2511.62\tvalid_1's l1: 41.423\tvalid_1's l2: 2778.72\n",
      "FOLD MAE = 41.423047648404925\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[702]\ttraining's l1: 30.3267\ttraining's l2: 1763.12\tvalid_1's l1: 40.8978\tvalid_1's l2: 3536.41\n",
      "FOLD MAE = 40.89783102474526\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[670]\ttraining's l1: 30.6494\ttraining's l2: 1822.95\tvalid_1's l1: 45.0603\tvalid_1's l2: 4309.68\n",
      "FOLD MAE = 45.06030568528248\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[341]\ttraining's l1: 36.0377\ttraining's l2: 2562.56\tvalid_1's l1: 38.5125\tvalid_1's l2: 2502.19\n",
      "FOLD MAE = 38.5125378258836\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1577]\ttraining's l1: 25.3846\ttraining's l2: 1238.62\tvalid_1's l1: 40.1731\tvalid_1's l2: 2783.61\n",
      "FOLD MAE = 40.17305642389921\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[353]\ttraining's l1: 34.2198\ttraining's l2: 2233.36\tvalid_1's l1: 58.7161\tvalid_1's l2: 7719.58\n",
      "FOLD MAE = 58.71611587491516\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[349]\ttraining's l1: 35.0452\ttraining's l2: 2476.79\tvalid_1's l1: 45.9283\tvalid_1's l2: 3964.26\n",
      "FOLD MAE = 45.928289314979494\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[282]\ttraining's l1: 37.1007\ttraining's l2: 2704.71\tvalid_1's l1: 47.5237\tvalid_1's l2: 4264.53\n",
      "FOLD MAE = 47.52367919285359\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[647]\ttraining's l1: 30.1908\ttraining's l2: 1783.95\tvalid_1's l1: 50.2047\tvalid_1's l2: 4481.71\n",
      "FOLD MAE = 50.20467073932573\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttraining's l1: 36.6966\ttraining's l2: 2690.57\tvalid_1's l1: 45.9191\tvalid_1's l2: 3793.18\n",
      "FOLD MAE = 45.919054602133514\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "Early stopping, best iteration is:\n",
      "[369]\ttraining's l1: 35.2978\ttraining's l2: 2504.03\tvalid_1's l1: 43.8009\tvalid_1's l2: 4616.99\n",
      "FOLD MAE = 43.80092589776246\n",
      "\n",
      "LGBMRegressor MAE = 45.7265714717306\n"
     ]
    }
   ],
   "source": [
    "lgbm_pred_2 = np.zeros((target2.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X2):\n",
    "    tr_x, val_x = X2.iloc[tr_idx], X2.iloc[val_idx]\n",
    "    tr_y, val_y = y2.iloc[tr_idx], y2.iloc[val_idx]\n",
    "    \n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], eval_metric = 'mean_absolute_error', early_stopping_rounds = 2000, verbose = 5000)\n",
    "    pred = lgbm.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    mae_list.append(mae)\n",
    "    sub_pred = lgbm.predict(target2) / 15\n",
    "    lgbm_pred_2 += sub_pred\n",
    "print(f'\\n{lgbm.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['중식계'] = (lgbm_pred_1 + ngb_pred_1 + cb_pred_1) / 3\n",
    "submission['석식계'] = (lgbm_pred_2 + ngb_pred_2 + cb_pred_2) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>중식계</th>\n",
       "      <th>석식계</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>1021.270296</td>\n",
       "      <td>367.276235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>955.712339</td>\n",
       "      <td>424.324562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>637.998207</td>\n",
       "      <td>236.101793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>1267.976615</td>\n",
       "      <td>554.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-02</td>\n",
       "      <td>1036.126351</td>\n",
       "      <td>494.879986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           일자          중식계         석식계\n",
       "0  2021-01-27  1021.270296  367.276235\n",
       "1  2021-01-28   955.712339  424.324562\n",
       "2  2021-01-29   637.998207  236.101793\n",
       "3  2021-02-01  1267.976615  554.425200\n",
       "4  2021-02-02  1036.126351  494.879986"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49252.6861395934, 24129.579534888042)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.중식계.sum(), submission.석식계.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"sub1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. 요일,일자, 년, 월, 일, 주 변환\n",
    "\n",
    "def transform_day_to_num(x) :\n",
    "    if x == '월' :\n",
    "        return 5\n",
    "    elif x == '화' :\n",
    "        return 4\n",
    "    elif x == '수' :\n",
    "        return 3\n",
    "    elif x == '목' :\n",
    "        return 2\n",
    "    else :\n",
    "        return 1        \n",
    "\n",
    "train['요일'] = train['요일'].apply(transform_day_to_num)\n",
    "test['요일'] = test['요일'].apply(transform_day_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['일자'] = pd.to_datetime(train['일자'])\n",
    "test['일자'] = pd.to_datetime(test['일자'])\n",
    "\n",
    "train['년'] = train['일자'].dt.year\n",
    "test['년'] = test['일자'].dt.year\n",
    "\n",
    "train['월'] = train['일자'].dt.month\n",
    "test['월'] = test['일자'].dt.month\n",
    "\n",
    "train['일'] = train.일자.dt.day\n",
    "test['일'] = test.일자.dt.day\n",
    "\n",
    "train['주'] = train.일자.dt.week\n",
    "test['주'] = test.일자.dt.week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 현본사소속재택근무자수를 이용한 코로나 단계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_corona(x) :\n",
    "    if x <1 :\n",
    "        return 3\n",
    "    elif x < 134:\n",
    "        return 2\n",
    "    elif x < 221 :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "train['코로나단계']=train['현본사소속재택근무자수'].apply(transform_corona)\n",
    "test['코로나단계']=test['현본사소속재택근무자수'].apply(transform_corona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 휴가 간 퍼센트를 수치로 하여 열 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['휴가비율']=(train.본사휴가자수/train.본사정원수)*100\n",
    "test['휴가비율']=(test.본사휴가자수/test.본사정원수)*100\n",
    "\n",
    "def transform_rest(x) :\n",
    "    if x <2.569236 :\n",
    "        return 0\n",
    "    elif x< 3.734756:\n",
    "        return 1\n",
    "    elif x< 6.562848:\n",
    "        return 2\n",
    "    else :\n",
    "        return 3\n",
    "\n",
    "train['휴가퍼센트']=train['휴가비율'].apply(transform_rest)\n",
    "test['휴가퍼센트']=test['휴가비율'].apply(transform_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 출장 간 퍼센트를 수치로 하여 열 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 %:  7.685325264750379\n",
      "50 %:  8.803353658536585\n",
      "75 %:  9.844372059355774\n"
     ]
    }
   ],
   "source": [
    "train['출장비율']=(train.본사출장자수/train.본사정원수)*100\n",
    "test['출장비율']=(test.본사출장자수/test.본사정원수)*100\n",
    "\n",
    "for i in np.arange(0.25,1,0.25):\n",
    "    print(int(i*100),'%: ',train.출장비율.quantile(q=i))\n",
    "\n",
    "def f1(x) :\n",
    "    if x <7.685325264750379 :\n",
    "        return 0\n",
    "    elif x< 8.803353658536585:\n",
    "        return 1\n",
    "    elif x< 9.844372059355774:\n",
    "        return 2\n",
    "    else :\n",
    "        return 3\n",
    "\n",
    "train['출장퍼센트']=train['출장비율'].apply(f1)\n",
    "test['출장퍼센트']=test['출장비율'].apply(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 공휴일을 직접 수작업으로 지정하고 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['공휴일전후'] = 0\n",
    "test['공휴일전후'] = 0\n",
    "\n",
    "train['공휴일전후'][17] = 1\n",
    "train['공휴일전후'][3] = 1\n",
    "train['공휴일전후'][62] = 1\n",
    "# train['공휴일전후'][67] = 1\n",
    "# train['공휴일전후'][82] = 1\n",
    "train['공휴일전후'][131] = 1\n",
    "# train['공휴일전후'][130] = 1\n",
    "train['공휴일전후'][152] = 1\n",
    "train['공휴일전후'][226] = 1\n",
    "train['공휴일전후'][221] = 1\n",
    "train['공휴일전후'][224] = 1\n",
    "# train['공휴일전후'][244] = 1\n",
    "train['공휴일전후'][245] = 1\n",
    "# train['공휴일전후'][267] = 1\n",
    "train['공휴일전후'][310] = 2\n",
    "train['공휴일전후'][311] = 1\n",
    "train['공휴일전후'][309] = 1\n",
    "train['공휴일전후'][330] = 1\n",
    "train['공휴일전후'][379] = 1\n",
    "train['공휴일전후'][467] = 1\n",
    "# train['공휴일전후'][469] = 1\n",
    "train['공휴일전후'][470] = 1\n",
    "train['공휴일전후'][502] = 2\n",
    "# train['공휴일전후'][501] = 1\n",
    "# train['공휴일전후'][511] = 1\n",
    "train['공휴일전후'][565] = 1\n",
    "train['공휴일전후'][623] = 1\n",
    "train['공휴일전후'][651] = 1\n",
    "# train['공휴일전후'][650] = 1\n",
    "train['공휴일전후'][705] = 1\n",
    "# train['공휴일전후'][707] = 1\n",
    "train['공휴일전후'][709] = 1\n",
    "# train['공휴일전후'][733] = 1\n",
    "# train['공휴일전후'][748] = 1\n",
    "# train['공휴일전후'][792] = 1\n",
    "train['공휴일전후'][815] = 1\n",
    "train['공휴일전후'][864] = 1\n",
    "# train['공휴일전후'][863] = 1\n",
    "train['공휴일전후'][950] = 1\n",
    "train['공휴일전후'][951] = 1\n",
    "train['공휴일전후'][953] = 1\n",
    "train['공휴일전후'][954] = 1\n",
    "train['공휴일전후'][955] = 1\n",
    "train['공휴일전후'][971] = 2\n",
    "# train['공휴일전후'][970] = 1\n",
    "# train['공휴일전후'][1037] = 1\n",
    "train['공휴일전후'][1038] = 1\n",
    "train['공휴일전후'][1099] = 1\n",
    "train['공휴일전후'][1129] = 1\n",
    "# train['공휴일전후'][1128] = 1\n",
    "train['공휴일전후'][1187] = 1\n",
    "# train['공휴일전후'][1186] = 1\n",
    "\n",
    "test['공휴일전후'][10] =2\n",
    "test['공휴일전후'][20] = 1\n",
    "\n",
    "##원핫인코딩##\n",
    "\n",
    "train = pd.get_dummies(train, columns=['공휴일전후'])\n",
    "test = pd.get_dummies(test, columns=['공휴일전후'])\n",
    "\n",
    "test['공휴일전후_0'][20] =1\n",
    "test['공휴일전후_1'][20] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 메뉴 토큰화하여 일반적인 계산으로 해준 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['조식메뉴토큰'] = train['조식메뉴'].str.split(' ')\n",
    "train['중식메뉴토큰'] = train['중식메뉴'].str.split(' ')\n",
    "train['석식메뉴토큰'] = train['석식메뉴'].str.split(' ')\n",
    "\n",
    "test['조식메뉴토큰'] = test['조식메뉴'].str.split(' ')\n",
    "test['중식메뉴토큰'] = test['중식메뉴'].str.split(' ')\n",
    "test['석식메뉴토큰'] = test['석식메뉴'].str.split(' ')\n",
    "\n",
    "def get_menu_comp_cnt(data) :\n",
    "    menu_cnt = []\n",
    "    for token in data :\n",
    "        comp_cnt = 0\n",
    "        for text in token :\n",
    "            if (len(text) > 1) & (text.startswith(\"(\") != 1) :\n",
    "                comp_cnt += 1\n",
    "            else :\n",
    "                pass\n",
    "        menu_cnt.append(comp_cnt)\n",
    "    return menu_cnt\n",
    "\n",
    "train['조식메뉴수'] = get_menu_comp_cnt(train['조식메뉴토큰'])\n",
    "train['중식메뉴수'] = get_menu_comp_cnt(train['중식메뉴토큰'])\n",
    "train['석식메뉴수'] = get_menu_comp_cnt(train['석식메뉴토큰'])\n",
    "\n",
    "test['조식메뉴수'] = get_menu_comp_cnt(test['조식메뉴토큰'])\n",
    "test['중식메뉴수'] = get_menu_comp_cnt(test['중식메뉴토큰'])\n",
    "test['석식메뉴수'] = get_menu_comp_cnt(test['석식메뉴토큰'])\n",
    "\n",
    "def get_menu_nunique(data) :\n",
    "    menu_n_list = []\n",
    "    for token in data :\n",
    "        menu_n = 0\n",
    "        for text in token :\n",
    "            if  '/' in text  :\n",
    "                menu_nunique = text.count('/') + 1\n",
    "                menu_n += menu_nunique\n",
    "            else :\n",
    "                pass\n",
    "        menu_n_list.append(menu_n)\n",
    "    return menu_n_list\n",
    "\n",
    "train['석식선택메뉴'] = get_menu_nunique(train['석식메뉴토큰'])\n",
    "train['중식선택메뉴'] = get_menu_nunique(train['중식메뉴토큰'])\n",
    "train['조식선택메뉴'] = get_menu_nunique(train['조식메뉴토큰'])\n",
    "\n",
    "test['석식선택메뉴'] = get_menu_nunique(test['석식메뉴토큰'])\n",
    "test['중식선택메뉴'] = get_menu_nunique(test['중식메뉴토큰'])\n",
    "test['조식선택메뉴'] = get_menu_nunique(test['조식메뉴토큰'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_food_embedding(x):\n",
    "    x_ = []\n",
    "    x = x.split(' ')\n",
    "    for i in x:\n",
    "        if '(' in i and ':' in i and ')' in i:\n",
    "            continue\n",
    "        if '/' in i:\n",
    "            x_.extend(i.split('/'))\n",
    "        else:\n",
    "            x_.append(i)\n",
    "    x_ = list(set(x_))\n",
    "    x_.remove('')\n",
    "    return x_\n",
    "\n",
    "train['중식메뉴_split'] = train['중식메뉴'].apply(lambda x: get_food_embedding(x))\n",
    "train['석식메뉴_split'] = train['석식메뉴'].apply(lambda x: get_food_embedding(x))\n",
    "\n",
    "test['중식메뉴_split'] = test['중식메뉴'].apply(lambda x: get_food_embedding(x))\n",
    "test['석식메뉴_split'] = test['석식메뉴'].apply(lambda x: get_food_embedding(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 출근한 인원 퍼센트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 %:  2281.0\n",
      "50 %:  2357.0\n",
      "75 %:  2461.0\n"
     ]
    }
   ],
   "source": [
    "train['출근'] = train['본사정원수']-(train['본사휴가자수']+train['본사출장자수']+train['현본사소속재택근무자수'])\n",
    "test['출근'] = test['본사정원수']-(test['본사휴가자수']+test['본사출장자수']+test['현본사소속재택근무자수'])\n",
    "\n",
    "for i in np.arange(0.25,1,0.25):\n",
    "    print(int(i*100),'%: ',train.출근.quantile(q=i))\n",
    "\n",
    "def f1(x) :\n",
    "    if x <2281.0 :\n",
    "        return 0\n",
    "    elif x< 2357.0:\n",
    "        return 1\n",
    "    elif x< 2461.0:\n",
    "        return 2\n",
    "    else :\n",
    "        return 3\n",
    "\n",
    "train['출근퍼센트']=train['출근'].apply(f1)\n",
    "test['출근퍼센트']=test['출근'].apply(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 계절,주, 월초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_season(x) :\n",
    "    if 3<=x<=5 :\n",
    "        return '봄'\n",
    "    elif 6<=x<=8:\n",
    "        return '여름'\n",
    "    elif 9<=x<=11 :\n",
    "        return '가을'\n",
    "    else :\n",
    "        return '겨울'\n",
    "\n",
    "train['월_계절']=train['월'].apply(transform_season)\n",
    "test['월_계절']=test['월'].apply(transform_season)\n",
    "\n",
    "train = pd.concat([train, pd.get_dummies(train['월_계절'])], axis=1)\n",
    "test = pd.concat([test, pd.get_dummies(test['월_계절'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_week(x) :\n",
    "    if 9<=x<=22 :\n",
    "        return '주_봄'\n",
    "    elif 23<=x<=35:\n",
    "        return '주_여름'\n",
    "    elif 36<=x<=48 :\n",
    "        return '주_가을'\n",
    "    else :\n",
    "        return '주_겨울'\n",
    "\n",
    "train['주_계절']=train['주'].apply(transform_week)\n",
    "test['주_계절']=test['주'].apply(transform_week)\n",
    "\n",
    "train = pd.concat([train, pd.get_dummies(train['주_계절'])], axis=1)\n",
    "test = pd.concat([test, pd.get_dummies(test['주_계절'])], axis=1)\n",
    "\n",
    "test['주_가을']=0\n",
    "test['주_여름']=0\n",
    "test['가을']=0\n",
    "test['여름']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_day(x) :\n",
    "    if 1<=x<=10 :\n",
    "        return '초_일'\n",
    "    elif 11<=x<=20:\n",
    "        return '중_일'\n",
    "    else :\n",
    "        return '말_일'\n",
    "\n",
    "train['초중말일자']=train['일'].apply(transform_day)\n",
    "test['초중말일자']=test['일'].apply(transform_day)\n",
    "\n",
    "train = pd.concat([train, pd.get_dummies(train['초중말일자'])], axis=1)\n",
    "test = pd.concat([test, pd.get_dummies(test['초중말일자'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = train[['월','년','요일','출장퍼센트','휴가퍼센트','코로나단계','말_일','중_일','공휴일전후_0','초_일','중식메뉴수','공휴일전후_1','주_봄','봄','주_가을','가을','주_겨울','겨울','공휴일전후_2']]\n",
    "y1 = train.중식계\n",
    "target1 = test[X1.columns]\n",
    "\n",
    "X2 = train[['요일', '년', '월', '코로나단계', '휴가퍼센트', '출장퍼센트', '공휴일전후_0', '공휴일전후_1', '공휴일전후_2', '석식메뉴수', '출근퍼센트', '겨울', '봄', '주_겨울', '주_가을', '가을', '말_일', '초_일','본사시간외근무명령서승인건수']]\n",
    "y2 = train.석식계\n",
    "target2 = test[X2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 15, random_state = 607, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 55.9408\ttraining's l2: 5577.62\tvalid_1's l1: 74.133\tvalid_1's l2: 11009.9\n",
      "Early stopping, best iteration is:\n",
      "[300]\ttraining's l1: 74.8755\ttraining's l2: 9872.37\tvalid_1's l1: 74.2095\tvalid_1's l2: 10101.7\n",
      "FOLD MAE = 74.20951863485327\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 58.3071\ttraining's l2: 6047\tvalid_1's l1: 69.3082\tvalid_1's l2: 7628.59\n",
      "Early stopping, best iteration is:\n",
      "[844]\ttraining's l1: 62.9544\ttraining's l2: 7156.8\tvalid_1's l1: 68.9781\tvalid_1's l2: 7518.64\n",
      "FOLD MAE = 68.97806127724365\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 55.5359\ttraining's l2: 5537.13\tvalid_1's l1: 80.8524\tvalid_1's l2: 12180.2\n",
      "[4000]\ttraining's l1: 52.0743\ttraining's l2: 4809.44\tvalid_1's l1: 80.8354\tvalid_1's l2: 11758.1\n",
      "Early stopping, best iteration is:\n",
      "[2633]\ttraining's l1: 54.2006\ttraining's l2: 5230\tvalid_1's l1: 80.5457\tvalid_1's l2: 12024.7\n",
      "FOLD MAE = 80.54567935651488\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 56.5964\ttraining's l2: 5754.78\tvalid_1's l1: 69.7656\tvalid_1's l2: 8926.42\n",
      "Early stopping, best iteration is:\n",
      "[1848]\ttraining's l1: 57.1477\ttraining's l2: 5876.2\tvalid_1's l1: 69.443\tvalid_1's l2: 8958.02\n",
      "FOLD MAE = 69.44304470107141\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 57.1426\ttraining's l2: 5844.26\tvalid_1's l1: 65.2834\tvalid_1's l2: 7469.35\n",
      "Early stopping, best iteration is:\n",
      "[618]\ttraining's l1: 65.078\ttraining's l2: 7707.24\tvalid_1's l1: 64.8493\tvalid_1's l2: 7194.16\n",
      "FOLD MAE = 64.84931891591542\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 56.5767\ttraining's l2: 5691.72\tvalid_1's l1: 76.9978\tvalid_1's l2: 10117.3\n",
      "[4000]\ttraining's l1: 52.6386\ttraining's l2: 4854.65\tvalid_1's l1: 77.6583\tvalid_1's l2: 10015.5\n",
      "Early stopping, best iteration is:\n",
      "[2300]\ttraining's l1: 55.8437\ttraining's l2: 5536.69\tvalid_1's l1: 76.3682\tvalid_1's l2: 9959.68\n",
      "FOLD MAE = 76.36819124085044\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 56.7861\ttraining's l2: 5735.8\tvalid_1's l1: 59.7981\tvalid_1's l2: 6481.2\n",
      "Early stopping, best iteration is:\n",
      "[1390]\ttraining's l1: 59.0255\ttraining's l2: 6268.25\tvalid_1's l1: 59.3004\tvalid_1's l2: 6290.83\n",
      "FOLD MAE = 59.30043860808725\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 57.0376\ttraining's l2: 5810.29\tvalid_1's l1: 65.8982\tvalid_1's l2: 8008.09\n",
      "[4000]\ttraining's l1: 53.0245\ttraining's l2: 4974.16\tvalid_1's l1: 65.2682\tvalid_1's l2: 7720.2\n",
      "Early stopping, best iteration is:\n",
      "[3375]\ttraining's l1: 54.1475\ttraining's l2: 5208.33\tvalid_1's l1: 65.0649\tvalid_1's l2: 7834.1\n",
      "FOLD MAE = 65.06488540816069\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 57.4216\ttraining's l2: 5911.47\tvalid_1's l1: 73.0223\tvalid_1's l2: 9866.12\n",
      "[4000]\ttraining's l1: 52.4024\ttraining's l2: 4834.08\tvalid_1's l1: 71.4067\tvalid_1's l2: 9754.46\n",
      "Early stopping, best iteration is:\n",
      "[3096]\ttraining's l1: 54.3228\ttraining's l2: 5219.47\tvalid_1's l1: 70.9712\tvalid_1's l2: 9544.36\n",
      "FOLD MAE = 70.97123364491446\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 56.8167\ttraining's l2: 5853.12\tvalid_1's l1: 75.0401\tvalid_1's l2: 10109.6\n",
      "Early stopping, best iteration is:\n",
      "[1316]\ttraining's l1: 59.8725\ttraining's l2: 6429.82\tvalid_1's l1: 73.4939\tvalid_1's l2: 9867.1\n",
      "FOLD MAE = 73.49391551222234\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 55.5126\ttraining's l2: 5500.68\tvalid_1's l1: 86.444\tvalid_1's l2: 14408.8\n",
      "Early stopping, best iteration is:\n",
      "[633]\ttraining's l1: 62.9143\ttraining's l2: 7223.09\tvalid_1's l1: 85.5627\tvalid_1's l2: 14276.9\n",
      "FOLD MAE = 85.56266948373441\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 56.3784\ttraining's l2: 5608.97\tvalid_1's l1: 62.2516\tvalid_1's l2: 7330.94\n",
      "[4000]\ttraining's l1: 51.9723\ttraining's l2: 4688.41\tvalid_1's l1: 62.6893\tvalid_1's l2: 7565.92\n",
      "Early stopping, best iteration is:\n",
      "[2130]\ttraining's l1: 56.0281\ttraining's l2: 5526.76\tvalid_1's l1: 62.0755\tvalid_1's l2: 7291.17\n",
      "FOLD MAE = 62.07549319685836\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 56.8629\ttraining's l2: 5786.14\tvalid_1's l1: 64.6956\tvalid_1's l2: 7856.02\n",
      "[4000]\ttraining's l1: 52.6227\ttraining's l2: 4826.99\tvalid_1's l1: 63.3678\tvalid_1's l2: 7430.46\n",
      "Early stopping, best iteration is:\n",
      "[3985]\ttraining's l1: 52.6487\ttraining's l2: 4832.55\tvalid_1's l1: 63.3509\tvalid_1's l2: 7429.87\n",
      "FOLD MAE = 63.35085346027434\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 56.5326\ttraining's l2: 5701.64\tvalid_1's l1: 82.4778\tvalid_1's l2: 11642.2\n",
      "Early stopping, best iteration is:\n",
      "[404]\ttraining's l1: 68.7019\ttraining's l2: 8517.32\tvalid_1's l1: 80.738\tvalid_1's l2: 11133\n",
      "FOLD MAE = 80.7380476038804\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 57.0733\ttraining's l2: 5811.79\tvalid_1's l1: 72.672\tvalid_1's l2: 9066.84\n",
      "Early stopping, best iteration is:\n",
      "[959]\ttraining's l1: 61.2704\ttraining's l2: 6791.15\tvalid_1's l1: 71.6848\tvalid_1's l2: 8677.69\n",
      "FOLD MAE = 71.6847657575602\n",
      "\n",
      "LGBMRegressor MAE = 71.10907445347611\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMRegressor(random_state = 607, max_depth = 4, n_estimators = 20000, learning_rate = .01)\n",
    "\n",
    "lgbm_pred_1 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X1):\n",
    "    tr_x, val_x = X1.iloc[tr_idx], X1.iloc[val_idx]\n",
    "    tr_y, val_y = y1.iloc[tr_idx], y1.iloc[val_idx]\n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], eval_metric = 'mean_absolute_error', early_stopping_rounds = 2000, verbose = 2000)\n",
    "    pred = lgbm.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = lgbm.predict(target1) / 15\n",
    "    lgbm_pred_1 += sub_pred\n",
    "print(f'\\n{lgbm.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 석식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 33.7666\ttraining's l2: 2183.63\tvalid_1's l1: 53.3843\tvalid_1's l2: 5188.85\n",
      "Early stopping, best iteration is:\n",
      "[1062]\ttraining's l1: 36.634\ttraining's l2: 2619.48\tvalid_1's l1: 52.6661\tvalid_1's l2: 5018.79\n",
      "FOLD MAE = 52.66606674111978\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 33.6406\ttraining's l2: 2020.2\tvalid_1's l1: 49.6769\tvalid_1's l2: 8096.75\n",
      "Early stopping, best iteration is:\n",
      "[809]\ttraining's l1: 38.2948\ttraining's l2: 2653.8\tvalid_1's l1: 48.5952\tvalid_1's l2: 8142.31\n",
      "FOLD MAE = 48.59523398921298\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 34.4335\ttraining's l2: 2156.98\tvalid_1's l1: 50.6925\tvalid_1's l2: 5014.91\n",
      "Early stopping, best iteration is:\n",
      "[759]\ttraining's l1: 38.503\ttraining's l2: 2818.1\tvalid_1's l1: 50.7606\tvalid_1's l2: 4892.55\n",
      "FOLD MAE = 50.76061781244508\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 34.5359\ttraining's l2: 2251.6\tvalid_1's l1: 44.2863\tvalid_1's l2: 3229.44\n",
      "Early stopping, best iteration is:\n",
      "[977]\ttraining's l1: 37.5909\ttraining's l2: 2737.25\tvalid_1's l1: 43.8836\tvalid_1's l2: 3157.41\n",
      "FOLD MAE = 43.88357237981803\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 34.5153\ttraining's l2: 2257.6\tvalid_1's l1: 43.9857\tvalid_1's l2: 3449.56\n",
      "[4000]\ttraining's l1: 31.1026\ttraining's l2: 1794.68\tvalid_1's l1: 44.5032\tvalid_1's l2: 3424.94\n",
      "Early stopping, best iteration is:\n",
      "[2756]\ttraining's l1: 33.1456\ttraining's l2: 2052.07\tvalid_1's l1: 43.6392\tvalid_1's l2: 3379.49\n",
      "FOLD MAE = 43.63919594891683\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 33.4741\ttraining's l2: 2143.95\tvalid_1's l1: 42.9927\tvalid_1's l2: 4244.63\n",
      "Early stopping, best iteration is:\n",
      "[371]\ttraining's l1: 44.2516\ttraining's l2: 3692.42\tvalid_1's l1: 43.9916\tvalid_1's l2: 3743.78\n",
      "FOLD MAE = 43.9915959817546\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 34.6195\ttraining's l2: 2276.31\tvalid_1's l1: 43.2244\tvalid_1's l2: 3303.69\n",
      "Early stopping, best iteration is:\n",
      "[1160]\ttraining's l1: 36.9323\ttraining's l2: 2639.98\tvalid_1's l1: 42.5072\tvalid_1's l2: 3294\n",
      "FOLD MAE = 42.50724621684118\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 34.34\ttraining's l2: 2240.38\tvalid_1's l1: 41.2524\tvalid_1's l2: 2472.57\n",
      "[4000]\ttraining's l1: 31.3799\ttraining's l2: 1838.62\tvalid_1's l1: 41.8772\tvalid_1's l2: 2559.15\n",
      "Early stopping, best iteration is:\n",
      "[2465]\ttraining's l1: 33.4626\ttraining's l2: 2119.23\tvalid_1's l1: 40.8985\tvalid_1's l2: 2421.58\n",
      "FOLD MAE = 40.89846433619315\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 34.1468\ttraining's l2: 2210.67\tvalid_1's l1: 49.4497\tvalid_1's l2: 4175.87\n",
      "[4000]\ttraining's l1: 31.0216\ttraining's l2: 1773.58\tvalid_1's l1: 47.8739\tvalid_1's l2: 4054.7\n",
      "[6000]\ttraining's l1: 28.7487\ttraining's l2: 1516.22\tvalid_1's l1: 47.8059\tvalid_1's l2: 4136.26\n",
      "Early stopping, best iteration is:\n",
      "[4148]\ttraining's l1: 30.7943\ttraining's l2: 1747.29\tvalid_1's l1: 47.7001\tvalid_1's l2: 4037.4\n",
      "FOLD MAE = 47.70009452109777\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 34.5944\ttraining's l2: 2221.73\tvalid_1's l1: 46.7022\tvalid_1's l2: 4085.74\n",
      "Early stopping, best iteration is:\n",
      "[448]\ttraining's l1: 42.66\ttraining's l2: 3460.29\tvalid_1's l1: 46.4081\tvalid_1's l2: 4243.53\n",
      "FOLD MAE = 46.408127951621495\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 33.7507\ttraining's l2: 2127.25\tvalid_1's l1: 42.5147\tvalid_1's l2: 4455.18\n",
      "Early stopping, best iteration is:\n",
      "[829]\ttraining's l1: 38.838\ttraining's l2: 2865.13\tvalid_1's l1: 41.083\tvalid_1's l2: 4444.77\n",
      "FOLD MAE = 41.083033299953414\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 34.761\ttraining's l2: 2270.32\tvalid_1's l1: 46.1855\tvalid_1's l2: 4294.5\n",
      "Early stopping, best iteration is:\n",
      "[1520]\ttraining's l1: 35.983\ttraining's l2: 2456.84\tvalid_1's l1: 45.7868\tvalid_1's l2: 4301.37\n",
      "FOLD MAE = 45.786767012297226\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 34.3753\ttraining's l2: 2267.45\tvalid_1's l1: 43.5044\tvalid_1's l2: 2964.76\n",
      "[4000]\ttraining's l1: 31.0987\ttraining's l2: 1797.82\tvalid_1's l1: 42.064\tvalid_1's l2: 2877.81\n",
      "Early stopping, best iteration is:\n",
      "[3161]\ttraining's l1: 32.2661\ttraining's l2: 1943.32\tvalid_1's l1: 42.2328\tvalid_1's l2: 2843.05\n",
      "FOLD MAE = 42.23281494311671\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 33.936\ttraining's l2: 2180.9\tvalid_1's l1: 49.456\tvalid_1's l2: 4256.4\n",
      "Early stopping, best iteration is:\n",
      "[395]\ttraining's l1: 43.6178\ttraining's l2: 3612.64\tvalid_1's l1: 45.7361\tvalid_1's l2: 3529.24\n",
      "FOLD MAE = 45.73605687036513\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 35.3405\ttraining's l2: 2353.57\tvalid_1's l1: 37.7723\tvalid_1's l2: 2248.46\n",
      "Early stopping, best iteration is:\n",
      "[1383]\ttraining's l1: 36.7006\ttraining's l2: 2597.53\tvalid_1's l1: 36.9863\tvalid_1's l2: 2134.65\n",
      "FOLD MAE = 36.98629694740689\n",
      "\n",
      "LGBMRegressor MAE = 44.85834566347736\n"
     ]
    }
   ],
   "source": [
    "#### 석식\n",
    "lgbm_pred_2 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X2):\n",
    "    tr_x, val_x = X2.iloc[tr_idx], X2.iloc[val_idx]\n",
    "    tr_y, val_y = y2.iloc[tr_idx], y2.iloc[val_idx]\n",
    "    \n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], eval_metric = 'mean_absolute_error', early_stopping_rounds = 2000, verbose = 2000)\n",
    "    pred = lgbm.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    mae_list.append(mae)\n",
    "    sub_pred = lgbm.predict(target2) / 15\n",
    "    lgbm_pred_2 += sub_pred\n",
    "print(f'\\n{lgbm.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['중식계'] = lgbm_pred_1\n",
    "sub['석식계'] = lgbm_pred_2\n",
    "sub.to_csv('lgbm_07.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 중식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD MAE = 70.10232097856948\n",
      "FOLD MAE = 63.502781626428316\n",
      "FOLD MAE = 62.09974376918921\n",
      "FOLD MAE = 55.77105644007209\n",
      "FOLD MAE = 51.62687426922283\n",
      "FOLD MAE = 59.7786133181349\n",
      "FOLD MAE = 49.45553687661668\n",
      "FOLD MAE = 55.74232923272992\n",
      "FOLD MAE = 53.970878067900664\n",
      "FOLD MAE = 57.64740321672922\n",
      "FOLD MAE = 67.46559108580053\n",
      "FOLD MAE = 44.07543539475756\n",
      "FOLD MAE = 50.04290972236863\n",
      "FOLD MAE = 61.36299853485639\n",
      "FOLD MAE = 56.16672909433216\n",
      "\n",
      "NGBRegressor MAE = 57.25408010851391\n"
     ]
    }
   ],
   "source": [
    "ngb = NGBRegressor(n_estimators = 15000, verbose = 0, random_state = 607)\n",
    "\n",
    "ngb_pred_1 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X1):\n",
    "    tr_x, val_x = X1.iloc[tr_idx], X1.iloc[val_idx]\n",
    "    tr_y, val_y = y1.iloc[tr_idx], y1.iloc[val_idx]\n",
    "    ngb.fit(tr_x, tr_y, val_x, val_y, early_stopping_rounds = 2000)\n",
    "    pred = ngb.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = ngb.predict(target1) / 15\n",
    "    ngb_pred_1 += sub_pred\n",
    "print(f'\\n{ngb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 석식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD MAE = 53.678848321123816\n",
      "FOLD MAE = 35.83918789274469\n",
      "FOLD MAE = 34.61361751374115\n",
      "FOLD MAE = 28.702501912273178\n",
      "FOLD MAE = 28.867312087179357\n",
      "FOLD MAE = 27.99527395299076\n",
      "FOLD MAE = 28.361790178107675\n",
      "FOLD MAE = 28.577669332117342\n",
      "FOLD MAE = 31.297708941708226\n",
      "FOLD MAE = 29.366161071432895\n",
      "FOLD MAE = 28.056203716587913\n",
      "FOLD MAE = 27.28797461646958\n",
      "FOLD MAE = 24.18223845281041\n",
      "FOLD MAE = 29.306064062382802\n",
      "FOLD MAE = 23.917991668368433\n",
      "\n",
      "NGBRegressor MAE = 30.670036248002543\n"
     ]
    }
   ],
   "source": [
    "ngb = NGBRegressor(n_estimators = 15000, verbose = 0, random_state = 607)\n",
    "\n",
    "ngb_pred_2 = np.zeros((target2.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X2):\n",
    "    tr_x, val_x = X2.iloc[tr_idx], X2.iloc[val_idx]\n",
    "    tr_y, val_y = y2.iloc[tr_idx], y2.iloc[val_idx]\n",
    "    ngb.fit(tr_x, tr_y, val_x, val_y, early_stopping_rounds = 2000)\n",
    "    pred = ngb.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = ngb.predict(target2) / 15\n",
    "    ngb_pred_2 += sub_pred\n",
    "print(f'\\n{ngb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['중식계'] = ngb_pred_1\n",
    "sub['석식계'] = ngb_pred_2\n",
    "\n",
    "sub.to_csv('nbg_07.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbg=pd.read_csv('nbg_07.csv')\n",
    "lgbm=pd.read_csv('lgbm_07.csv')\n",
    "\n",
    "ensemble=nbg.copy()\n",
    "ensemble['중식계']=nbg['중식계']*0.3+lgbm['중식계']*0.7\n",
    "ensemble['석식계']=nbg['석식계']*0.3+lgbm['석식계']*0.7\n",
    "\n",
    "ensemble.to_csv('ensemble_07.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 띄어쓰기 및 오타 수정\n",
    "train.at[1142, '중식메뉴'] = '쌀밥/곤드레밥/찰현미밥 된장찌개 돼지고추장불고기 버섯잡채 삼색물만두무침 겉절이김치/양념장 견과류샐러드*요거트D '\n",
    "train['중식메뉴'] = train['중식메뉴'].str.replace('삽겹', '삼겹')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe1 = pd.read_csv('레시피+기본정보_20210712.csv', encoding='cp949')\n",
    "recipe2 = pd.read_csv('레시피+재료정보_20210712.csv', encoding='cp949')\n",
    "\n",
    "category = pd.read_excel('대분류중분류.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe1 = pd.read_csv('레시피+기본정보_20210712.csv', encoding='cp949')\n",
    "recipe2 = pd.read_csv('레시피+재료정보_20210712.csv', encoding='cp949')\n",
    "\n",
    "category = pd.read_excel('대분류중분류.xlsx')\n",
    "\n",
    "recipe1 = recipe1.iloc[:, :-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_food_embedding(x):\n",
    "    x_ = []\n",
    "    x = x.split(' ')\n",
    "    for i in x:\n",
    "        if '(' in i and ':' in i and ')' in i:\n",
    "            continue\n",
    "        elif '/' in i:\n",
    "            x_.extend(i.split('/'))\n",
    "        elif '*' in i:\n",
    "            x_.extend(i.split('*'))\n",
    "        else:\n",
    "            x_.append(i)\n",
    "    x_ = list(set(x_))\n",
    "    x_.remove('')\n",
    "    return x_\n",
    "\n",
    "train['조식메뉴_split'] = train['조식메뉴'].apply(lambda x: get_food_embedding(x))\n",
    "train['중식메뉴_split'] = train['중식메뉴'].apply(lambda x: get_food_embedding(x))\n",
    "train['석식메뉴_split'] = train['석식메뉴'].apply(lambda x: get_food_embedding(x))\n",
    "\n",
    "test['조식메뉴_split'] = test['조식메뉴'].apply(lambda x: get_food_embedding(x))\n",
    "test['중식메뉴_split'] = test['중식메뉴'].apply(lambda x: get_food_embedding(x))\n",
    "test['석식메뉴_split'] = test['석식메뉴'].apply(lambda x: get_food_embedding(x))\n",
    "\n",
    "regex = \"\\(.*\\)|\\s-\\s.*\"\n",
    "category['소분류'] = category['소분류'].apply(lambda x : re.sub(regex, '', x))\n",
    "\n",
    "#### 크게 종류를 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "밥_list = list(category[category['대분류'] == '밥류']['소분류'])\n",
    "과자빵_list = list(category[category['대분류'] == '과자 및 빵류']['소분류'])\n",
    "면만두_list = list(category[category['대분류'] == '면 및 만두류']['소분류'])\n",
    "죽_list = list(category[category['대분류'] == '죽류']['소분류'])\n",
    "국_list = list(category[category['대분류'] == '국(탕)류']['소분류'])\n",
    "찌개_list = list(category[category['대분류'] == '찌개류']['소분류'])\n",
    "찜_list = list(category[category['대분류'] == '찜류']['소분류'])\n",
    "구이_list = list(category[category['대분류'] == '구이류']['소분류'])\n",
    "전_list = list(category[category['대분류'] == '전류']['소분류'])\n",
    "볶음_list = list(category[category['대분류'] == '볶음류']['소분류'])\n",
    "조림_list = list(category[category['대분류'] == '조림류']['소분류'])\n",
    "튀김_list = list(category[category['대분류'] == '튀김류']['소분류'])\n",
    "무침_list = list(category[category['대분류'] == '무침류']['소분류'])\n",
    "김치_list = list(category[category['대분류'] == '김치류']['소분류'])\n",
    "회_list = list(category[category['대분류'] == '회류']['소분류'])\n",
    "젓갈_list = list(category[category['대분류'] == '젓갈류']['소분류'])\n",
    "절임_list = list(category[category['대분류'] == '절임류']['소분류'])\n",
    "장_list = list(category[category['대분류'] == '장류']['소분류'])\n",
    "우유_list = list(category[category['대분류'] == '우유 및 유제품류']['소분류'])\n",
    "음료_list = list(category[category['대분류'] == '음료류']['소분류'])\n",
    "떡_list = list(category[category['대분류'] == '떡류']['소분류'])\n",
    "원재료_list = list(category[category['대분류'] == '원재료']['소분류'])\n",
    "주류_list = list(category[category['대분류'] == '주류']['소분류'])\n",
    "\n",
    "num=[]\n",
    "for t in range(train.shape[0]):\n",
    "    for i in range(len(train['중식메뉴_split'][t])):\n",
    "        token = train['중식메뉴_split'][t][i]\n",
    "        if  token.endswith('주') or token in 주류_list:\n",
    "            print(token)\n",
    "            num.append(token)\n",
    "\n",
    "num=pd.DataFrame(num)\n",
    "num=pd.DataFrame(num.value_counts().index.values)\n",
    "num=pd.DataFrame(num[0].apply(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 일반적으로 인기가 많은 메뉴, 자주 나오지 않는 메뉴 등은 가중치를 크게 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Dae(data, col) :\n",
    "    \n",
    "    recipe_df = pd.DataFrame(np.zeros((data.shape[0], 25)), \n",
    "                          columns = ['밥류', '과자 및 빵류', '면 및 만두류', '죽류', '국(탕)류', '찌개류', '찜류', '구이류',\n",
    "       '전류', '볶음류', '조림류', '튀김류', '무침류', '김치류', '회류', '젓갈류', '절임류', '장류',\n",
    "       '우유 및 유제품류', '음료류', '떡류', '원재료', '주류', '드레싱류', '조리_기타'])\n",
    "\n",
    "    for t in range(data.shape[0]):\n",
    "        for i in range(len(data[col][t])):\n",
    "            token = data[col][t][i]\n",
    "            if '덮밥' in token or '비빔밥' in token or '볶음밥' in token:\n",
    "                recipe_df.at[t,'밥류'] +=3\n",
    "            elif  token.endswith('밥') or '밥' in token or token in 밥_list:\n",
    "                recipe_df.at[t, '밥류'] += 1 \n",
    "                \n",
    "            elif token.endswith('과자') or token in 과자빵_list:\n",
    "                recipe_df.at[t, '과자 및 빵류'] += 3\n",
    "                \n",
    "            elif token.endswith('면') or token.endswith('만두') or '면' in token or '만두' in token or token in 면만두_list:\n",
    "                recipe_df.at[t, '면 및 만두류'] += 4\n",
    "                \n",
    "            elif token.endswith('죽') or token in 죽_list or '죽' in token:\n",
    "                recipe_df.at[t, '죽류'] += 2\n",
    "                \n",
    "            elif token.endswith('구이') or token in 구이_list or '구이' in token or token.endswith('데리야끼') or token.endswith('립') or\\\n",
    "                '함박' in token or '그라탕' in token or token.endswith('갈비') or '주물럭' in token or '스테이크' in token or token.endswith('구이') or '불고기' in token or '구이' in token:\n",
    "                recipe_df.at[t, '구이류'] += 5\n",
    "                \n",
    "            elif token.endswith('국') or token.endswith('탕') or token in 국_list:\n",
    "                if '만두' in token or '해물' in token or '도토리묵' in token or '냉국' in token or '사골' in token or '고기' in token or '해장' in token or token=='육개장'  or '수제비' in token or '옹심이' in token or '삼계탕' in token or '닭볶' in token or '전복' in token or '나주곰탕' in token or '감자탕' in token or '갈비' in token or '등뼈탕' in token or '들깨' in token or '홍합' in token or '새우' in token:\n",
    "                    recipe_df.at[t, '국(탕)류'] += 4\n",
    "                else:\n",
    "                    recipe_df.at[t, '국(탕)류'] += 2\n",
    "                    \n",
    "            elif token.endswith('찌개') or token in 찌개_list:\n",
    "                if '차돌' in token or '갈비' in token or '고기' in token or '돼지' in token: \n",
    "                    recipe_df.at[t, '찌개류'] += 4\n",
    "                else:\n",
    "                    recipe_df.at[t, '찌개류'] += 2\n",
    "                \n",
    "            elif token.endswith('찜') or token in 찜_list or '찜' in token or '보쌈' in token or '수육' in token or '김치말이' in token:\n",
    "                if '브로컬리들깨찜' in token or  '꽈리고추찜' in token or  '깻잎찜' in token or  '가지찜' in token or  '청경채찜' in token or '호박잎쌈' in token:\n",
    "                    recipe_df.at[t, '찜류'] += 2\n",
    "                else:\n",
    "                    recipe_df.at[t, '찜류'] += 4\n",
    "                \n",
    "            elif token.endswith('전') or token in 전_list or '전병' in token:\n",
    "                recipe_df.at[t, '전류'] += 3\n",
    "                \n",
    "            elif token.endswith('볶음') or token in 볶음_list or '볶음' in token or token == '깐풍연근' or \\\n",
    "                '고추잡채' in token or '궁보계정' in token or '산슬' in token or token.endswith('잡채') or '마파두부' in token or '두루치기' in token or '닭갈비' in token:\n",
    "                if '미역줄기볶음' in token or '마늘쫑볶음' in token or '카레감자채볶음' in token or '모둠버섯볶음' in token or '고구마순볶음' in token or '콩나물볶음' in token or '버섯볶음' in token or '멸치' in token or '가지볶음' in token or '애기새송이버섯볶음' in token or '파프리카감자채볶음' in token or '호박새우젓볶음' in token or '청경채새송이볶음' in token or '오이볶음' in token or '호박채나물볶음' in token or '도라지볶음' in token or '도라지나물볶음' in token or '고춧잎볶음' in token or '고구마줄기볶음' in token or '감자볶음' in token or '새송이버섯볶음' in token or '가지볶음' in token or '브로콜리버섯볶음' in token or '명엽채볶음' in token or '매운호박볶음' in token or '머위대들깨볶음' in token or '멸치볶음' in token:\n",
    "                    recipe_df.at[t, '볶음류'] += 1\n",
    "                else:\n",
    "                    recipe_df.at[t, '볶음류'] += 3\n",
    "                \n",
    "            elif token.endswith('조림') or token in 조림_list or '조림' in token or '오향장육' in token or '동파육' in token:\n",
    "                if '땅콩조림' in token or '연근조림' in token or '견과류조림' in token or '연근땅콩조림' in token or '새송이버섯조림' in token or '우엉조림' in token or '시래기조림' in token or '검정콩조림' in token or '꽈리고추어묵조림' in token or '단호박장조림' in token or '감자조림' in token or '견과류연근조림' in token or '고추장감자조림' in token or '꽈리고추감자조림' in token or '콩조림' in token:\n",
    "                    recipe_df.at[t, '조림류'] += 1\n",
    "                else:\n",
    "                    recipe_df.at[t, '조림류'] += 3\n",
    "            elif token.endswith('튀김') or token.endswith('치킨') or token.endswith('탕수육') or '치킨' in token or '탕수' in token or token in 튀김_list or\\\n",
    "                '튀김' in token or '통닭' in token or token.endswith('새우') or '강정' in token or '미트볼' in token or '프리타타' in token or '카츠' in token or '깐풍' in token or\\\n",
    "                token.endswith('고로케') or '유린기' in token or '탕수' in token or token.endswith('닭') or '너겟' in token or\\\n",
    "                token.endswith('강정') or '가스' in token or '까스' in token or '핑거' in token or '텐더' in token or '커틀렛' in token or '커틀릿' in token:\n",
    "                recipe_df.at[t, '튀김류'] += 5\n",
    "                \n",
    "            elif token.endswith('무침') or token in 무침_list or '무침' in token or '파채' in token or token.endswith('샐러드') or '양장피' in token\\\n",
    "            or '범벅' in token or token.endswith('채'):\n",
    "                recipe_df.at[t, '무침류'] += 1\n",
    "                \n",
    "            elif token.endswith('김치') or token in 김치_list or '겉절이' in token:\n",
    "                recipe_df.at[t, '김치류'] += 1\n",
    "                \n",
    "            elif token.endswith('회') or token in 회_list:\n",
    "                recipe_df.at[t, '회류'] += 1\n",
    "                \n",
    "            elif token.endswith('젓갈') or token in 젓갈_list or '젓갈' in token:\n",
    "                recipe_df.at[t, '젓갈류'] += 1\n",
    "                \n",
    "            elif token.endswith('절임') or token in 절임_list or '절임' in token:\n",
    "                recipe_df.at[t, '절임류'] += 1\n",
    "                \n",
    "            elif token.endswith('장') or token in 장_list:\n",
    "                recipe_df.at[t, '장류'] += 1\n",
    "                \n",
    "            elif token.endswith('우유') or token in 우유_list:\n",
    "                recipe_df.at[t, '우유 및 유제품류'] += 1\n",
    "                \n",
    "            elif token.endswith('음료') or token in 음료_list or '요구르트' in token:\n",
    "                recipe_df.at[t, '음료류'] += 1\n",
    "                \n",
    "            elif token.endswith('떡') or token in 떡_list:\n",
    "                recipe_df.at[t, '떡류'] += 2\n",
    "                \n",
    "            elif token in 원재료_list or token == '연두부' or token.endswith('김') or '생' in token or token.endswith('쌈'):\n",
    "                recipe_df.at[t, '원재료'] += 1\n",
    "                \n",
    "            elif token.endswith('주') or token in 주류_list:\n",
    "                recipe_df.at[t, '주류'] += 1\n",
    "                \n",
    "            elif token.endswith('드레싱') or 'D' in token or '소스' in token:\n",
    "                recipe_df.at[t, '드레싱류'] += 1\n",
    "                \n",
    "            else :\n",
    "                recipe_df.at[t, '조리_기타'] += 1\n",
    "            \n",
    "    return recipe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가중치가 각각 다르기 때문에 그 날의 식단의 점수를 합한 총점수 열을 만들어 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_조식=get_Dae(train, '조식메뉴_split')\n",
    "train_중식=get_Dae(train, '중식메뉴_split')\n",
    "train_석식=get_Dae(train, '석식메뉴_split')\n",
    "\n",
    "test_조식=get_Dae(test, '조식메뉴_split')\n",
    "test_중식=get_Dae(test, '중식메뉴_split')\n",
    "test_석식=get_Dae(test, '석식메뉴_split')\n",
    "\n",
    "\n",
    "train_조식['조식점수']=train_조식.sum(axis=1)\n",
    "train_중식['중식점수']=train_중식.sum(axis=1)\n",
    "train_석식['석식점수']=train_석식.sum(axis=1)\n",
    "test_조식['조식점수']=test_조식.sum(axis=1)\n",
    "test_중식['중식점수']=test_중식.sum(axis=1)\n",
    "test_석식['석식점수']=test_석식.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['일자'] = pd.to_datetime(train['일자'])\n",
    "train['년'] = train['일자'].dt.year\n",
    "train['월'] = train['일자'].dt.month\n",
    "train['일'] = train['일자'].dt.day\n",
    "train['주'] = train['일자'].dt.week\n",
    "train['요일'] = train['일자'].dt.weekday\n",
    "\n",
    "test['일자'] = pd.to_datetime(test['일자'])\n",
    "test['년'] = test['일자'].dt.year\n",
    "test['월'] = test['일자'].dt.month\n",
    "test['일'] = test['일자'].dt.day\n",
    "test['주'] = test['일자'].dt.week\n",
    "test['요일'] = test['일자'].dt.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 출근인원 및 휴가, 출장, 야근, 재택의 비율을 구한 열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['출근'] = train['본사정원수']-(train['본사휴가자수']+train['본사출장자수']+train['현본사소속재택근무자수'])\n",
    "\n",
    "train['휴가비율'] = train['본사휴가자수']/train['본사정원수']\n",
    "train['출장비율'] = train['본사출장자수']/train['본사정원수']\n",
    "train['야근비율'] = train['본사시간외근무명령서승인건수']/train['출근']\n",
    "train['재택비율'] = train['현본사소속재택근무자수']/train['본사정원수']\n",
    "\n",
    "test['출근'] = test['본사정원수']-(test['본사휴가자수']+test['본사출장자수']+test['현본사소속재택근무자수'])\n",
    "\n",
    "test['휴가비율'] = test['본사휴가자수']/test['본사정원수']\n",
    "test['출장비율'] = test['본사출장자수']/test['본사정원수']\n",
    "test['야근비율'] = test['본사시간외근무명령서승인건수']/test['출근']\n",
    "test['재택비율'] = test['현본사소속재택근무자수']/test['본사정원수']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    if 3 <= x <= 5 :\n",
    "        return('봄')\n",
    "    elif 6 <= x <= 8 :\n",
    "        return('여름')\n",
    "    elif 9 <= x <= 11 :\n",
    "        return('가을')\n",
    "    else :\n",
    "        return('겨울')\n",
    "\n",
    "train['계절']=train.월.apply(f1)\n",
    "test['계절']=test.월.apply(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x):\n",
    "    if 3 <= x <= 5 :\n",
    "        return('봄')\n",
    "    elif 6 <= x <= 8 :\n",
    "        return('여름')\n",
    "    elif 9 <= x <= 11 :\n",
    "        return('가을')\n",
    "    else :\n",
    "        return('겨울')\n",
    "\n",
    "train['계절']=train.월.apply(f1)\n",
    "test['계절']=test.월.apply(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 년도, 월, 일, 주, 요일 계절별, 재택, 야근 출장, 휴가 (mean, min, max 값) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.merge(train, train.groupby('년')['현본사소속재택근무자수'].agg([('재택근무자_년평균','mean'),('재택근무자_년최대','max'),('재택근무자_년최소','min')]).reset_index(), how='left',on='년')\n",
    "test=pd.merge(test, test.groupby('년')['현본사소속재택근무자수'].agg([('재택근무자_년평균','mean'),('재택근무자_년최대','max'),('재택근무자_년최소','min')]).reset_index(), how='left',on='년')\n",
    "\n",
    "train=pd.merge(train, train.groupby('년')['본사시간외근무명령서승인건수'].agg([('야간근무자_년평균','mean'),('야간근무자_년최대','max'),('야간근무자_년최소','min')]).reset_index(), how='left',on='년')\n",
    "test=pd.merge(test, test.groupby('년')['본사시간외근무명령서승인건수'].agg([('야간근무자_년평균','mean'),('야간근무자_년최대','max'),('야간근무자_년최소','min')]).reset_index(), how='left',on='년')\n",
    "\n",
    "train=pd.merge(train, train.groupby('년')['본사출장자수'].agg([('출장근무자_년평균','mean'),('출장근무자_년최대','max'),('출장근무자_년최소','min')]).reset_index(), how='left',on='년')\n",
    "test=pd.merge(test, test.groupby('년')['본사출장자수'].agg([('출장근무자_년평균','mean'),('출장근무자_년최대','max'),('출장근무자_년최소','min')]).reset_index(), how='left',on='년')\n",
    "\n",
    "train=pd.merge(train, train.groupby('년')['본사휴가자수'].agg([('휴가자_년평균','mean'),('휴가자_년최대','max'),('휴가자_년최소','min')]).reset_index(), how='left',on='년')\n",
    "test=pd.merge(test, test.groupby('년')['본사휴가자수'].agg([('휴가자_년평균','mean'),('휴가자_년최대','max'),('휴가자_년최소','min')]).reset_index(), how='left',on='년')\n",
    "\n",
    "train=pd.merge(train, train.groupby('월')['현본사소속재택근무자수'].agg([('재택근무자_월평균','mean'),('재택근무자_월최대','max'),('재택근무자_월최소','min')]).reset_index(), how='left',on='월')\n",
    "test=pd.merge(test, test.groupby('월')['현본사소속재택근무자수'].agg([('재택근무자_월평균','mean'),('재택근무자_월최대','max'),('재택근무자_월최소','min')]).reset_index(), how='left',on='월')\n",
    "\n",
    "train=pd.merge(train, train.groupby('월')['본사시간외근무명령서승인건수'].agg([('야간근무자_월평균','mean'),('야간근무자_월최대','max'),('야간근무자_월최소','min')]).reset_index(), how='left',on='월')\n",
    "test=pd.merge(test, test.groupby('월')['본사시간외근무명령서승인건수'].agg([('야간근무자_월평균','mean'),('야간근무자_월최대','max'),('야간근무자_월최소','min')]).reset_index(), how='left',on='월')\n",
    "\n",
    "train=pd.merge(train, train.groupby('월')['본사출장자수'].agg([('출장근무자_월평균','mean'),('출장근무자_월최대','max'),('출장근무자_월최소','min')]).reset_index(), how='left',on='월')\n",
    "test=pd.merge(test, test.groupby('월')['본사출장자수'].agg([('출장근무자_월평균','mean'),('출장근무자_월최대','max'),('출장근무자_월최소','min')]).reset_index(), how='left',on='월')\n",
    "\n",
    "train=pd.merge(train, train.groupby('월')['본사휴가자수'].agg([('휴가자_월평균','mean'),('휴가자_월최대','max'),('휴가자_월최소','min')]).reset_index(), how='left',on='월')\n",
    "test=pd.merge(test, test.groupby('월')['본사휴가자수'].agg([('휴가자_월평균','mean'),('휴가자_월최대','max'),('휴가자_월최소','min')]).reset_index(), how='left',on='월')\n",
    "\n",
    "#### 연도 별 재택근무자 수(평균, 최댓값, 최솟값)\n",
    "train=pd.merge(train, train.groupby('일')['현본사소속재택근무자수'].agg([('재택근무자_일평균','mean'),('재택근무자_일최대','max'),('재택근무자_일최소','min')]).reset_index(), how='left',on='일')\n",
    "test=pd.merge(test, test.groupby('일')['현본사소속재택근무자수'].agg([('재택근무자_일평균','mean'),('재택근무자_일최대','max'),('재택근무자_일최소','min')]).reset_index(), how='left',on='일')\n",
    "\n",
    "train=pd.merge(train, train.groupby('일')['본사시간외근무명령서승인건수'].agg([('야간근무자_일평균','mean'),('야간근무자_일최대','max'),('야간근무자_일최소','min')]).reset_index(), how='left',on='일')\n",
    "test=pd.merge(test, test.groupby('일')['본사시간외근무명령서승인건수'].agg([('야간근무자_일평균','mean'),('야간근무자_일최대','max'),('야간근무자_일최소','min')]).reset_index(), how='left',on='일')\n",
    "\n",
    "train=pd.merge(train, train.groupby('일')['본사출장자수'].agg([('출장근무자_일평균','mean'),('출장근무자_일최대','max'),('출장근무자_일최소','min')]).reset_index(), how='left',on='일')\n",
    "test=pd.merge(test, test.groupby('일')['본사출장자수'].agg([('출장근무자_일평균','mean'),('출장근무자_일최대','max'),('출장근무자_일최소','min')]).reset_index(), how='left',on='일')\n",
    "\n",
    "train=pd.merge(train, train.groupby('일')['본사휴가자수'].agg([('휴가자_일평균','mean'),('휴가자_일최대','max'),('휴가자_일최소','min')]).reset_index(), how='left',on='일')\n",
    "test=pd.merge(test, test.groupby('일')['본사휴가자수'].agg([('휴가자_일평균','mean'),('휴가자_일최대','max'),('휴가자_일최소','min')]).reset_index(), how='left',on='일')\n",
    "\n",
    "#### 연도 별 재택근무자 수(평균, 최댓값, 최솟값)\n",
    "train=pd.merge(train, train.groupby('주')['현본사소속재택근무자수'].agg([('재택근무자_주평균','mean'),('재택근무자_주최대','max'),('재택근무자_주최소','min')]).reset_index(), how='left',on='주')\n",
    "test=pd.merge(test, test.groupby('주')['현본사소속재택근무자수'].agg([('재택근무자_주평균','mean'),('재택근무자_주최대','max'),('재택근무자_주최소','min')]).reset_index(), how='left',on='주')\n",
    "\n",
    "train=pd.merge(train, train.groupby('주')['본사시간외근무명령서승인건수'].agg([('야간근무자_주평균','mean'),('야간근무자_주최대','max'),('야간근무자_주최소','min')]).reset_index(), how='left',on='주')\n",
    "test=pd.merge(test, test.groupby('주')['본사시간외근무명령서승인건수'].agg([('야간근무자_주평균','mean'),('야간근무자_주최대','max'),('야간근무자_주최소','min')]).reset_index(), how='left',on='주')\n",
    "\n",
    "train=pd.merge(train, train.groupby('주')['본사출장자수'].agg([('출장근무자_주평균','mean'),('출장근무자_주최대','max'),('출장근무자_주최소','min')]).reset_index(), how='left',on='주')\n",
    "test=pd.merge(test, test.groupby('주')['본사출장자수'].agg([('출장근무자_주평균','mean'),('출장근무자_주최대','max'),('출장근무자_주최소','min')]).reset_index(), how='left',on='주')\n",
    "\n",
    "train=pd.merge(train, train.groupby('주')['본사휴가자수'].agg([('휴가자_주평균','mean'),('휴가자_주최대','max'),('휴가자_주최소','min')]).reset_index(), how='left',on='주')\n",
    "test=pd.merge(test, test.groupby('주')['본사휴가자수'].agg([('휴가자_주평균','mean'),('휴가자_주최대','max'),('휴가자_주최소','min')]).reset_index(), how='left',on='주')\n",
    "\n",
    "#### 연도 별 재택근무자 수(평균, 최댓값, 최솟값)\n",
    "train=pd.merge(train, train.groupby('요일')['현본사소속재택근무자수'].agg([('재택근무자_요일평균','mean'),('재택근무자_요일최대','max'),('재택근무자_요일최소','min')]).reset_index(), how='left',on='요일')\n",
    "test=pd.merge(test, test.groupby('요일')['현본사소속재택근무자수'].agg([('재택근무자_요일평균','mean'),('재택근무자_요일최대','max'),('재택근무자_요일최소','min')]).reset_index(), how='left',on='요일')\n",
    "\n",
    "train=pd.merge(train, train.groupby('요일')['본사시간외근무명령서승인건수'].agg([('야간근무자_요일평균','mean'),('야간근무자_요일최대','max'),('야간근무자_요일최소','min')]).reset_index(), how='left',on='요일')\n",
    "test=pd.merge(test, test.groupby('요일')['본사시간외근무명령서승인건수'].agg([('야간근무자_요일평균','mean'),('야간근무자_요일최대','max'),('야간근무자_요일최소','min')]).reset_index(), how='left',on='요일')\n",
    "\n",
    "train=pd.merge(train, train.groupby('요일')['본사출장자수'].agg([('출장근무자_요일평균','mean'),('출장근무자_요일최대','max'),('출장근무자_요일최소','min')]).reset_index(), how='left',on='요일')\n",
    "test=pd.merge(test, test.groupby('요일')['본사출장자수'].agg([('출장근무자_요일평균','mean'),('출장근무자_요일최대','max'),('출장근무자_요일최소','min')]).reset_index(), how='left',on='요일')\n",
    "\n",
    "train=pd.merge(train, train.groupby('요일')['본사휴가자수'].agg([('휴가자_요일평균','mean'),('휴가자_요일최대','max'),('휴가자_요일최소','min')]).reset_index(), how='left',on='요일')\n",
    "test=pd.merge(test, test.groupby('요일')['본사휴가자수'].agg([('휴가자_요일평균','mean'),('휴가자_요일최대','max'),('휴가자_요일최소','min')]).reset_index(), how='left',on='요일')\n",
    "\n",
    "#### 연도 별 재택근무자 수(평균, 최댓값, 최솟값)\n",
    "train=pd.merge(train, train.groupby('계절')['현본사소속재택근무자수'].agg([('재택근무자_계절평균','mean'),('재택근무자_계절최대','max'),('재택근무자_계절최소','min')]).reset_index(), how='left',on='계절')\n",
    "test=pd.merge(test, test.groupby('계절')['현본사소속재택근무자수'].agg([('재택근무자_계절평균','mean'),('재택근무자_계절최대','max'),('재택근무자_계절최소','min')]).reset_index(), how='left',on='계절')\n",
    "\n",
    "train=pd.merge(train, train.groupby('계절')['본사시간외근무명령서승인건수'].agg([('야간근무자_계절평균','mean'),('야간근무자_계절최대','max'),('야간근무자_계절최소','min')]).reset_index(), how='left',on='계절')\n",
    "test=pd.merge(test, test.groupby('계절')['본사시간외근무명령서승인건수'].agg([('야간근무자_계절평균','mean'),('야간근무자_계절최대','max'),('야간근무자_계절최소','min')]).reset_index(), how='left',on='계절')\n",
    "\n",
    "train=pd.merge(train, train.groupby('계절')['본사출장자수'].agg([('출장근무자_계절평균','mean'),('출장근무자_계절최대','max'),('출장근무자_계절최소','min')]).reset_index(), how='left',on='계절')\n",
    "test=pd.merge(test, test.groupby('계절')['본사출장자수'].agg([('출장근무자_계절평균','mean'),('출장근무자_계절최대','max'),('출장근무자_계절최소','min')]).reset_index(), how='left',on='계절')\n",
    "\n",
    "train=pd.merge(train, train.groupby('계절')['본사휴가자수'].agg([('휴가자_계절평균','mean'),('휴가자_계절최대','max'),('휴가자_계절최소','min')]).reset_index(), how='left',on='계절')\n",
    "test=pd.merge(test, test.groupby('계절')['본사휴가자수'].agg([('휴가자_계절평균','mean'),('휴가자_계절최대','max'),('휴가자_계절최소','min')]).reset_index(), how='left',on='계절')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 요일, 계절별 중식계, 석식계 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1=train.copy()\n",
    "\n",
    "mean=train_1['중식계'].mean()\n",
    "agg=train_1.groupby('요일')['중식계'].agg(['count','mean'])\n",
    "counts=agg['count']\n",
    "means=agg['mean']\n",
    "weight=80\n",
    "smooth=(counts*means+weight*mean)/(counts+weight)\n",
    "train['요일_중식계']=train['요일'].map(smooth)\n",
    "test['요일_중식계']=test['요일'].map(smooth)\n",
    "\n",
    "mean=train_1['석식계'].mean()\n",
    "agg=train_1.groupby('요일')['석식계'].agg(['count','mean'])\n",
    "counts=agg['count']\n",
    "means=agg['mean']\n",
    "weight=80\n",
    "smooth=(counts*means+weight*mean)/(counts+weight)\n",
    "train['요일_석식계']=train['요일'].map(smooth)\n",
    "test['요일_석식계']=test['요일'].map(smooth)\n",
    "\n",
    "\n",
    "mean=train_1['중식계'].mean()\n",
    "agg=train_1.groupby('계절')['중식계'].agg(['count','mean'])\n",
    "counts=agg['count']\n",
    "means=agg['mean']\n",
    "weight=80\n",
    "smooth=(counts*means+weight*mean)/(counts+weight)\n",
    "train['계절_중식계']=train['계절'].map(smooth)\n",
    "test['계절_중식계']=test['계절'].map(smooth)\n",
    "\n",
    "mean=train_1['석식계'].mean()\n",
    "agg=train_1.groupby('계절')['석식계'].agg(['count','mean'])\n",
    "counts=agg['count']\n",
    "means=agg['mean']\n",
    "weight=80\n",
    "smooth=(counts*means+weight*mean)/(counts+weight)\n",
    "train['계절_석식계']=train['계절'].map(smooth)\n",
    "test['계절_석식계']=test['계절'].map(smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns=test.columns[(test.dtypes== 'int64') + (test.dtypes== 'float64')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 원 데이터는 과적합으로 보여 제외시킨 후 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns=select_columns.drop(['본사정원수', '본사휴가자수', '본사출장자수', '본사시간외근무명령서승인건수', '현본사소속재택근무자수','일'])\n",
    "\n",
    "train_점심=pd.concat([train[select_columns],train_중식],axis=1)\n",
    "test_점심=pd.concat([test[select_columns],test_중식],axis=1)\n",
    "train_저녁 = pd.concat([train[select_columns],train_석식],axis=1)\n",
    "test_저녁 = pd.concat([test[select_columns],test_석식],axis=1)\n",
    "\n",
    "X1 = train_점심\n",
    "y1 = train.중식계\n",
    "target1 = test_점심\n",
    "\n",
    "X2 = train_저녁\n",
    "y2 = train.석식계\n",
    "target2 = test_저녁\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:24<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, -79.35438519561515)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 사용할 모델 설정 (속도가 빠른 모델 사용 권장)\n",
    "model = LGBMRegressor(random_state=0)\n",
    "\n",
    "# 각 특성과 타깃(class) 사이에 유의한 통계적 관계가 있는지 계산하여 특성을 선택하는 방법 \n",
    "cv_scores = []\n",
    "for p in tqdm(range(5,100,1)):\n",
    "    X_new = SelectPercentile(percentile=p).fit_transform(X1, y1)    #SelectPercentile: 지정된 비율만큼 특성을 선택한다.\n",
    "    cv_score = cross_val_score(model, X_new, y1, scoring='neg_mean_absolute_error', cv=5).mean()\n",
    "    cv_scores.append((p,cv_score))\n",
    "\n",
    "# Print the best percentile\n",
    "best_score = cv_scores[np.argmax([score for _, score in cv_scores])]\n",
    "print(best_score)\n",
    "\n",
    "# Plot the performance change with p\n",
    "plt.plot([k for k, _ in cv_scores], [score for _, score in cv_scores])\n",
    "plt.xlabel('Percent of features')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1205, 43)\n",
      "['요일', '출근', '휴가비율', '출장비율', '야근비율', '재택비율', '재택근무자_년평균', '재택근무자_년최대', '재택근무자_년최소', '야간근무자_년평균', '출장근무자_년평균', '휴가자_년평균', '야간근무자_일최대', '출장근무자_일최대', '야간근무자_주평균', '출장근무자_주평균', '출장근무자_주최대', '휴가자_주평균', '휴가자_주최대', '재택근무자_요일평균', '재택근무자_요일최대', '야간근무자_요일평균', '야간근무자_요일최대', '야간근무자_요일최소', '출장근무자_요일평균', '출장근무자_요일최대', '출장근무자_요일최소', '휴가자_요일평균', '휴가자_요일최소', '요일_중식계', '요일_석식계', '면 및 만두류', '국(탕)류', '찌개류', '전류', '볶음류', '김치류', '회류', '젓갈류', '음료류', '원재료', '조리_기타', '중식점수']\n"
     ]
    }
   ],
   "source": [
    "# 과적합을 피하기 위해 최적의 p값 주변의 값을 선택하는게 더 나은 결과를 얻을 수 있다. \n",
    "fs = SelectPercentile(percentile=best_score[0]).fit(X1, y1)\n",
    "X1_select = fs.transform(X1)\n",
    "target1_select = fs.transform(target1)\n",
    "\n",
    "print(X1_select.shape)\n",
    "print(X1.columns[fs.get_support()].tolist()) #get_support: 선택한 특성을 불린값으로 보여줘서 어떤 특성을 선택했는지 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 셀렉션 진행 후 상관관계가 높은 변수를 제외하여 피쳐를 정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = train_점심[['요일', '출근', '휴가비율', '출장비율', '야근비율', '재택비율', '재택근무자_년평균', '재택근무자_년최대', '재택근무자_년최소', '야간근무자_년평균', '출장근무자_년평균', '휴가자_년평균', '야간근무자_일최대', '출장근무자_일최대', '야간근무자_주평균', '출장근무자_주평균', '출장근무자_주최대', '휴가자_주평균', '휴가자_주최대', '재택근무자_요일평균', '재택근무자_요일최대', '야간근무자_요일평균', '야간근무자_요일최대', '야간근무자_요일최소', '출장근무자_요일평균', '출장근무자_요일최대', '출장근무자_요일최소', '휴가자_요일평균', '휴가자_요일최소', '요일_중식계', '요일_석식계', '면 및 만두류', '국(탕)류', '찌개류', '전류', '볶음류', '김치류', '회류', '젓갈류', '음료류', '원재료', '조리_기타', '중식점수']]\n",
    "y1 = train.중식계\n",
    "target1 = test_점심[X1.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [01:24<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, -56.66545518016203)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 사용할 모델 설정 (속도가 빠른 모델 사용 권장)\n",
    "model = LGBMRegressor(random_state=0)\n",
    "\n",
    "# 각 특성과 타깃(class) 사이에 유의한 통계적 관계가 있는지 계산하여 특성을 선택하는 방법 \n",
    "cv_scores = []\n",
    "for p in tqdm(range(5,100,1)):\n",
    "    X_new = SelectPercentile(percentile=p).fit_transform(X2, y2)    #SelectPercentile: 지정된 비율만큼 특성을 선택한다.\n",
    "    cv_score = cross_val_score(model, X_new, y2, scoring='neg_mean_absolute_error', cv=5).mean()\n",
    "    cv_scores.append((p,cv_score))\n",
    "\n",
    "# Print the best percentile\n",
    "best_score = cv_scores[np.argmax([score for _, score in cv_scores])]\n",
    "print(best_score)\n",
    "\n",
    "# Plot the performance change with p\n",
    "plt.plot([k for k, _ in cv_scores], [score for _, score in cv_scores])\n",
    "plt.xlabel('Percent of features')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1205, 79)\n",
      "['요일', '년', '월', '주', '출근', '휴가비율', '출장비율', '야근비율', '재택비율', '재택근무자_년평균', '재택근무자_년최대', '재택근무자_년최소', '야간근무자_년평균', '야간근무자_년최대', '출장근무자_년평균', '출장근무자_년최대', '출장근무자_년최소', '휴가자_년평균', '휴가자_년최대', '휴가자_년최소', '재택근무자_월평균', '야간근무자_월평균', '야간근무자_월최대', '출장근무자_월최대', '휴가자_월평균', '휴가자_월최대', '휴가자_월최소', '재택근무자_일평균', '야간근무자_일평균', '야간근무자_일최대', '출장근무자_일최소', '휴가자_일최소', '재택근무자_주평균', '야간근무자_주평균', '야간근무자_주최대', '휴가자_주평균', '휴가자_주최대', '휴가자_주최소', '재택근무자_요일평균', '재택근무자_요일최대', '야간근무자_요일평균', '야간근무자_요일최대', '야간근무자_요일최소', '출장근무자_요일평균', '출장근무자_요일최대', '출장근무자_요일최소', '휴가자_요일평균', '휴가자_요일최대', '휴가자_요일최소', '재택근무자_계절평균', '재택근무자_계절최대', '야간근무자_계절평균', '야간근무자_계절최대', '출장근무자_계절평균', '출장근무자_계절최대', '출장근무자_계절최소', '휴가자_계절평균', '휴가자_계절최대', '휴가자_계절최소', '요일_중식계', '요일_석식계', '계절_중식계', '계절_석식계', '밥류', '국(탕)류', '찌개류', '찜류', '구이류', '전류', '볶음류', '조림류', '튀김류', '무침류', '김치류', '장류', '우유 및 유제품류', '떡류', '원재료', '석식점수']\n"
     ]
    }
   ],
   "source": [
    "# 과적합을 피하기 위해 최적의 p값 주변의 값을 선택하는게 더 나은 결과를 얻을 수 있다. \n",
    "fs = SelectPercentile(percentile=best_score[0]).fit(X2, y2)\n",
    "X2_select = fs.transform(X2)\n",
    "target2_select = fs.transform(target2)\n",
    "\n",
    "print(X2_select.shape)\n",
    "print(X2.columns[fs.get_support()].tolist()) #get_support: 선택한 특성을 불린값으로 보여줘서 어떤 특성을 선택했는지 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = train_저녁[['요일', '년', '월', '주', '출근', '휴가비율', '출장비율', '야근비율', '재택비율', '재택근무자_년평균', '재택근무자_년최대', '재택근무자_년최소', '야간근무자_년평균', '야간근무자_년최대', '출장근무자_년평균', '출장근무자_년최대', '출장근무자_년최소', '휴가자_년평균', '휴가자_년최대', '휴가자_년최소', '재택근무자_월평균', '야간근무자_월평균', '야간근무자_월최대', '출장근무자_월최대', '휴가자_월평균', '휴가자_월최대', '휴가자_월최소', '재택근무자_일평균', '야간근무자_일평균', '야간근무자_일최대', '출장근무자_일최소', '휴가자_일최소', '재택근무자_주평균', '야간근무자_주평균', '야간근무자_주최대', '휴가자_주평균', '휴가자_주최대', '휴가자_주최소', '재택근무자_요일평균', '재택근무자_요일최대', '야간근무자_요일평균', '야간근무자_요일최대', '야간근무자_요일최소', '출장근무자_요일평균', '출장근무자_요일최대', '출장근무자_요일최소', '휴가자_요일평균', '휴가자_요일최대', '휴가자_요일최소', '재택근무자_계절평균', '재택근무자_계절최대', '야간근무자_계절평균', '야간근무자_계절최대', '출장근무자_계절평균', '출장근무자_계절최대', '출장근무자_계절최소', '휴가자_계절평균', '휴가자_계절최대', '휴가자_계절최소', '요일_중식계', '요일_석식계', '계절_중식계', '계절_석식계', '밥류', '국(탕)류', '찌개류', '찜류', '구이류', '전류', '볶음류', '조림류', '튀김류', '무침류', '김치류', '장류', '우유 및 유제품류', '떡류', '원재료', '석식점수']]\n",
    "y2 = train.석식계\n",
    "target2 = test_저녁[X2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 39.0524\ttraining's l2: 2663.5\tvalid_1's l1: 62.2652\tvalid_1's l2: 6673.96\n",
      "Early stopping, best iteration is:\n",
      "[1539]\ttraining's l1: 42.8359\ttraining's l2: 3218.45\tvalid_1's l1: 61.5201\tvalid_1's l2: 6702.38\n",
      "FOLD MAE = 61.52006182022204\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 37.426\ttraining's l2: 2467.98\tvalid_1's l1: 59.2325\tvalid_1's l2: 5809.28\n",
      "Early stopping, best iteration is:\n",
      "[1503]\ttraining's l1: 41.6575\ttraining's l2: 3066.61\tvalid_1's l1: 58.9235\tvalid_1's l2: 5749.6\n",
      "FOLD MAE = 58.92346366696711\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 38.3687\ttraining's l2: 2586.53\tvalid_1's l1: 74.3732\tvalid_1's l2: 10136.7\n",
      "Early stopping, best iteration is:\n",
      "[1605]\ttraining's l1: 40.901\ttraining's l2: 2943.6\tvalid_1's l1: 74.5094\tvalid_1's l2: 10071.9\n",
      "FOLD MAE = 74.50940711251782\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 37.7792\ttraining's l2: 2574.47\tvalid_1's l1: 65.6034\tvalid_1's l2: 7492.4\n",
      "[4000]\ttraining's l1: 27.0669\ttraining's l2: 1326.84\tvalid_1's l1: 65.9969\tvalid_1's l2: 7546.02\n",
      "Early stopping, best iteration is:\n",
      "[2836]\ttraining's l1: 31.9184\ttraining's l2: 1829.82\tvalid_1's l1: 65.354\tvalid_1's l2: 7348.85\n",
      "FOLD MAE = 65.35400245503534\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 36.9665\ttraining's l2: 2428.04\tvalid_1's l1: 62.0048\tvalid_1's l2: 6191.32\n",
      "Early stopping, best iteration is:\n",
      "[929]\ttraining's l1: 48.1904\ttraining's l2: 4124.03\tvalid_1's l1: 58.6079\tvalid_1's l2: 5768.02\n",
      "FOLD MAE = 58.60789521477079\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 36.5389\ttraining's l2: 2364.99\tvalid_1's l1: 68.1962\tvalid_1's l2: 9306.67\n",
      "[4000]\ttraining's l1: 26.0496\ttraining's l2: 1200.58\tvalid_1's l1: 65.2951\tvalid_1's l2: 8674.19\n",
      "[6000]\ttraining's l1: 19.9659\ttraining's l2: 702.573\tvalid_1's l1: 65.7021\tvalid_1's l2: 8682.23\n",
      "Early stopping, best iteration is:\n",
      "[4586]\ttraining's l1: 23.9499\ttraining's l2: 1010.02\tvalid_1's l1: 65.0169\tvalid_1's l2: 8604.61\n",
      "FOLD MAE = 65.01690060106175\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 38.3436\ttraining's l2: 2610.44\tvalid_1's l1: 65.8296\tvalid_1's l2: 7675.93\n",
      "Early stopping, best iteration is:\n",
      "[1603]\ttraining's l1: 41.5656\ttraining's l2: 3071.83\tvalid_1's l1: 65.6004\tvalid_1's l2: 7593.61\n",
      "FOLD MAE = 65.60041696168003\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 36.8669\ttraining's l2: 2415.63\tvalid_1's l1: 68.6397\tvalid_1's l2: 8187.06\n",
      "Early stopping, best iteration is:\n",
      "[1279]\ttraining's l1: 43.2798\ttraining's l2: 3333.66\tvalid_1's l1: 68.185\tvalid_1's l2: 8003.87\n",
      "FOLD MAE = 68.18497080443392\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 39.2065\ttraining's l2: 2757.17\tvalid_1's l1: 71.818\tvalid_1's l2: 9593.12\n",
      "[4000]\ttraining's l1: 28.4931\ttraining's l2: 1441.38\tvalid_1's l1: 68.6148\tvalid_1's l2: 8708.3\n",
      "[6000]\ttraining's l1: 21.1666\ttraining's l2: 805.799\tvalid_1's l1: 68.23\tvalid_1's l2: 8591.25\n",
      "Early stopping, best iteration is:\n",
      "[5095]\ttraining's l1: 23.9561\ttraining's l2: 1022.99\tvalid_1's l1: 67.7494\tvalid_1's l2: 8534.47\n",
      "FOLD MAE = 67.74937691968572\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 38.5193\ttraining's l2: 2633.2\tvalid_1's l1: 61.557\tvalid_1's l2: 6644.05\n",
      "[4000]\ttraining's l1: 26.7772\ttraining's l2: 1262.33\tvalid_1's l1: 61.4682\tvalid_1's l2: 6704.21\n",
      "Early stopping, best iteration is:\n",
      "[2768]\ttraining's l1: 33.022\ttraining's l2: 1929.84\tvalid_1's l1: 60.7246\tvalid_1's l2: 6532.36\n",
      "FOLD MAE = 60.7246021825736\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 36.5295\ttraining's l2: 2386.75\tvalid_1's l1: 86.7077\tvalid_1's l2: 13022.3\n",
      "Early stopping, best iteration is:\n",
      "[1839]\ttraining's l1: 37.5979\ttraining's l2: 2525.68\tvalid_1's l1: 86.4226\tvalid_1's l2: 13015.6\n",
      "FOLD MAE = 86.42262190997704\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 38.2261\ttraining's l2: 2577.07\tvalid_1's l1: 60.9304\tvalid_1's l2: 7486.95\n",
      "Early stopping, best iteration is:\n",
      "[1734]\ttraining's l1: 40.6079\ttraining's l2: 2905.96\tvalid_1's l1: 60.8672\tvalid_1's l2: 7381.51\n",
      "FOLD MAE = 60.8672268434279\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 38.0301\ttraining's l2: 2568.09\tvalid_1's l1: 63.3646\tvalid_1's l2: 7230.54\n",
      "[4000]\ttraining's l1: 27.913\ttraining's l2: 1374.59\tvalid_1's l1: 66.495\tvalid_1's l2: 7691.48\n",
      "Early stopping, best iteration is:\n",
      "[2265]\ttraining's l1: 35.9488\ttraining's l2: 2299.07\tvalid_1's l1: 62.871\tvalid_1's l2: 7152.92\n",
      "FOLD MAE = 62.87103602707909\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 37.4399\ttraining's l2: 2472.4\tvalid_1's l1: 74.323\tvalid_1's l2: 9401.93\n",
      "Early stopping, best iteration is:\n",
      "[1481]\ttraining's l1: 41.7754\ttraining's l2: 3097.14\tvalid_1's l1: 73.5047\tvalid_1's l2: 9364.72\n",
      "FOLD MAE = 73.5047325422479\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 37.4792\ttraining's l2: 2502.05\tvalid_1's l1: 63.3214\tvalid_1's l2: 6297.34\n",
      "Early stopping, best iteration is:\n",
      "[1651]\ttraining's l1: 40.3791\ttraining's l2: 2907.99\tvalid_1's l1: 63.4515\tvalid_1's l2: 6240.12\n",
      "FOLD MAE = 63.45146275670961\n",
      "\n",
      "LGBMRegressor MAE = 66.22054518789264\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 15, random_state = 607, shuffle = True)\n",
    "\n",
    "lgbm = LGBMRegressor(random_state = 607, max_depth = 4, n_estimators = 20000, learning_rate = .01)\n",
    "\n",
    "lgbm_pred_1 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X1):\n",
    "    tr_x, val_x = X1.iloc[tr_idx], X1.iloc[val_idx]\n",
    "    tr_y, val_y = y1.iloc[tr_idx], y1.iloc[val_idx]\n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], eval_metric = 'mean_absolute_error', early_stopping_rounds = 2000, verbose = 2000)\n",
    "    pred = lgbm.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = lgbm.predict(target1) / 15\n",
    "    lgbm_pred_1 += sub_pred\n",
    "print(f'\\n{lgbm.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 24.1249\ttraining's l2: 1113.51\tvalid_1's l1: 50.8954\tvalid_1's l2: 5019.18\n",
      "Early stopping, best iteration is:\n",
      "[1232]\ttraining's l1: 28.8751\ttraining's l2: 1595.2\tvalid_1's l1: 50.6795\tvalid_1's l2: 4898\n",
      "FOLD MAE = 50.679493231575975\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 22.8621\ttraining's l2: 912.924\tvalid_1's l1: 51.8244\tvalid_1's l2: 8097.56\n",
      "Early stopping, best iteration is:\n",
      "[1208]\ttraining's l1: 28.1868\ttraining's l2: 1406.83\tvalid_1's l1: 51.1363\tvalid_1's l2: 7961.77\n",
      "FOLD MAE = 51.13626095817595\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 23.9261\ttraining's l2: 1043.72\tvalid_1's l1: 50.5497\tvalid_1's l2: 5187.06\n",
      "[4000]\ttraining's l1: 18.2643\ttraining's l2: 594.396\tvalid_1's l1: 49.5709\tvalid_1's l2: 5239.91\n",
      "Early stopping, best iteration is:\n",
      "[2787]\ttraining's l1: 21.2154\ttraining's l2: 806.142\tvalid_1's l1: 49.5693\tvalid_1's l2: 5097.27\n",
      "FOLD MAE = 49.5693030847618\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 22.8624\ttraining's l2: 1009.6\tvalid_1's l1: 42.0639\tvalid_1's l2: 2747.66\n",
      "Early stopping, best iteration is:\n",
      "[1432]\ttraining's l1: 26.4849\ttraining's l2: 1359.6\tvalid_1's l1: 41.8123\tvalid_1's l2: 2807.12\n",
      "FOLD MAE = 41.8123329309442\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 23.5997\ttraining's l2: 1057.36\tvalid_1's l1: 44.7319\tvalid_1's l2: 3461.86\n",
      "Early stopping, best iteration is:\n",
      "[1794]\ttraining's l1: 24.7718\ttraining's l2: 1161.73\tvalid_1's l1: 44.489\tvalid_1's l2: 3415.63\n",
      "FOLD MAE = 44.48902637621788\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 23.4327\ttraining's l2: 1047.19\tvalid_1's l1: 36.9406\tvalid_1's l2: 2306.95\n",
      "Early stopping, best iteration is:\n",
      "[843]\ttraining's l1: 32.5129\ttraining's l2: 2007.82\tvalid_1's l1: 37.3924\tvalid_1's l2: 2155.58\n",
      "FOLD MAE = 37.39237492007642\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 23.2147\ttraining's l2: 1029.14\tvalid_1's l1: 45.174\tvalid_1's l2: 4092.82\n",
      "[4000]\ttraining's l1: 16.617\ttraining's l2: 512.411\tvalid_1's l1: 45.4222\tvalid_1's l2: 4057.56\n",
      "Early stopping, best iteration is:\n",
      "[2810]\ttraining's l1: 20.1561\ttraining's l2: 769.509\tvalid_1's l1: 45.0794\tvalid_1's l2: 4108.27\n",
      "FOLD MAE = 45.07936956288431\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 23.0133\ttraining's l2: 1008.8\tvalid_1's l1: 40.1536\tvalid_1's l2: 2342.76\n",
      "Early stopping, best iteration is:\n",
      "[1623]\ttraining's l1: 25.477\ttraining's l2: 1249.68\tvalid_1's l1: 39.9911\tvalid_1's l2: 2350.75\n",
      "FOLD MAE = 39.99111065298905\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 23.8596\ttraining's l2: 1099.82\tvalid_1's l1: 50.403\tvalid_1's l2: 4209.83\n",
      "Early stopping, best iteration is:\n",
      "[554]\ttraining's l1: 36.9213\ttraining's l2: 2605.81\tvalid_1's l1: 47.6632\tvalid_1's l2: 3976.69\n",
      "FOLD MAE = 47.66322552946445\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 25.0363\ttraining's l2: 1203.08\tvalid_1's l1: 45.0554\tvalid_1's l2: 4638.98\n",
      "Early stopping, best iteration is:\n",
      "[1187]\ttraining's l1: 29.6856\ttraining's l2: 1668.86\tvalid_1's l1: 44.7204\tvalid_1's l2: 4685.24\n",
      "FOLD MAE = 44.720420655746615\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 23.1141\ttraining's l2: 996.8\tvalid_1's l1: 43.0014\tvalid_1's l2: 4536.39\n",
      "Early stopping, best iteration is:\n",
      "[807]\ttraining's l1: 32.6258\ttraining's l2: 2016.37\tvalid_1's l1: 42.197\tvalid_1's l2: 4764.83\n",
      "FOLD MAE = 42.19702614581629\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 23.2852\ttraining's l2: 1004.75\tvalid_1's l1: 40.8685\tvalid_1's l2: 3386.4\n",
      "Early stopping, best iteration is:\n",
      "[868]\ttraining's l1: 32.4215\ttraining's l2: 2008.6\tvalid_1's l1: 40.6394\tvalid_1's l2: 3216.45\n",
      "FOLD MAE = 40.63936511272871\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 24.2436\ttraining's l2: 1137.1\tvalid_1's l1: 49.3233\tvalid_1's l2: 4226.26\n",
      "Early stopping, best iteration is:\n",
      "[1141]\ttraining's l1: 28.9706\ttraining's l2: 1626.28\tvalid_1's l1: 48.6337\tvalid_1's l2: 4154.85\n",
      "FOLD MAE = 48.6337232499136\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 23.453\ttraining's l2: 1045.37\tvalid_1's l1: 44.6021\tvalid_1's l2: 3410.6\n",
      "Early stopping, best iteration is:\n",
      "[673]\ttraining's l1: 34.5485\ttraining's l2: 2287.69\tvalid_1's l1: 43.7615\tvalid_1's l2: 3338.98\n",
      "FOLD MAE = 43.76152098401565\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[2000]\ttraining's l1: 23.7513\ttraining's l2: 1091.28\tvalid_1's l1: 40.2197\tvalid_1's l2: 2485.36\n",
      "Early stopping, best iteration is:\n",
      "[438]\ttraining's l1: 39.2205\ttraining's l2: 2961.88\tvalid_1's l1: 38.3022\tvalid_1's l2: 2385.79\n",
      "FOLD MAE = 38.302200654132704\n",
      "\n",
      "LGBMRegressor MAE = 44.4044502699629\n"
     ]
    }
   ],
   "source": [
    "lgbm_pred_2 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X2):\n",
    "    tr_x, val_x = X2.iloc[tr_idx], X2.iloc[val_idx]\n",
    "    tr_y, val_y = y2.iloc[tr_idx], y2.iloc[val_idx]\n",
    "    \n",
    "    lgbm.fit(tr_x, tr_y, eval_set = [(tr_x, tr_y), (val_x, val_y)], eval_metric = 'mean_absolute_error', early_stopping_rounds = 2000, verbose = 2000)\n",
    "    pred = lgbm.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    mae_list.append(mae)\n",
    "    sub_pred = lgbm.predict(target2) / 15\n",
    "    lgbm_pred_2 += sub_pred\n",
    "print(f'\\n{lgbm.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['중식계'] = lgbm_pred_1\n",
    "sub['석식계'] = lgbm_pred_2\n",
    "\n",
    "sub.to_csv('lgbm_08.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD MAE = 61.91712188759171\n",
      "FOLD MAE = 44.303112323491774\n",
      "FOLD MAE = 33.190311047148484\n",
      "FOLD MAE = 30.850593398388046\n",
      "FOLD MAE = 26.646026571636114\n",
      "FOLD MAE = 27.38376605965061\n",
      "FOLD MAE = 25.246879253695326\n",
      "FOLD MAE = 28.471729031357178\n",
      "FOLD MAE = 23.2840539862871\n",
      "FOLD MAE = 23.291399036428373\n",
      "FOLD MAE = 26.233322840723822\n",
      "FOLD MAE = 21.047706879414925\n",
      "FOLD MAE = 21.039945123209048\n",
      "FOLD MAE = 21.607567728679633\n",
      "FOLD MAE = 18.556625364518045\n",
      "\n",
      "NGBRegressor MAE = 28.871344035481346\n"
     ]
    }
   ],
   "source": [
    "ngb = NGBRegressor(n_estimators = 15000, verbose = 0, random_state = 607)\n",
    "\n",
    "ngb_pred_1 = np.zeros((target1.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X1):\n",
    "    tr_x, val_x = X1.iloc[tr_idx], X1.iloc[val_idx]\n",
    "    tr_y, val_y = y1.iloc[tr_idx], y1.iloc[val_idx]\n",
    "    ngb.fit(tr_x, tr_y, val_x, val_y, early_stopping_rounds = 2000)\n",
    "    pred = ngb.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = ngb.predict(target1) / 15\n",
    "    ngb_pred_1 += sub_pred\n",
    "print(f'\\n{ngb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD MAE = 49.38987790948225\n",
      "FOLD MAE = 26.047134006267648\n",
      "FOLD MAE = 23.08987984907987\n",
      "FOLD MAE = 18.025295456372575\n",
      "FOLD MAE = 20.574132137364202\n",
      "FOLD MAE = 15.782133997830886\n",
      "FOLD MAE = 17.360119658901173\n",
      "FOLD MAE = 14.55535028052221\n",
      "FOLD MAE = 16.628500720192783\n",
      "FOLD MAE = 14.815169452405673\n",
      "FOLD MAE = 12.378371844213797\n",
      "FOLD MAE = 12.66994999455343\n",
      "FOLD MAE = 13.411980377074281\n",
      "FOLD MAE = 14.652960751817016\n",
      "FOLD MAE = 10.980362983526803\n",
      "\n",
      "NGBRegressor MAE = 18.690747961306975\n"
     ]
    }
   ],
   "source": [
    "ngb = NGBRegressor(n_estimators = 15000, verbose = 0, random_state = 607)\n",
    "\n",
    "ngb_pred_2 = np.zeros((target2.shape[0]))\n",
    "mae_list = []\n",
    "for tr_idx, val_idx in kf.split(X2):\n",
    "    tr_x, val_x = X2.iloc[tr_idx], X2.iloc[val_idx]\n",
    "    tr_y, val_y = y2.iloc[tr_idx], y2.iloc[val_idx]\n",
    "    ngb.fit(tr_x, tr_y, val_x, val_y, early_stopping_rounds = 2000)\n",
    "    pred = ngb.predict(val_x)\n",
    "    mae = mean_absolute_error(val_y, pred)\n",
    "    mae_list.append(mae)\n",
    "    print(f'FOLD MAE = {mae}')\n",
    "    sub_pred = ngb.predict(target2) / 15\n",
    "    ngb_pred_2 += sub_pred\n",
    "print(f'\\n{ngb.__class__.__name__} MAE = {np.mean(mae_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['중식계'] = ngb_pred_1\n",
    "sub['석식계'] = ngb_pred_2\n",
    "\n",
    "sub.to_csv('nbg_08.csv', index = False)\n",
    "\n",
    "nbg=pd.read_csv('nbg_08.csv')\n",
    "lgbm=pd.read_csv('lgbm_08.csv')\n",
    "\n",
    "ensemble=nbg.copy()\n",
    "ensemble['중식계']=nbg['중식계']*0.5+lgbm['중식계']*0.5\n",
    "ensemble['석식계']=nbg['석식계']*0.5+lgbm['석식계']*0.5\n",
    "\n",
    "ensemble.to_csv('ensemble_08.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_1=pd.read_csv('ensemble_08.csv') #63.5\n",
    "ensemble_2=pd.read_csv('ensemble_07.csv') #62\n",
    "ensemble_3=pd.read_csv('sub1.csv') #66\n",
    "ensemble_all=ensemble_1.copy()\n",
    "\n",
    "ensemble_all['중식계']=ensemble_1['중식계']*0.6 + ensemble_2['중식계']*0.3 + ensemble_3['중식계']*0.1\n",
    "ensemble_all['석식계']=ensemble_1['석식계']*0.6 + ensemble_2['석식계']*0.3 + ensemble_3['석식계']*0.1\n",
    "ensemble_all.to_csv('ensemble_new.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

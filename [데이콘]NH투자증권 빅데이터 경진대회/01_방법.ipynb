{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf Version \n",
      " 2.3.0\n",
      "tf.keras Version \n",
      " 2.4.0\n"
     ]
    }
   ],
   "source": [
    "#기본 패키지\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#데이터 처리 패키지\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#시각화 패키지\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family=fm.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()) # for Windows OS user\n",
    "from matplotlib import rc \n",
    "rc('font', family='malgun gothic')\n",
    "rc('axes', unicode_minus = False)\n",
    "import seaborn as sns\n",
    "#plt.style.use('ggplot')\n",
    "\n",
    "#수학 패키지\n",
    "from scipy.stats.mstats import gmean\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "import uuid\n",
    "import random\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from itertools import combinations\n",
    "\n",
    "#머신러닝 패키지\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, LinearRegression, SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import Lasso,ElasticNet,Ridge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from vecstack import stacking, StackingTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "#딥러닝 패키지\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import * #Model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "#from keras.utils.np_utils import *\n",
    "#from tensorflow.keras.utils.vis_utils import * #model_to_dot\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras import layers\n",
    "print('tf Version \\n', tf.__version__)\n",
    "print('tf.keras Version \\n', tf.keras.__version__)\n",
    "\n",
    "import kerastuner as kt\n",
    "import datetime\n",
    "import os\n",
    "import sys, warnings\n",
    "if not sys.warnoptions: warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import shap\n",
    "\n",
    "import klib\n",
    "# Dacon plotly 그림 업로드 \n",
    "pd.options.plotting.backend = 'plotly'\n",
    "## plotly.io를 import 한 후 renderers 기본값을 꼭 \"notebook_connected\" 로 설정해주시기 바랍니다.\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus = pd.read_csv(\"open/cus_info.csv\")\n",
    "hist = pd.read_csv(\"open/stk_bnc_hist.csv\")\n",
    "iem = pd.read_csv(\"open/iem_info.csv\")\n",
    "train = pd.read_csv(\"open/stk_hld_train.csv\")\n",
    "test = pd.read_csv(\"open/stk_hld_test.csv\")\n",
    "\n",
    "submission = pd.read_csv(\"open/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. cus(10,000건): 고객 및 주거래계좌 정보\n",
    "\n",
    "- act_id: 계좌 ID\n",
    "- sex_dit_cd: 성별\n",
    "- cus_age_stn_cd: 연령대\n",
    "- ivs_icn_cd: 투자성향\n",
    "- cus_aet_stn_cd: 자산구간\n",
    "- mrz_pdt_tp_sgm_cd: 주거래상품군\n",
    "- lsg_sgm_cd: Life Style\n",
    "- tco_cus_grd_cd: 서비스 등급\n",
    "- tot_ivs_te_sgm_cd: 총 투자기간\n",
    "- mrz_btp_dit_cd: 주거래업종구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cus.columns=['계좌번호','성별','연령대','투자성향','자산구간','주거래상품군','Life_style','서비스등급','총투자기간','주거래업종구분']\n",
    "hist.columns=['계좌번호','기준일자','종목코드','잔고수량','잔고금액','주당액면가']\n",
    "iem.columns=['종목코드','종목한글명','종목업종','시가총액규모유형','시장구분']\n",
    "train.columns=['계좌번호','종목코드','매수일자','hold_d']\n",
    "test.columns=['계좌번호','종목코드','매수일자','과거보유일','submit_id','hold_d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hold_d에 0.6을 곱한 값을 과거보유일로 했을 때 영향력이 아주 강했다.\\\n",
    "타겟값을 그대로 사용하였을 때 이러한 결과가 나왔기 때문에 카테고리별로 이러한 값을 넣어주어도 과적합이 일어나지 않을 것으로 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우리가 예측해야하는 값이 뭐냐? - 바로 2020년 12월 31일 이후 살아있는 주식들이 얼마나 보유될 것인가를 예측해야한다.\n",
    "\n",
    "지금 우리에게 있는 데이터는 train 과 test 데이터가 있다.\\\n",
    "train 데이터에는 16년부터 20년 12월30일까지 종료된, 한마디로 팔아버린 주식에 대한 데이터가 있다.\\\n",
    "test 에는 20년 12월30일 이전 구매한 주식을 아직 가지고 있는 데이터가 있다.\\\n",
    "train에는 16년에 사고 16년에 판 주식도 있을 것이고 16년에 사고 20년 12월에 판 주식도 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과거보유일을 어떻게 넣어줄 것인가가 중요한 것이다!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16 년 12월 30일을 기준으로 잘라서 데이터 생성(과거보유일, hold_d 가능)\\\n",
    "17 년 12월 30일을 기준으로 잘라서 데이터 생성(과거보유일, hold_d 가능)\\\n",
    "18 년 12월 30일을 기준으로 잘라서 데이터 생성(과거보유일, hold_d 가능)\\\n",
    "19 년 12월 30일을 기준으로 잘라서 데이터 생성(과거보유일, hold_d 가능)\n",
    "\n",
    "20 년 12월 30일을 기준으로 잘라서 데이터 --> test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist['기준일자']=pd.to_datetime(hist.기준일자.astype(str))\n",
    "train['매수일자']=pd.to_datetime(train.매수일자.astype(str))\n",
    "test['매수일자']=pd.to_datetime(test.매수일자.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff 를 하기 위해 순서대로 정렬해준 것\n",
    "hist_order=hist.sort_values(by=['계좌번호','종목코드','기준일자'],ascending=True).reset_index(drop='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "고객이 특정 종목을 여러번 시작했을 경우 밑의 전처리에서 계좌번호와 종목코드로만 묶을 경우 해소되지 않는 부분을 해소하기 위한 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t=train.reset_index()\n",
    "train_t.columns=['종류별', '계좌번호', '종목코드', '매수일자', 'hold_d']\n",
    "train_t.종류별=train_t.종류별+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t=test.reset_index()\n",
    "test_t.columns=['종류별', '계좌번호', '종목코드', '매수일자', '과거보유일', 'submit_id', 'hold_d']\n",
    "test_t.drop(['과거보유일','submit_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t.종류별=test_t.종류별+681473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=pd.concat((train_t,test_t)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_order=pd.merge(hist_order,tt[['계좌번호','종목코드','매수일자','종류별']],how='left',left_on=['계좌번호','종목코드','기준일자'],right_on=['계좌번호','종목코드','매수일자'])\n",
    "hist_order.drop('매수일자',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_order['종류별']=hist_order.종류별.fillna(method='pad')\n",
    "hist=pd.merge(hist,hist_order[['계좌번호','기준일자','종목코드','종류별']],how='left',on=['계좌번호','기준일자','종목코드'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.drop(['잔고수량','잔고금액','주당액면가'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>계좌번호</th>\n",
       "      <th>기준일자</th>\n",
       "      <th>종목코드</th>\n",
       "      <th>종류별</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1119c23c3a504ca7b75060277410c0f6fb9018ec7638c2...</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>A008770</td>\n",
       "      <td>681511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1119c23c3a504ca7b75060277410c0f6fb9018ec7638c2...</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>A008770</td>\n",
       "      <td>681511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1119c23c3a504ca7b75060277410c0f6fb9018ec7638c2...</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>A005940</td>\n",
       "      <td>681510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1119c23c3a504ca7b75060277410c0f6fb9018ec7638c2...</td>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>A005930</td>\n",
       "      <td>681509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1119c23c3a504ca7b75060277410c0f6fb9018ec7638c2...</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>A005930</td>\n",
       "      <td>681509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573834</th>\n",
       "      <td>720aa28d24bfa8fbeddf4fe625cb53af0a6f7ff2d526de...</td>\n",
       "      <td>2020-08-06</td>\n",
       "      <td>A035720</td>\n",
       "      <td>680918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573835</th>\n",
       "      <td>720aa28d24bfa8fbeddf4fe625cb53af0a6f7ff2d526de...</td>\n",
       "      <td>2020-08-13</td>\n",
       "      <td>A035720</td>\n",
       "      <td>680918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573836</th>\n",
       "      <td>720aa28d24bfa8fbeddf4fe625cb53af0a6f7ff2d526de...</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>A035720</td>\n",
       "      <td>680917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573837</th>\n",
       "      <td>720aa28d24bfa8fbeddf4fe625cb53af0a6f7ff2d526de...</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>A035720</td>\n",
       "      <td>680917.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573838</th>\n",
       "      <td>720aa28d24bfa8fbeddf4fe625cb53af0a6f7ff2d526de...</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>A035720</td>\n",
       "      <td>752039.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2573839 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      계좌번호       기준일자  \\\n",
       "0        1119c23c3a504ca7b75060277410c0f6fb9018ec7638c2... 2020-08-20   \n",
       "1        1119c23c3a504ca7b75060277410c0f6fb9018ec7638c2... 2020-06-23   \n",
       "2        1119c23c3a504ca7b75060277410c0f6fb9018ec7638c2... 2016-01-04   \n",
       "3        1119c23c3a504ca7b75060277410c0f6fb9018ec7638c2... 2020-08-14   \n",
       "4        1119c23c3a504ca7b75060277410c0f6fb9018ec7638c2... 2020-06-23   \n",
       "...                                                    ...        ...   \n",
       "2573834  720aa28d24bfa8fbeddf4fe625cb53af0a6f7ff2d526de... 2020-08-06   \n",
       "2573835  720aa28d24bfa8fbeddf4fe625cb53af0a6f7ff2d526de... 2020-08-13   \n",
       "2573836  720aa28d24bfa8fbeddf4fe625cb53af0a6f7ff2d526de... 2020-08-19   \n",
       "2573837  720aa28d24bfa8fbeddf4fe625cb53af0a6f7ff2d526de... 2020-08-25   \n",
       "2573838  720aa28d24bfa8fbeddf4fe625cb53af0a6f7ff2d526de... 2020-09-01   \n",
       "\n",
       "            종목코드       종류별  \n",
       "0        A008770  681511.0  \n",
       "1        A008770  681511.0  \n",
       "2        A005940  681510.0  \n",
       "3        A005930  681509.0  \n",
       "4        A005930  681509.0  \n",
       "...          ...       ...  \n",
       "2573834  A035720  680918.0  \n",
       "2573835  A035720  680918.0  \n",
       "2573836  A035720  680917.0  \n",
       "2573837  A035720  680917.0  \n",
       "2573838  A035720  752039.0  \n",
       "\n",
       "[2573839 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_t.매수일자='2020-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist=pd.concat((hist,test_t[['계좌번호','매수일자','종목코드','종류별']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>계좌번호</th>\n",
       "      <th>종목코드</th>\n",
       "      <th>매수일자</th>\n",
       "      <th>hold_d</th>\n",
       "      <th>과거보유일</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A006360</td>\n",
       "      <td>20180726</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005930</td>\n",
       "      <td>20180131</td>\n",
       "      <td>80</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A005070</td>\n",
       "      <td>20180517</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A003520</td>\n",
       "      <td>20201112</td>\n",
       "      <td>22</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0ad104dbed99be0cd858aa772765ddedade554601a981b...</td>\n",
       "      <td>A002310</td>\n",
       "      <td>20180905</td>\n",
       "      <td>324</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681467</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A260660</td>\n",
       "      <td>20180831</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681468</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A271980</td>\n",
       "      <td>20201027</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681469</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A289080</td>\n",
       "      <td>20181121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681470</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A307930</td>\n",
       "      <td>20200214</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681471</th>\n",
       "      <td>4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...</td>\n",
       "      <td>A308100</td>\n",
       "      <td>20200116</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681472 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     계좌번호     종목코드      매수일자  \\\n",
       "0       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A006360  20180726   \n",
       "1       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005930  20180131   \n",
       "2       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A005070  20180517   \n",
       "3       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A003520  20201112   \n",
       "4       0ad104dbed99be0cd858aa772765ddedade554601a981b...  A002310  20180905   \n",
       "...                                                   ...      ...       ...   \n",
       "681467  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A260660  20180831   \n",
       "681468  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A271980  20201027   \n",
       "681469  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A289080  20181121   \n",
       "681470  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A307930  20200214   \n",
       "681471  4561928f2825f6389f228088ac807a9fb4575ffdcbc47a...  A308100  20200116   \n",
       "\n",
       "        hold_d  과거보유일  \n",
       "0           11    6.0  \n",
       "1           80   48.0  \n",
       "2            5    3.0  \n",
       "3           22   13.0  \n",
       "4          324  194.0  \n",
       "...        ...    ...  \n",
       "681467       1    0.0  \n",
       "681468       1    0.0  \n",
       "681469       1    0.0  \n",
       "681470       1    0.0  \n",
       "681471       1    0.0  \n",
       "\n",
       "[681472 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train\n",
    "# 과거보유일이 주식보유기간과 어떤 관련이 있는지 과거보유일에 대한 피처를 만들 때 근거있는 식을 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"과거보유일\"] = train[\"hold_d\"]*0.6\n",
    "train.과거보유일 = np.trunc(train[\"과거보유일\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train과 test에 고객정보(cus_info)와 주식정보(iem_info)를 추가하겠습니다.\n",
    "\n",
    "train_data = pd.merge(train, cus, how = \"left\", on = [\"계좌번호\"])\n",
    "train_data = pd.merge(train_data, iem, how = \"left\", on = [\"종목코드\"])\n",
    "\n",
    "test_data = pd.merge(test, cus, how = \"left\", on = [\"계좌번호\"])\n",
    "test_data = pd.merge(test_data, iem, how = \"left\", on = [\"종목코드\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가적으로 약간의 전처리를 통해 train data와 test data를 구성하겠습니다.\n",
    "\n",
    "hist[\"평균잔고금액\"] = hist[\"잔고금액\"] / hist[\"잔고수량\"]\n",
    "hist = hist.fillna(0)\n",
    "\n",
    "train_data = pd.merge(train_data, hist, how = \"left\", left_on = [\"계좌번호\", \"종목코드\",'매수일자'],right_on=['계좌번호','종목코드','기준일자'])\n",
    "train_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "test_data = pd.merge(test_data, hist, how = \"left\",  left_on= [\"계좌번호\", \"종목코드\",'매수일자'],right_on=['계좌번호','종목코드','기준일자'])\n",
    "test_data.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 681472 entries, 0 to 681471\n",
      "Data columns (total 23 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   계좌번호        681472 non-null  object \n",
      " 1   종목코드        681472 non-null  object \n",
      " 2   매수일자        681472 non-null  int64  \n",
      " 3   hold_d      681472 non-null  int64  \n",
      " 4   과거보유일       681472 non-null  float64\n",
      " 5   성별          681472 non-null  int64  \n",
      " 6   연령대         681472 non-null  int64  \n",
      " 7   투자성향        681472 non-null  int64  \n",
      " 8   자산구간        681472 non-null  int64  \n",
      " 9   주거래상품군      681472 non-null  int64  \n",
      " 10  Life_style  681472 non-null  int64  \n",
      " 11  서비스등급       681472 non-null  int64  \n",
      " 12  총투자기간       681472 non-null  int64  \n",
      " 13  주거래업종구분     681472 non-null  int64  \n",
      " 14  종목한글명       681472 non-null  object \n",
      " 15  종목업종        681472 non-null  int64  \n",
      " 16  시가총액규모유형    681472 non-null  int64  \n",
      " 17  시장구분        681472 non-null  int64  \n",
      " 18  기준일자        681472 non-null  int64  \n",
      " 19  잔고수량        681472 non-null  float64\n",
      " 20  잔고금액        681472 non-null  float64\n",
      " 21  주당액면가       681472 non-null  float64\n",
      " 22  평균잔고금액      681472 non-null  float64\n",
      "dtypes: float64(5), int64(15), object(3)\n",
      "memory usage: 119.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 성별 - 그대로 넣기\n",
    "2. 연령 - 그대로 넣기\n",
    "3. 투자성향 - 99를 0으로 바꿔주기\n",
    "4. 자산구간 - 자신의 총자산 금액 구간별 코드 - 투자성향과 합쳐서 워드투백터(일단은 곱으로 해결했음)\n",
    "5. 주거래상품군 - 대부분이 2(국내상품) 이다. \n",
    "6. Life_style - 나이와 성별 직종을 묶어 나타낸 것이다. 이를 오히려 나이와 성별까지 더해서 구분하면 좋을 것으로 보인다.\n",
    "7. 서비스등급 - 자산구간과 역수라고 생각하면 된다.\n",
    "8. 총투자기간 - hold_d와 연관성이 가장 높다고 생각한다.\n",
    "9. 주거래업종구분 - 제조가 많고 mean_encoding을 해도 괜찮을 것으로 보인다.\n",
    "10. 종목한글명 + 11. 종목업종 - 종목업종 별 종목 중 가장 많은 종목에 투자를 하였는지를 확인하기 위해 mode를 이용하여 사용\n",
    "11. 시가총액규모유형 - 어떻게 사용해야할지 모르겠다\n",
    "12. 시장구분 - 이 또한 어떻게 사용해야할지 모르겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWAzsEecM4wW"
   },
   "source": [
    "# 수치형 변수 분포확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['매수일자']=pd.to_datetime(train_data.매수일자.astype(str))\n",
    "test_data['매수일자']=pd.to_datetime(test_data.매수일자.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['년']=train_data.매수일자.dt.year\n",
    "train_data['월']=train_data.매수일자.dt.month\n",
    "train_data['일']=train_data.매수일자.dt.day\n",
    "train_data['요일']=train_data.매수일자.dt.day_of_week\n",
    "\n",
    "test_data['년']=test_data.매수일자.dt.year\n",
    "test_data['월']=test_data.매수일자.dt.month\n",
    "test_data['일']=test_data.매수일자.dt.day\n",
    "test_data['요일']=test_data.매수일자.dt.day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test=pd.concat([train_data,test_data])\n",
    "train_test=train_test.reset_index(drop='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "년\n",
      "2016    20.0\n",
      "2017     8.0\n",
      "2018     8.0\n",
      "2019     6.0\n",
      "2020     5.0\n",
      "Name: 잔고수량, dtype: float64\n",
      "년\n",
      "2016    122.0\n",
      "2017     30.0\n",
      "2018     30.0\n",
      "2019     32.0\n",
      "2020     25.0\n",
      "Name: 잔고수량, dtype: float64\n",
      "년\n",
      "2016    400.0\n",
      "2017    100.0\n",
      "2018    100.0\n",
      "2019    110.0\n",
      "2020    100.0\n",
      "Name: 잔고수량, dtype: float64\n",
      "년\n",
      "2016    1247.6\n",
      "2017     500.0\n",
      "2018     400.0\n",
      "2019     466.0\n",
      "2020     300.0\n",
      "Name: 잔고수량, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.2,1,0.2):\n",
    "    print(train_test.groupby('년').잔고수량.quantile(q=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 년도별 잔고수량 평균 이상 이하\n",
    "def f_2016(x):\n",
    "    if x<20:\n",
    "        return 0\n",
    "    elif x<122:\n",
    "        return 1\n",
    "    elif x<400:\n",
    "        return 2\n",
    "    elif x<1247:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "def f_2017(x):\n",
    "    if x<8:\n",
    "        return 0\n",
    "    elif x<30:\n",
    "        return 1\n",
    "    elif x<100:\n",
    "        return 2\n",
    "    elif x<500:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "def f_2018(x):\n",
    "    if x<8:\n",
    "        return 0\n",
    "    elif x<30:\n",
    "        return 1\n",
    "    elif x<100:\n",
    "        return 2\n",
    "    elif x<400:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "def f_2019(x):\n",
    "    if x<6:\n",
    "        return 0\n",
    "    elif x<32:\n",
    "        return 1\n",
    "    elif x<110:\n",
    "        return 2\n",
    "    elif x<466:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "def f_2020(x):\n",
    "    if x<5:\n",
    "        return 0\n",
    "    elif x<25:\n",
    "        return 1\n",
    "    elif x<100:\n",
    "        return 2\n",
    "    elif x<300:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['년도_잔고수량']=0\n",
    "train_data.loc[train_data.년==2016,'년도_잔고수량']=train_data.query('년==2016')['잔고수량'].apply(f_2016)\n",
    "train_data.loc[train_data.년==2017,'년도_잔고수량']=train_data.query('년==2017')['잔고수량'].apply(f_2017)\n",
    "train_data.loc[train_data.년==2018,'년도_잔고수량']=train_data.query('년==2018')['잔고수량'].apply(f_2018)\n",
    "train_data.loc[train_data.년==2019,'년도_잔고수량']=train_data.query('년==2019')['잔고수량'].apply(f_2019)\n",
    "train_data.loc[train_data.년==2020,'년도_잔고수량']=train_data.query('년==2020')['잔고수량'].apply(f_2020)\n",
    "\n",
    "test_data['년도_잔고수량']=0\n",
    "test_data.loc[test_data.년==2016,'년도_잔고수량']=test_data.query('년==2016')['잔고수량'].apply(f_2016)\n",
    "test_data.loc[test_data.년==2017,'년도_잔고수량']=test_data.query('년==2017')['잔고수량'].apply(f_2017)\n",
    "test_data.loc[test_data.년==2018,'년도_잔고수량']=test_data.query('년==2018')['잔고수량'].apply(f_2018)\n",
    "test_data.loc[test_data.년==2019,'년도_잔고수량']=test_data.query('년==2019')['잔고수량'].apply(f_2019)\n",
    "test_data.loc[test_data.년==2020,'년도_잔고수량']=test_data.query('년==2020')['잔고수량'].apply(f_2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "년\n",
       "2016    5.182650\n",
       "2017    4.162498\n",
       "2018    3.539667\n",
       "2019    3.324126\n",
       "2020    2.832396\n",
       "Name: 총투자기간, dtype: float64"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test.groupby('년').총투자기간.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 년도별 총투자기간 평균 이상 이하\n",
    "def g_2016(x):\n",
    "    if x>5.182650:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def g_2017(x):\n",
    "    if x>4.162498:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def g_2018(x):\n",
    "    if x>3.539667:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def g_2019(x):\n",
    "    if x>3.324126:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "def g_2020(x):\n",
    "    if x>2.832396:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['년도_총투자기간']=0\n",
    "train_data.loc[train_data.년==2016,'년도_총투자기간']=train_data.query('년==2016')['총투자기간'].apply(g_2016)\n",
    "train_data.loc[train_data.년==2017,'년도_총투자기간']=train_data.query('년==2017')['총투자기간'].apply(g_2017)\n",
    "train_data.loc[train_data.년==2018,'년도_총투자기간']=train_data.query('년==2018')['총투자기간'].apply(g_2018)\n",
    "train_data.loc[train_data.년==2019,'년도_총투자기간']=train_data.query('년==2019')['총투자기간'].apply(g_2019)\n",
    "train_data.loc[train_data.년==2020,'년도_총투자기간']=train_data.query('년==2020')['총투자기간'].apply(g_2020)\n",
    "\n",
    "test_data['년도_총투자기간']=0\n",
    "test_data.loc[test_data.년==2016,'년도_총투자기간']=test_data.query('년==2016')['총투자기간'].apply(g_2016)\n",
    "test_data.loc[test_data.년==2017,'년도_총투자기간']=test_data.query('년==2017')['총투자기간'].apply(g_2017)\n",
    "test_data.loc[test_data.년==2018,'년도_총투자기간']=test_data.query('년==2018')['총투자기간'].apply(g_2018)\n",
    "test_data.loc[test_data.년==2019,'년도_총투자기간']=test_data.query('년==2019')['총투자기간'].apply(g_2019)\n",
    "test_data.loc[test_data.년==2020,'년도_총투자기간']=test_data.query('년==2020')['총투자기간'].apply(g_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "train_data['금액변화']=train_data.평균잔고금액-train_data.주당액면가\n",
    "test_data['금액변화']=test_data.평균잔고금액-test_data.주당액면가\n",
    "\n",
    "#\n",
    "train_data['금액변화비율']=train_data.평균잔고금액/train_data.주당액면가\n",
    "test_data['금액변화비율']=test_data.평균잔고금액/test_data.주당액면가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매수를 몇번 했는지\n",
    "train_data=pd.merge(train_data,train_test.groupby('계좌번호')['년'].agg([('매수횟수',np.size)]).reset_index(),how='left',on='계좌번호')\n",
    "test_data=pd.merge(test_data,train_test.groupby('계좌번호')['년'].agg([('매수횟수',np.size)]).reset_index(),how='left',on='계좌번호')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종목업종 별 보유기간이 어떻게 되는지 (총자산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 고객별 주 종목업종이 어떤것인지 파악을 한다.\n",
    "고객_종목업종=train_test.groupby('계좌번호')['종목업종'].agg([('고객별_종목업종', lambda x: x.mode()[0])]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.merge(train_data,고객_종목업종,how='left',on='계좌번호')\n",
    "test_data=pd.merge(test_data,고객_종목업종,how='left',on='계좌번호')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종목업종 별 hold_d 값의 평균을 넣어준 것\n",
    "train_data=pd.merge(train_data,train_data.groupby('고객별_종목업종')['hold_d'].agg([('고객별_종목_hold',np.mean)]).reset_index(),how='left',on='고객별_종목업종')\n",
    "test_data=pd.merge(test_data,train_data.groupby('고객별_종목업종')['hold_d'].agg([('고객별_종목_hold',np.mean)]).reset_index(),how='left',on='고객별_종목업종')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 681472 entries, 0 to 681471\n",
      "Data columns (total 33 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   계좌번호         681472 non-null  object        \n",
      " 1   종목코드         681472 non-null  object        \n",
      " 2   매수일자         681472 non-null  datetime64[ns]\n",
      " 3   hold_d       681472 non-null  int64         \n",
      " 4   성별           681472 non-null  int64         \n",
      " 5   연령대          681472 non-null  int64         \n",
      " 6   투자성향         681472 non-null  int64         \n",
      " 7   자산구간         681472 non-null  int64         \n",
      " 8   주거래상품군       681472 non-null  int64         \n",
      " 9   Life_style   681472 non-null  int64         \n",
      " 10  서비스등급        681472 non-null  int64         \n",
      " 11  총투자기간        681472 non-null  int64         \n",
      " 12  주거래업종구분      681472 non-null  int64         \n",
      " 13  종목한글명        681472 non-null  object        \n",
      " 14  종목업종         681472 non-null  int64         \n",
      " 15  시가총액규모유형     681472 non-null  int64         \n",
      " 16  시장구분         681472 non-null  int64         \n",
      " 17  기준일자         681472 non-null  int64         \n",
      " 18  잔고수량         681472 non-null  float64       \n",
      " 19  잔고금액         681472 non-null  float64       \n",
      " 20  주당액면가        681472 non-null  float64       \n",
      " 21  평균잔고금액       681472 non-null  float64       \n",
      " 22  년            681472 non-null  int64         \n",
      " 23  월            681472 non-null  int64         \n",
      " 24  일            681472 non-null  int64         \n",
      " 25  요일           681472 non-null  int64         \n",
      " 26  년도_잔고수량      681472 non-null  int64         \n",
      " 27  년도_총투자기간     681472 non-null  int64         \n",
      " 28  금액변화         681472 non-null  float64       \n",
      " 29  금액변화비율       681472 non-null  float64       \n",
      " 30  매수횟수         681472 non-null  int64         \n",
      " 31  고객별_종목업종     681472 non-null  int64         \n",
      " 32  고객별_종목_hold  681472 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(7), int64(22), object(3)\n",
      "memory usage: 192.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70596 entries, 0 to 70595\n",
      "Data columns (total 35 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   계좌번호         70596 non-null  object        \n",
      " 1   종목코드         70596 non-null  object        \n",
      " 2   매수일자         70596 non-null  datetime64[ns]\n",
      " 3   과거보유일        70596 non-null  int64         \n",
      " 4   submit_id    70596 non-null  object        \n",
      " 5   hold_d       70596 non-null  int64         \n",
      " 6   성별           70596 non-null  int64         \n",
      " 7   연령대          70596 non-null  int64         \n",
      " 8   투자성향         70596 non-null  int64         \n",
      " 9   자산구간         70596 non-null  int64         \n",
      " 10  주거래상품군       70596 non-null  int64         \n",
      " 11  Life_style   70596 non-null  int64         \n",
      " 12  서비스등급        70596 non-null  int64         \n",
      " 13  총투자기간        70596 non-null  int64         \n",
      " 14  주거래업종구분      70596 non-null  int64         \n",
      " 15  종목한글명        70596 non-null  object        \n",
      " 16  종목업종         70596 non-null  int64         \n",
      " 17  시가총액규모유형     70596 non-null  int64         \n",
      " 18  시장구분         70596 non-null  int64         \n",
      " 19  기준일자         70596 non-null  int64         \n",
      " 20  잔고수량         70596 non-null  float64       \n",
      " 21  잔고금액         70596 non-null  float64       \n",
      " 22  주당액면가        70596 non-null  float64       \n",
      " 23  평균잔고금액       70596 non-null  float64       \n",
      " 24  년            70596 non-null  int64         \n",
      " 25  월            70596 non-null  int64         \n",
      " 26  일            70596 non-null  int64         \n",
      " 27  요일           70596 non-null  int64         \n",
      " 28  년도_잔고수량      70596 non-null  int64         \n",
      " 29  년도_총투자기간     70596 non-null  int64         \n",
      " 30  금액변화         70596 non-null  float64       \n",
      " 31  금액변화비율       70596 non-null  float64       \n",
      " 32  매수횟수         70596 non-null  int64         \n",
      " 33  고객별_종목업종     70596 non-null  int64         \n",
      " 34  고객별_종목_hold  70596 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(7), int64(23), object(4)\n",
      "memory usage: 19.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "투자성향\n",
       "0     2.974824\n",
       "1     2.079632\n",
       "2     2.494175\n",
       "3     2.743414\n",
       "4     3.069208\n",
       "5     3.557083\n",
       "9     6.000000\n",
       "99    2.483282\n",
       "Name: 자산구간, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('투자성향')['자산구간'].mean()\n",
    "# 투자성향이 전문투자가형이 자산이 상당히 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['투자성형_자산구간']=train_data.투자성향*train_data.자산구간\n",
    "\n",
    "test_data['투자성형_자산구간']=test_data.투자성향*test_data.자산구간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['국내주식']=train_data.주거래상품군.apply(lambda x: 1 if x==2 else 0)\n",
    "\n",
    "test_data['국내주식']=test_data.주거래상품군.apply(lambda x: 1 if x==2 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Life_style\n",
    "- 나이와 성별 직종을 묶어 나타낸 것. 이를 오히려 나이와 성별까지 더해서 구분하면 좋을 것으로 보인다.\n",
    "- Life_style 은 대체로 5이상이 hold_d가 높다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['나이_직종']=train_data.Life_style*train_data.연령대\n",
    "\n",
    "test_data['나이_직종']=test_data.Life_style*test_data.연령대"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "서비스등급\n",
    "- 자산구간의 역수라고 생각"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEZCAYAAABfKbiYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkRUlEQVR4nO3df1RU953/8ecMMIIwg8shxFBgu4kS3Fq3u4shKa6bTWetJ9vYH3E5rlGSZgMhkbVn46ZdjvEHaexSW9zGdGtOJZEgcWlycpI1etY0k93UVsvSAGrSTAJmaxAIqRziwAwCA3e+f/h1ViLIgJcZRl+PczyH+7nvy33fORdfc3/MHUsgEAggIiJiAmukGxARkauHQkVEREyjUBEREdMoVERExDQKFRERMY1CRWSKHn/8cTo6Oia1TG1tLUePHp2mjkQiT6EiMkXPPvssZ86cmdQyhw4d4sSJE6b2kZOTg91uZ86cOWP+Ky8vH3O5HTt2kJSUNO4/m81map9ybVCoiFzG008/zX333RdS7ZIlSzh06NCosQMHDnD77bdPer0PPvggW7ZsCbn+9ddf5+zZs2P+G+/3PPLII3i93jH/tbW1YbXqvweZvNhINyAil3rnnXfo6emJ2PoNwyAuLi5i65fopbciIpfh8XjweDxhXefLL7/M0NAQb7/9dsSuvwwODhIfHx+RdUt005GKyGW0tLTgdruB8+/eV69eHZw31vWUbdu2UVVVFZzu6uoiNjb0P7MXX3yRjRs3cvDgQfr6+li9ejU7d+5k2bJl4y6TmJiI0+kcd/7Xv/519u7dG3IPAL29vdjt9kktIwIKFZFxnTt3jgMHDhATE0NDQwO33HILpaWlwfm/+MUvLlnm7rvv5tZbbw1OHzlyhFdfffWy6zEMgyNHjrBr1y5OnTqFy+UiKysLgP3797NmzRp+9rOfUVRURF5eHhaLZdTyjY2Nk9qub3/72/z0pz+9bM3IyAj9/f3MmTMHgLNnz05qHXLtUqiIjGPXrl3cfvvt3HHHHTz22GMcOnSIJUuWBOfPmjXrkmVycnJGhUp3d/eEoVJZWckLL7zAww8/zH333TcqNLKzs6mvr6e6upqHH36YRx55hDVr1gCQkZGB1+sNeXtWr17NT37yE7Zv38727dtDXk5kMhQqImNoamrihz/8IW+99RY33HADL730Eps2bWLbtm2mr+vRRx/l0UcfHXe+1Wrl/vvv5/777x813t7efkXrbWpq4qOPPuJv/uZvLpnn8XjYu3fvqCMzkVAoVEQ+5Ze//CWrV69m3759pKenA+evdfzlX/4lXV1d/OQnPxnzKAXglVde4b333gtOv/vuu9Pe79DQEHv37uWVV16hra0Nr9dLamoqn/vc57jvvvtYunTpmMsdPXqUt956a8xQ+eSTT3jiiScUKjJpChWRT9mzZw/PPffcqM+XJCcn89///d98//vfH/fzGw899BCnT59mYGAgOHbjjTdO6XMqk/G1r30Ni8XCxo0b+eM//mMSExPp6enhF7/4BWvWrGHr1q2XHOVcUFdXx4EDBy4ZNwxDH36UKVGoiHzKs88+O+b4H/zBH1BRUTHucvfcc8+k17V//34KCwsntcyBAweC13Z8Ph//+Z//yenTp8nIyAjWXH/99RQUFNDR0cGLL744bqisWrWK6urqS8ZPnTo16tqQSKgUKiIRtGLFiiu6syoxMZG8vDw2bdrE448/TmZmJgCBQID6+np27949bqCITAeFikiUO3ToEE8++SR33XUXn3zyCYZhEBsby7x589i4ceNlj6D27dvHK6+8csm4YRjMnj17GruWq5VF31EvIiJm0WNaRETENAoVERExjUJFRERMo1ARERHTXPN3f3V2dka6BRGRqHLhSRNjmfZQ8fl87N69m7NnzxIIBFi3bh3Dw8NUVVXh9/vJzs5m7dq1wPlP97rdbgzDoLi4mMzMTDo7O6+4VkREwmPaQ2VwcJDCwkJSUlJoampi//79/P73v6ekpIS0tDR27NhBa2srw8PDeDweysvLaWtro7a2lrKyMqqrq6+odv78+dO9iSIi8v9Ne6ikpKQEf05MTCQuLg6/309aWhoAeXl5tLS00NfXR35+PgBZWVl4vV5GRkauuFahIiISPmG7ptLT08Orr77K/fffz549e4Ljdrudjo4Oent7cTgcwXGr1YrH4yEpKemKaj/N5XLhcrkAqKioIDU11dTtFBG5loUlVBobG2lsbOTBBx9k1qxZ9Pf3B+d5vV4cDgdDQ0P4fL7guNVqJSkp6YprP83pdI766tXu7m7TtlNE5FpwuQv1035L8YcffkhjYyPFxcXY7XZsNht+v5+enh4AGhoaWLhwITk5OdTX1wPnv3woJSXFlFoREQmfaX/213/8x3/w5ptvkpycDEBqairLly9nz549xMXFkZuby1e+8hUMw+CZZ57h9OnTJCQkUFRURGpqKidPnryi2onolmIRkcm53JHKNf9ASYWKiMjkRPT0l4iIXDuu+U/Ui5hl586dkW5hXOvXr490C3KN0JGKiIiYRkcqIgKA1V0Z6RbGZSzYEOkWJEQ6UhEREdMoVERExDQKFRERMY1CRURETKNQERER0yhURETENAoVERExjUJFRERMo1ARERHTKFRERMQ0ChURETGNQkVEREyjUBEREdMoVERExDQKFRERMc20f59Kb28vBw8exGKx8LWvfY2KiorgvO7ubu68807uvPNONmzYgN1uB8DpdLJkyRI6OzupqqrC7/eTnZ3N2rVrAairq8PtdmMYBsXFxWRmZo5bKyIi4TPtoVJTU8PcuXMZHBwkPj6erVu3AmAYBv/yL//CHXfcAcCcOXPYtGnTqGWrq6spKSkhLS2NHTt20NrayvDwMB6Ph/Lyctra2qitraWsrGzM2vnz50/35omIyEWmPVRKS0v57W9/y7Fjx0aNHz16lD/90z8lPj4eAIvFMmr+yMgIfr+ftLQ0APLy8mhpaaGvr4/8/HwAsrKy8Hq949aOFSoulwuXywVARUUFqamppm6vyEwUyn7eE4Y+pkp/p9EjYl8n/MYbb/Cd73wHgIGBAT7++GO2bNlCcnIyhYWFxMTEkJSUFKy32+10dHTQ29uLw+EIjlutVjwez5i1Y3E6nTidzuB0d3e32ZsmMuOEsp/P5Aus+judWdLT08edF5FQaW1tJTMzM3iUEh8fz1NPPQXAiRMnqKmpobS0lP7+/uAyXq8Xh8PB0NAQPp8vOG61WklKShqzVkREwisib05+9atfcdtttwWnDcMI/nwhDGw2G36/n56e8wflDQ0NLFy4kJycHOrr6wFob28nJSVl3FoREQmviByptLS0sGbNmuB0V1cXu3btIjY2ltjYWB544AEACgsLqaysJC4ujtzcXDIyMkhPT6e5uZnNmzeTkJBAUVHRuLUiIhJelkAgEIh0E5HU2dkZ6RbkKrFz585ItzCu9evXT1hjdVeGoZOpMRZsiHQLcpHLXVOZydfmREQkyihURETENAoVERExjUJFRERMo1ARERHTKFRERMQ0ChURETGNQkVEREyjUBEREdMoVERExDQKFRERMY1CRURETKNQERER0yhURETENAoVERExjUJFRERMo1ARERHTKFRERMQ00/4d9b29vRw8eBCLxcKqVas4fPgwL7/8MsnJycTGxvLYY48BUFdXh9vtxjAMiouLyczMpLOzk6qqKvx+P9nZ2axdu3bStSIiEj7THio1NTXMnTuXwcFBAHw+H6tXr2bx4sXBGrfbjcfjoby8nLa2NmpraykrK6O6upqSkhLS0tLYsWMHra2tDA8Ph1w7f/786d48ERG5yLSf/iotLWXBggXBaZ/PR2Ji4qia48ePk5+fD0BWVhZer5eRkRH8fj9paWkA5OXl0dLSMqlaEREJr2k/Uvk0wzB4/vnniYmJYenSpTidTnp7e3E4HMEaq9WKx+MhKSkpOGa32+no6JhU7VhcLhculwuAiooKUlNTzd5EkRknlP28Jwx9TJX+TqNH2EOloKCAgoICBgcH2b59OzfffDOzZ8/G5/MFa6xWK0lJSfT39wfHvF4vDoeDoaGhkGvH4nQ6cTqdwenu7m4zN09kRgplP5/Jd+3o73RmSU9PH3de2PejkZERAGw2GwkJCVgsFnJycqivrwegvb2dlJQUbDYbfr+fnp7z758aGhpYuHDhpGpFRCS8wn6ksm/fPk6ePIlhGCxevJiMjAzS09Npbm5m8+bNJCQkUFRUBEBhYSGVlZXExcWRm5s76VoREQkvSyAQCES6iUjq7OyMdAtyldi5c2ekWxjX+vXrJ6yxuivD0MnUGAs2RLoFuciMOv0lIiJXL4WKiIiYRqEiIiKmUaiIiIhpFCoiImIahYqIiJhGoSIiIqZRqIiIiGkUKiIiYhqFioiImEahIiIiplGoiIiIaRQqIiJiGoWKiIiYRqEiIiKmUaiIiIhpFCoiImIahYqIiJhGoSIiIqaJne4V9Pb2cvDgQSwWC6tWreLIkSO8/vrrDAwMkJeXx9e//nUANmzYgN1uB8DpdLJkyRI6OzupqqrC7/eTnZ3N2rVrAairq8PtdmMYBsXFxWRmZo5bKyIi4TPtoVJTU8PcuXMZHBwEYO7cuWzduhXDMNi0aRNf+tKXcDgczJkzh02bNo1atrq6mpKSEtLS0tixYwetra0MDw/j8XgoLy+nra2N2tpaysrKxqydP3/+dG+eiIhcZNpPf5WWlrJgwYLg9E033XR+xVYrSUlJxMaezzWLxTJquZGREfx+P2lpaQDk5eXR0tLC8ePHyc/PByArKwuv1zturYiIhNe0H6mM57XXXmPBggXMnj2bgYEBPv74Y7Zs2UJycjKFhYXExMSQlJQUrLfb7XR0dNDb24vD4QiOW61WPB7PmLVjcblcuFwuACoqKkhNTZ2mLZSpeP7ZtyPdwpjuuf/zkW7hioSyn/eEoY+pCqX/J/evCkMnk/etFXWRbiGswh4q586dY+/evSxatIgvf/nLAMTHx/PUU08BcOLECWpqaigtLaW/vz+4nNfrxeFwMDQ0hM/nC45fOOIZq3YsTqcTp9MZnO7u7jZ1++TqFO37SSj9z+S7dqL59Y/m3seTnp4+7ryw70fPPPMMX/nKV7j11luDY4ZhBH++EAY2mw2/309Pz/n3Tw0NDSxcuJCcnBzq6+sBaG9vJyUlZdxaEREJr7AfqTQ1NY1K7pUrV5KSksKuXbuIjY0lNjaWBx54AIDCwkIqKyuJi4sjNzeXjIwM0tPTaW5uZvPmzSQkJFBUVDRurYiIhJclEAgEIt1EJHV2dka6BbnIa/s/inQLY/ryihsmrNm5c2cYOpma9evXT1hjdVeGoZOpMRZsmLDm+aOlYehk8u754o8j3YLpZtTpLxERuXopVERExDQKFRERMY1CRURETKNQERER0yhURETENCGHynPPPXfJWG1tranNiIhIdJvww49nzpyhv7+f9957j7a2Ni58rKW/v5+mpibWrFkz7U2KiEh0mDBUmpub+fWvf01XVxd79uwJjttsNgoKCqa1ORERiS4ThsqyZctYtmwZTz/9NCUlJeHoSUREolTIz/66ECgDAwOjHgA5e/Zs87sSEZGoFHKo1NfX8+yzz2K1WomJiQHOf7HWj3989T3XRkREpibkUPnZz35GeXk5N9ww8YP1RETk2hTyLcUpKSkKFBERuayQQ2Xx4sX8z//8z3T2IiIiUW5Sp7/6+/ux2WzExv7fYhffZiwiIte2kENF4SEiIhPRs79ERMQ0IR+pfPOb3xxzXEcwIiJywZROf/n9fo4cOUJfX9+Ey/X29nLw4EEsFgurVq2is7OTqqoq/H4/2dnZrF27FoC6ujrcbjeGYVBcXExmZqYptSIiEj5TOv0VFxfH7bffzrFjxyasrampIS4ujpGREQCqq6spKSnhu9/9LmfOnKG1tRW3243H46G8vJyioqLg04+vtFZERMIr5COVT+vp6eHs2bMT1pWWlvLb3/6WY8eOMTIygt/vJy0tDYC8vDxaWlro6+sjPz8fgKysLLxerym18+fPv6Qfl8uFy+UCoKKigtTU1Km+BDItPop0A2OK9v0klP57wtDHVEXz6x/NvU9FyKHy7W9/G4vFAsDw8DAej4d77713Uivr7e0lKSkpOG232+no6KC3txeHwxEct1qteDyeK64di9PpxOl0Bqe7u7sntQ1ybYr2/SSU/mfyXTvR/PpHc+/jSU9PH3deyKHy6KOPBn+OiYlhzpw5WK2T2w0TExPp7+8PTnu9XhwOB0NDQ/h8vuC41WolKSnpimtFRCS8Qk6F6667joSEBE6fPk1bWxuDg4OTXpnNZsPv99PTc/5Au6GhgYULF5KTk0N9fT0A7e3tpKSkmFIrIiLhFfKRyrvvvsuuXbvIyckhEAiwd+9e/uEf/oHPfvazk1phYWEhlZWVxMXFkZubS0ZGBunp6TQ3N7N582YSEhIoKioypVZERMLLErjw/cAT2LJlC6WlpVx33XXA+fOEu3fvpqysbFobnG6dnZ2RbkEu8tr+mXmh/ssrJn6Y6s6dO8PQydSsX79+whqruzIMnUyNsWDDhDXPHy0NQyeTd88Xr76vB7ncNZWQT39ZLJZgoMD5Oxr8fv+VdSYiIleVkEMlEAgwMDAQnD537tyUrquIiMjVK+RrKsuWLePxxx/H6XRitVp5/fXXWbZs2XT2JiIiUSbkUMnIyOC+++7jN7/5DYZhcM899zBnzpxpbE1ERKJNyKe/nn76abKzs7nnnntYu3YtOTk57N69ezp7ExGRKBNyqMTHx49e0GrFMAzTGxIRkegVcqjMmjWL3/3ud8Hpjz6ambd+iohI5IR8TWXNmjVUVlbyR3/0R1itVtxud0j3vouIyLVjUhfqKyoqeP/99xkaGuLee+/FbrdPZ28iIhJlJvXo+1mzZrFo0aLp6kVERKLcTH7atYiIRBmFioiImEahIiIiplGoiIiIaRQqIiJiGoWKiIiYRqEiIiKmUaiIiIhpJvXhR7McOnSI+vr64PTp06e59957efnll0lOTiY2NpbHHnsMgLq6OtxuN4ZhUFxcTGZmJp2dnVRVVeH3+8nOzmbt2rXj1oqISPhEJFSWL1/O8uXLAaivr+f3v/89Pp+P1atXs3jx4mCd2+3G4/FQXl5OW1sbtbW1lJWVUV1dTUlJCWlpaezYsYPW1laGh4fHrBURkfCJ6OkvwzB47bXXWL58OT6fj8TExFHzjx8/Tn5+PgBZWVl4vV5GRkbw+/2kpaUBkJeXR0tLy5i1IiISXhE5UrngrbfeYtGiRdhsNgzD4PnnnycmJoalS5fidDrp7e3F4XAE661WKx6Ph6SkpOCY3W6no6NjzFrDMLBaR+emy+XC5XIBUFFRQWpq6jRvpUzOzPxKhWjfT0LpvycMfUxVNL/+0dz7VEQ0VP7rv/6Lhx56CICCggIKCgoYHBxk+/bt3HzzzcyePRufzxest1qtJCUl0d/fHxzzer04HA6GhoYuqf10oAA4nU6cTmdwuru7ezo2Ta4y0b6fhNL/TL5rJ5pf/2jufTzp6enjzovYftTX14ff7yc5ORmAkZERAGw2GwkJCVgsFnJycoIX9Nvb20lJScFms+H3++npOf++qqGhgYULF45ZKyIi4RWxIxW32012dnZwet++fZw8eRLDMFi8eDEZGRmkp6fT3NzM5s2bSUhIoKioCIDCwkIqKyuJi4sjNzf3srUiIhI+EQuVW265hVtuuSU4feG24ItZrdYxw2HevHls27YtpFoREQmfmXwaVUREooxCRURETKNQERER0yhURETENAoVERExjUJFRERMo1ARERHTKFRERMQ0ChURETGNQkVEREyjUBEREdMoVERExDQKFRERMY1CRURETKNQERER0yhURETENAoVERExjUJFRERMo1ARERHTROw76jds2IDdbgfA6XRy4403UlVVhd/vJzs7O/id9XV1dbjdbgzDoLi4mMzMTDo7O0OuFRGR8IlYqMyZM4dNmzYFp7/3ve9RUlJCWloaO3bsoLW1leHhYTweD+Xl5bS1tVFbW0tZWRnV1dUh14qISPhELFQsFkvw55GREfx+P2lpaQDk5eXR0tJCX18f+fn5AGRlZeH1eidVKyIi4RWRUBkYGODjjz9my5YtJCcnU1hYSFJSUnC+3W6no6OD3t5eHA5HcNxqteLxeEKuNQwDq3X0ZSOXy4XL5QKgoqKC1NTU6dpMmZKPIt3AmKJ9Pwml/54w9DFV0fz6R3PvUxGRUImPj+epp54C4MSJE9TU1NDf3x+c7/V6cTgcDA0N4fP5guNWq5WkpKSQaz8dKHD++o3T6QxOd3d3m7ptcnWK9v0klP5n8l070fz6R3Pv40lPTx93XkT2I8Mwgj9fOLrw+/309Jx/r9TQ0MDChQvJycmhvr4egPb2dlJSUrDZbCHXiohIeEXkSKWrq4tdu3YRGxtLbGwsDzzwAH19fVRWVhIXF0dubi4ZGRmkp6fT3NzM5s2bSUhIoKioCIDCwsKQa0VEJHwiEirp6el897vfHTV2/fXXs23btlFjVqt1zHCYN29eyLUiIhI+M/k0qoiIRBmFioiImEahIiIiplGoiIiIaRQqIiJiGoWKiIiYRqEiIiKmUaiIiIhpFCoiImIahYqIiJhGoSIiIqaJ2Jd0yfS477lfR7qFMVXfe1ukWxCRMNCRioiImEahIiIiplGoiIiIaRQqIiJiGoWKiIiYRqEiIiKmicgtxT6fj927d3P27FkCgQDr1q3jvffe4+WXXyY5OZnY2Fgee+wxAOrq6nC73RiGQXFxMZmZmXR2dlJVVYXf7yc7O5u1a9eOWysiIuETkVAZHByksLCQlJQUmpqa2L9/P5/5zGdYvXo1ixcvDta53W48Hg/l5eW0tbVRW1tLWVkZ1dXVlJSUkJaWxo4dO2htbWV4eHjMWhERCZ+IhEpKSkrw58TEROLj4/H5fPzhH/7hqLrjx4+Tn58PQFZWFl6vl5GREfx+P2lpaQDk5eXR0tJCX1/fJbUiIhJeEf1EfU9PD6+++ir3338/LpeL559/npiYGJYuXYrT6aS3txeHwxGst1qteDwekpKSgmN2u52Ojo4xaw3DwGodfdnI5XLhcrkAqKioIDU1dZq3UoBJvM4fTWsfUxXt+0ko/feEoY+piubXP5p7n4qIhUpjYyONjY08+OCD2O12CgoKKCgoYHBwkO3bt3PzzTcze/ZsfD5fcBmr1UpSUhL9/f3BMa/Xi8PhYGho6JLaTwcKgNPpxOl0Bqe7u7unaQvlYtH+Ol8L/c/ku3ai+fWP5t7Hk56ePu68iOxHH374IY2NjRQXF2O32wEYGRkBwGazkZCQgMViIScnh/r6egDa29tJSUnBZrPh9/vp6Tn/vqqhoYGFCxeOWSsiIuEVkSOVY8eO4Xa72bp1K3D+8DA5OZmTJ09iGAaLFy8mIyOD9PR0mpub2bx5MwkJCRQVFQFQWFhIZWUlcXFx5ObmXrZWRETCJyKh8tWvfpWvfvWrE9ZZrdYxw2HevHls27YtpFoREQmfmXwaVUREooxCRURETKNQERER0yhURETENAoVERExjUJFRERMo1ARERHTKFRERMQ0ChURETGNQkVEREwT0Uffz0QfPfpApFsY0w0/qIp0CyIiE9KRioiImEahIiIiplGoiIiIaRQqIiJiGoWKiIiYRqEiIiKmUaiIiIhpFCoiImKaq+7Dj3V1dbjdbgzDoLi4mMzMzEi3JCJyzbiqjlTcbjcej4fy8nKKioqora2NdEsiIteUqypUjh8/Tn5+PgBZWVl4vd4IdyQicm2xBAKBQKSbMMtPf/pTli9fTlZWFgCbNm2ivLwcq/X/stPlcuFyuQCoqKiISJ8iIlerq+pIZfbs2fh8vuC01WodFSgATqeTioqKsATKP//zP0/7OqaT+o+saO4/mnsH9X8lrqpQycnJob6+HoD29nZSUlIi3JGIyLXlqrr768/+7M9obm5m8+bNJCQkUFRUFOmWRESuKVdVqFit1hkVJE6nM9ItXBH1H1nR3H809w7q/0pcVRfqRUQksq6qayoiIhJZChURETHNVXVNZabo7e3l4MGDWCwWVq1aFel2Js3n87F7927Onj1LIBBg3bp1pKWlRbqtkA0PD/PDH/6QgYEBAoEA3/rWt6LyTsDvfOc7/N3f/R1f+MIXIt3KpGzYsAG73Q6cP7e/ZMmSCHc0ObW1tbS2tjI8PExRURGf/exnI93ShD7ds8Viobq6Gr/fz0033cQ3v/nNsPWiUJkGNTU1zJ07l8HBwUi3MiWDg4MUFhaSkpJCU1MT+/fv54EHHoh0WyGzWq384z/+I7NmzeLw4cO8+eabfOMb34h0W5NSX19Pf39/pNuYkjlz5rBp06ZItzElx44dY2hoiPLyctrb23n22WfZvHlzpNu6rLF6Bli3bh2pqans3LmTd955h4ULF4alH53+mgalpaUsWLAg0m1MWUpKSvCdfWJiIvHx8RHuaHKsViuzZs0CoKurK/iEhWhx7tw5Dh8+HHXv8C+wWCyRbmHK2tragv/5ZmRkjPow9Uw1Vs+Dg4OkpqYCkJuby8mTJ8PWj0JFxtXT08Orr77KnXfeGelWJm3//v2sX7+eDz74IGzv0MyyZ88evvGNb0Tlf84DAwN8/PHHbNmyhR07dtDd3R3pliYlKyuLhoYGAoEAH330EWfOnGGm3yA7Vs+xsbG0t7cTCAR45513MAwjbP3o9JeMqbGxkcbGRh588MHg+fFosmLFClasWEFzczPPPPMM69ati3RLIfnlL39Jamoq8+bNo6mpKdLtTFp8fDxPPfUUACdOnKCmpoZHHnkkwl2F7gtf+AIffPABW7du5cYbb2T+/PkzPtzH6rmwsJDq6mpiYmK4/vrrue6668LWj0JFLvHhhx/S2NhIcXFxpFuZknPnzhEfH4/FYiE1NZWBgYFItxSyX/3qV8yaNYsf/ehHnD59mnfffZe0tDTS09Mj3VpIDMMIPm/P4XBEuJupufvuu7n77rtpamoiMTEx0u2E5NM9f+Yzn2Hjxo0MDQ3xox/9KKw3DClU5BLHjh3D7XazdetWAFJTUyktLY1sU5PQ0dHBc889R2xsLDabjb//+7+PdEshKysrC/78wgsvkJ2dHTWBAuevYe3atYvY2FhiY2Oj6gYPgL6+PrZv3w7ADTfcEBX9j9Xz/v37+c1vfgOcD5yEhISw9aNP1IuIiGl0oV5EREyjUBEREdMoVERExDQKFRETnDp1iqGhoZBqW1paprkbkcjR3V8iJqiurubhhx8O6RlpTz75JP/2b/92Ret76aWXcLlcJCUlXTJv+fLlfOlLXxo19vOf/5zXX3/9ktr+/n5uueUW7r333ivqR+QChYrIJLz33nu88cYbl/0w5QsvvEBaWhq33357cGzdunUhB8lLL72EzWbjrrvuumzdypUrLwmP8Sxbtoxly5ZdMt7Q0MD7778f0u8QCYVOf4lMQiAQmPbHdrz//vu8++6707qOC0ZGRoiN1XtLMY/2JpFJ+OSTT/jkk0+A819xcObMGeD8p/gv1tXVNelrJ4Zh8O///u/ceuutGIbBvn37WLVqVfAT6hdLSEjgwIEDHDp06JJ5eXl5rFy5MqR1Dg4OhvWDcXL1U6iITILb7ebUqVOcO3eOrq4u6uvrgfMBc7Hf/e53jIyMhPQ7h4eHefvttzl06BBLlizhL/7iLwA4evQo3//+9/nrv/5rFi1ahM1mCy5z5513hvSgzw8++ICnn3563Pler5dAIMCRI0dYt25dVHx3iMxsChWREHk8HlpaWrjrrrs4ePAgK1euJDs7G4D//d//HVV72223jbqmcvTo0XF/7+HDh+nu7uahhx5izpw5wfEvfvGLfP7zn+e1116jr6+Pv/qrv5owJC62bt06brrpJn7wgx+EvpEiV0ihIhICwzD48Y9/TGFhITk5OZSXlzNv3jxTvpXxjjvuGHee3W4fdSprqiFx4sQJYmJi+NznPjdq/OTJk3g8Hv78z/980r9TZCwKFZEJ9Pf386//+q/k5uYG/1P+p3/6J5544gnOnTvHbbfddskyP//5zzl27Ni09eT3+3nppZc4fvx48NHsgUCAP/mTP2HlypWXXHw/deoUNpvtklDp7Oykq6tLoSKmUaiITCA+Pp6VK1dy8803B8ccDgdbt24d88uPVqxYccntu2NdbIeJr3lc7OJrHi+++CKBQIAnnniCmJgY4Py1mX379vHCCy+wevXqS5bfv38/b7755qgxr9fL0qVLQ1q/SCgUKiITsFqtowLlgtmzZ49ZHx8fH/JXME/1dNZ4tzVf7nbnFStWsHz58lFjhw8fpqura9LrFxmPQkUkChUUFPDiiy+yceNGrFZr8PMzixYt4m//9m/HXOaVV17hjTfeGDXm8/lG3VAgcqX0fSoiJhgYGMBms417muti/f394x7liEQ7hYqIiJhGj2kRERHTKFRERMQ0ChURETGNQkVEREyjUBEREdMoVERExDT/DwkHEKM4Z6mjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='서비스등급',data=train_data)\n",
    "plt.title('서비스등급')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총투자기간\n",
    "- hold_d 와 연관성이 가장 높아 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='총투자기간',data=train_data)\n",
    "plt.title('고객 별 총투자기간')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['총투자제곱']=train_data.총투자기간**2\n",
    "test_data['총투자제곱']=test_data.총투자기간**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주거래업종구분\n",
    "- mean_encoding을 해도 될 것으로도 보인다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=train_data['hold_d'].mean()\n",
    "agg=train_data.groupby('주거래업종구분')['hold_d'].agg(['count','mean'])\n",
    "counts=agg['count']\n",
    "means=agg['mean']\n",
    "weight=80\n",
    "smooth=(counts*means+weight*mean)/(counts+weight)\n",
    "\n",
    "train_data['주거래업종구분_ME']=train_data['주거래업종구분'].map(smooth)\n",
    "test_data['주거래업종구분_ME']=test_data['주거래업종구분'].map(smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "종목한글명 - 종목업종\n",
    "- 종목업종 별 종목 중 가장 많은 종목에 투자를 하였는지를 확인하기 위해 mode를 이용하여 사용\n",
    "#### train_data 와 업종_주종목을 merge 한다( key=종목업종). 그렇게 들어간 업종_주종목과 종목한글명이 같다면 1 아니면 0 이런식으로 열을 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "업종_주종목=train_test.groupby('종목업종')['종목한글명'].agg([('업종_주종목', lambda x: x.mode()[0])]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.merge(train_data, 업종_주종목, how='left', on='종목업종')\n",
    "test_data=pd.merge(test_data, 업종_주종목, how='left', on='종목업종')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data[(train_data[\"종목한글명\"] == train_data[\"업종_주종목\"])].index,'업종_주종목']=1\n",
    "train_data['업종_주종목']=train_data.업종_주종목.apply(lambda x: x if x==1 else 0)\n",
    "\n",
    "test_data.loc[test_data[(test_data[\"종목한글명\"] == test_data[\"업종_주종목\"])].index,'업종_주종목']=1\n",
    "test_data['업종_주종목']=test_data.업종_주종목.apply(lambda x: x if x==1 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구매 정보 관련\n",
    "train_data['투자_자산_wv'] = train_data['투자성향'].astype(str) + '_' + train_data['자산구간'].astype(str) \n",
    "\n",
    "test_data['투자_자산_wv'] = test_data['투자성향'].astype(str) + '_' + test_data['자산구간'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "trn = list(train_data.groupby(['계좌번호','종목코드','매수일자'])['투자_자산_wv'].unique())\n",
    "tst = list(test_data.groupby(['계좌번호','종목코드','매수일자'])['투자_자산_wv'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['4_2'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['2_4'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_6'], dtype=object),\n",
       " array(['4_1'], dtype=object),\n",
       " array(['4_1'], dtype=object),\n",
       " array(['4_1'], dtype=object),\n",
       " array(['2_3'], dtype=object),\n",
       " array(['2_3'], dtype=object),\n",
       " array(['2_3'], dtype=object),\n",
       " array(['0_1'], dtype=object),\n",
       " array(['0_1'], dtype=object),\n",
       " array(['0_1'], dtype=object),\n",
       " array(['0_1'], dtype=object),\n",
       " array(['0_1'], dtype=object),\n",
       " array(['0_1'], dtype=object),\n",
       " array(['0_1'], dtype=object),\n",
       " array(['0_1'], dtype=object),\n",
       " array(['0_1'], dtype=object),\n",
       " array(['0_1'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['3_1'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['5_5'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['3_3'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['2_2'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['3_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_4'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " array(['0_3'], dtype=object),\n",
       " ...]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(x, n,seed=0):\n",
    "    lst = []\n",
    "    for i in x:\n",
    "        tmp = []\n",
    "        np.random.seed(seed)\n",
    "        for j in range(n):\n",
    "            random.shuffle(i)\n",
    "            tmp += list(i)\n",
    "            lst.append(tmp)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_input = oversample(trn, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-236-c9d175e40c8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mw2v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw2v_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, corpus_file, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, max_final_vocab)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2VecTrainables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhashfxn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhashfxn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         super(Word2Vec, self).__init__(\n\u001b[0m\u001b[0;32m    598\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, corpus_file, workers, vector_size, epochs, callbacks, batch_words, trim_rule, sg, alpha, window, seed, hs, negative, ns_exponent, cbow_mean, min_alpha, compute_loss, **kwargs)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m             self.train(\n\u001b[0m\u001b[0;32m    747\u001b[0m                 \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                 \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_total_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m         \"\"\"\n\u001b[1;32m--> 724\u001b[1;33m         return super(Word2Vec, self).train(\n\u001b[0m\u001b[0;32m    725\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1061\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_training_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m         return super(BaseWordEmbeddingsModel, self).train(\n\u001b[0m\u001b[0;32m   1064\u001b[0m             \u001b[0mdata_iterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_iterable\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0m\u001b[0;32m    551\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0mthread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0m\u001b[0;32m    487\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             report_delay=report_delay, is_corpus_file_mode=False)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# blocks if workers too slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# a thread reporting that it finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "w2v = word2vec.Word2Vec(sentences = w2v_input, size = 100, window = 5, min_count = 1, sg = 1,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 9337/9337 [00:00<00:00, 98243.01it/s]\n"
     ]
    }
   ],
   "source": [
    "train_mean_vector = []\n",
    "for words in tqdm(trn):\n",
    "    tmp = np.zeros(100)\n",
    "    cnt = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            tmp += w2v[word]\n",
    "            cnt += 1\n",
    "        except:\n",
    "            pass\n",
    "    tmp /= cnt\n",
    "    train_mean_vector.append(tmp)\n",
    "train_mean_vector = np.array(train_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 9980/9980 [00:00<00:00, 96868.16it/s]\n"
     ]
    }
   ],
   "source": [
    "test_mean_vector = []\n",
    "for words in tqdm(tst):\n",
    "    tmp = np.zeros(100)\n",
    "    cnt = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            tmp += w2v[word]\n",
    "            cnt += 1\n",
    "        except:\n",
    "            pass\n",
    "    tmp /= cnt\n",
    "    test_mean_vector.append(tmp)\n",
    "test_mean_vector = np.array(test_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_vector = pd.DataFrame(train_mean_vector)\n",
    "test_mean_vector = pd.DataFrame(test_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean_vector.isnull().sum().sum(),test_mean_vector.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9337, 100), (9980, 100))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean_vector.shape,test_mean_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop([\"계좌번호\", \"종목코드\", \"매수일자\", \"기준일자\"], axis = 1)\n",
    "test_data = test_data.drop([\"계좌번호\", \"종목코드\", \"매수일자\", \"submit_id\", \"hold_d\", \"기준일자\",'과거보유일'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data에서 Y값을 추출한 후 hold_d column을 지워주겠습니다.\n",
    "\n",
    "train_label = train_data[\"hold_d\"]\n",
    "train_data.drop([\"hold_d\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_encoder = LabelEncoder()\n",
    "L_encoder.fit(iem[\"종목한글명\"])\n",
    "train_data[\"종목한글명\"] = L_encoder.transform(train_data[\"종목한글명\"])\n",
    "test_data[\"종목한글명\"] = L_encoder.transform(test_data[\"종목한글명\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a=pd.get_dummies(train_data['투자_자산_wv'])\n",
    "#b=pd.get_dummies(test_data['투자_자산_wv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a_sub_b = [x for x in a.columns if x not in b.columns]\n",
    "#a.drop(a_sub_b,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_sub_a = [x for x in b.columns if x not in a.columns]\n",
    "#b.drop(b_sub_a,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data=pd.concat([train_data,a],axis=1)\n",
    "#test_data=pd.concat([test_data,b],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((681472, 34), (70596, 34))"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop = True, inplace=True)\n",
    "train_label.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.drop([\"투자_자산_wv\"], axis = 1, inplace = True)\n",
    "#test_data.drop([\"투자_자산_wv\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's rmse: 62.7988\tvalid_0's l2: 3943.69\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's rmse: 62.6204\tvalid_0's l2: 3921.32\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's rmse: 67.8086\tvalid_0's l2: 4598.01\n",
      "Early stopping, best iteration is:\n",
      "[447]\tvalid_0's rmse: 67.7878\tvalid_0's l2: 4595.18\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's rmse: 71.2815\tvalid_0's l2: 5081.06\n",
      "[1000]\tvalid_0's rmse: 71.143\tvalid_0's l2: 5061.32\n",
      "[1500]\tvalid_0's rmse: 71.0995\tvalid_0's l2: 5055.14\n",
      "Early stopping, best iteration is:\n",
      "[1237]\tvalid_0's rmse: 71.0653\tvalid_0's l2: 5050.27\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's rmse: 57.6106\tvalid_0's l2: 3318.98\n",
      "[1000]\tvalid_0's rmse: 57.5456\tvalid_0's l2: 3311.5\n",
      "[1500]\tvalid_0's rmse: 57.4726\tvalid_0's l2: 3303.1\n",
      "[2000]\tvalid_0's rmse: 57.4625\tvalid_0's l2: 3301.94\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1848]\tvalid_0's rmse: 57.4432\tvalid_0's l2: 3299.72\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's rmse: 51.6036\tvalid_0's l2: 2662.93\n",
      "[1000]\tvalid_0's rmse: 51.4032\tvalid_0's l2: 2642.29\n",
      "[1500]\tvalid_0's rmse: 51.3468\tvalid_0's l2: 2636.49\n",
      "[2000]\tvalid_0's rmse: 51.3248\tvalid_0's l2: 2634.24\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1989]\tvalid_0's rmse: 51.3239\tvalid_0's l2: 2634.15\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's rmse: 45.4151\tvalid_0's l2: 2062.53\n",
      "[1000]\tvalid_0's rmse: 45.311\tvalid_0's l2: 2053.09\n",
      "[1500]\tvalid_0's rmse: 45.1637\tvalid_0's l2: 2039.76\n",
      "[2000]\tvalid_0's rmse: 45.1565\tvalid_0's l2: 2039.11\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1720]\tvalid_0's rmse: 45.1347\tvalid_0's l2: 2037.14\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's rmse: 34.73\tvalid_0's l2: 1206.17\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's rmse: 26.569\tvalid_0's l2: 705.912\n",
      "[1000]\tvalid_0's rmse: 26.5518\tvalid_0's l2: 704.999\n",
      "Early stopping, best iteration is:\n",
      "[716]\tvalid_0's rmse: 26.5009\tvalid_0's l2: 702.299\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's rmse: 20.6758\tvalid_0's l2: 427.491\n",
      "[1000]\tvalid_0's rmse: 20.6228\tvalid_0's l2: 425.298\n",
      "[1500]\tvalid_0's rmse: 20.604\tvalid_0's l2: 424.525\n",
      "Early stopping, best iteration is:\n",
      "[1314]\tvalid_0's rmse: 20.5932\tvalid_0's l2: 424.081\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[500]\tvalid_0's rmse: 20.0449\tvalid_0's l2: 401.798\n",
      "[1000]\tvalid_0's rmse: 19.9649\tvalid_0's l2: 398.597\n",
      "Early stopping, best iteration is:\n",
      "[906]\tvalid_0's rmse: 19.9596\tvalid_0's l2: 398.384\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "folds = KFold(n_splits=10)\n",
    "for train_idx, val_idx in folds.split(train_data):\n",
    "    \n",
    "    train_x = train_data.iloc[train_idx, :]\n",
    "    train_y = train_label[train_idx]\n",
    "    val_x = train_data.iloc[val_idx, :]\n",
    "    val_y = train_label[val_idx]\n",
    "    \n",
    "    model = LGBMRegressor(objective= \"regression\",\n",
    "                          max_depth= 5,\n",
    "                          n_estimators= 2000,\n",
    "                          learning_rate= 0.01,\n",
    "                          num_leaves = 31)\n",
    "    \n",
    "    model.fit(train_x, train_y,\n",
    "              eval_set=[(val_x, val_y)],\n",
    "              eval_metric=[\"rmse\"],\n",
    "              early_stopping_rounds=300,\n",
    "              verbose=500)\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"a9c45428-bb34-47fc-a91c-afd03dd34b61\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a9c45428-bb34-47fc-a91c-afd03dd34b61\")) {                    Plotly.newPlot(                        \"a9c45428-bb34-47fc-a91c-afd03dd34b61\",                        [{\"alignmentgroup\": \"True\", \"hovertemplate\": \"variable=0<br>index=%{x}<br>value=%{y}<extra></extra>\", \"legendgroup\": \"0\", \"marker\": {\"color\": \"#636efa\"}, \"name\": \"0\", \"offsetgroup\": \"0\", \"orientation\": \"v\", \"showlegend\": true, \"textposition\": \"auto\", \"type\": \"bar\", \"x\": [\"\\uc131\\ubcc4\", \"\\uc5f0\\ub839\\ub300\", \"\\ud22c\\uc790\\uc131\\ud5a5\", \"\\uc790\\uc0b0\\uad6c\\uac04\", \"\\uc8fc\\uac70\\ub798\\uc0c1\\ud488\\uad70\", \"Life_style\", \"\\uc11c\\ube44\\uc2a4\\ub4f1\\uae09\", \"\\ucd1d\\ud22c\\uc790\\uae30\\uac04\", \"\\uc8fc\\uac70\\ub798\\uc5c5\\uc885\\uad6c\\ubd84\", \"\\uc885\\ubaa9\\ud55c\\uae00\\uba85\", \"\\uc885\\ubaa9\\uc5c5\\uc885\", \"\\uc2dc\\uac00\\ucd1d\\uc561\\uaddc\\ubaa8\\uc720\\ud615\", \"\\uc2dc\\uc7a5\\uad6c\\ubd84\", \"\\uc794\\uace0\\uc218\\ub7c9\", \"\\uc794\\uace0\\uae08\\uc561\", \"\\uc8fc\\ub2f9\\uc561\\uba74\\uac00\", \"\\ud3c9\\uade0\\uc794\\uace0\\uae08\\uc561\", \"\\ub144\", \"\\uc6d4\", \"\\uc77c\", \"\\uc694\\uc77c\", \"\\ub144\\ub3c4_\\uc794\\uace0\\uc218\\ub7c9\", \"\\ub144\\ub3c4_\\ucd1d\\ud22c\\uc790\\uae30\\uac04\", \"\\uae08\\uc561\\ubcc0\\ud654\", \"\\uae08\\uc561\\ubcc0\\ud654\\ube44\\uc728\", \"\\ub9e4\\uc218\\ud69f\\uc218\", \"\\uace0\\uac1d\\ubcc4_\\uc885\\ubaa9\\uc5c5\\uc885\", \"\\uace0\\uac1d\\ubcc4_\\uc885\\ubaa9_hold\", \"\\ud22c\\uc790\\uc131\\ud615_\\uc790\\uc0b0\\uad6c\\uac04\", \"\\uad6d\\ub0b4\\uc8fc\\uc2dd\", \"\\ub098\\uc774_\\uc9c1\\uc885\", \"\\ucd1d\\ud22c\\uc790\\uc81c\\uacf1\", \"\\uc8fc\\uac70\\ub798\\uc5c5\\uc885\\uad6c\\ubd84_ME\", \"\\uc5c5\\uc885_\\uc8fc\\uc885\\ubaa9\"], \"xaxis\": \"x\", \"y\": [601, 486, 408, 1228, 128, 295, 693, 806, 1238, 374, 208, 295, 162, 959, 1357, 312, 422, 3813, 2548, 397, 67, 89, 226, 207, 932, 4713, 792, 753, 926, 84, 441, 0, 703, 106], \"yaxis\": \"y\"}],                        {\"barmode\": \"relative\", \"legend\": {\"title\": {\"text\": \"variable\"}, \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"index\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"value\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a9c45428-bb34-47fc-a91c-afd03dd34b61');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(model.feature_importances_,index=train_data.columns).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in models:\n",
    "    result.append(i.predict(test_data))\n",
    "predict = np.mean(result, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"hold_d\"] = np.round(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"dacon_baseline.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((477030, 60), (204442, 60))"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(ftr, target, test_size=0.3, random_state=0)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_params = {\n",
    "    'max_depth':(8, 16),\n",
    "    'num_leaves':(24, 64),\n",
    "    'min_child_samples':(10, 200),\n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1),\n",
    "    'colsample_bytree':(0.5, 1),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha':(0.01, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_rmse_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree, max_bin, reg_lambda, reg_alpha):\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\":2000, \n",
    "        \"learning_rate\":0.02,\n",
    "        'max_depth':int(round(max_depth)),\n",
    "        'num_leaves':int(round(num_leaves)),\n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample':max(min(subsample, 1), 0),\n",
    "        'colsample_bytree':max(min(colsample_bytree, 1), 0),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0)\n",
    "    }\n",
    "    \n",
    "    lgb_model = LGBMRegressor(**params)\n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'RMSE', verbose= 100, \n",
    "                early_stopping_rounds= 100)\n",
    "    valid_pred = lgb_model.predict(valid_x)\n",
    "    RMSE = np.sqrt(mean_squared_error(valid_y, valid_pred))\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 12.018\ttraining's l2: 144.433\tvalid_1's rmse: 11.92\tvalid_1's l2: 142.087\n",
      "[200]\ttraining's rmse: 3.19423\ttraining's l2: 10.2031\tvalid_1's rmse: 2.75257\tvalid_1's l2: 7.57664\n",
      "[300]\ttraining's rmse: 1.98932\ttraining's l2: 3.95738\tvalid_1's rmse: 1.30434\tvalid_1's l2: 1.70131\n",
      "[400]\ttraining's rmse: 1.79635\ttraining's l2: 3.22686\tvalid_1's rmse: 1.08134\tvalid_1's l2: 1.16929\n",
      "[500]\ttraining's rmse: 1.71586\ttraining's l2: 2.94417\tvalid_1's rmse: 1.02317\tvalid_1's l2: 1.04688\n",
      "[600]\ttraining's rmse: 1.67486\ttraining's l2: 2.80516\tvalid_1's rmse: 0.983042\tvalid_1's l2: 0.966371\n",
      "[700]\ttraining's rmse: 1.6513\ttraining's l2: 2.7268\tvalid_1's rmse: 0.965472\tvalid_1's l2: 0.932136\n",
      "[800]\ttraining's rmse: 1.63166\ttraining's l2: 2.66231\tvalid_1's rmse: 0.956135\tvalid_1's l2: 0.914194\n",
      "[900]\ttraining's rmse: 1.61681\ttraining's l2: 2.61406\tvalid_1's rmse: 0.945839\tvalid_1's l2: 0.894611\n",
      "[1000]\ttraining's rmse: 1.60367\ttraining's l2: 2.57177\tvalid_1's rmse: 0.937525\tvalid_1's l2: 0.878953\n",
      "[1100]\ttraining's rmse: 1.59419\ttraining's l2: 2.54144\tvalid_1's rmse: 0.928524\tvalid_1's l2: 0.862157\n",
      "[1200]\ttraining's rmse: 1.58411\ttraining's l2: 2.50939\tvalid_1's rmse: 0.922643\tvalid_1's l2: 0.851271\n",
      "[1300]\ttraining's rmse: 1.57433\ttraining's l2: 2.47853\tvalid_1's rmse: 0.919135\tvalid_1's l2: 0.844809\n",
      "[1400]\ttraining's rmse: 1.56541\ttraining's l2: 2.45052\tvalid_1's rmse: 0.916221\tvalid_1's l2: 0.839461\n",
      "Early stopping, best iteration is:\n",
      "[1397]\ttraining's rmse: 1.5655\ttraining's l2: 2.45078\tvalid_1's rmse: 0.916184\tvalid_1's l2: 0.839393\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9162  \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 360.4   \u001b[0m | \u001b[0m 12.82   \u001b[0m | \u001b[0m 113.5   \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 49.84   \u001b[0m | \u001b[0m 21.88   \u001b[0m | \u001b[0m 8.918   \u001b[0m | \u001b[0m 0.9818  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 15.3446\ttraining's l2: 235.456\tvalid_1's rmse: 15.321\tvalid_1's l2: 234.734\n",
      "[200]\ttraining's rmse: 4.29945\ttraining's l2: 18.4853\tvalid_1's rmse: 3.99225\tvalid_1's l2: 15.938\n",
      "[300]\ttraining's rmse: 2.37018\ttraining's l2: 5.61777\tvalid_1's rmse: 1.84651\tvalid_1's l2: 3.4096\n",
      "[400]\ttraining's rmse: 1.98053\ttraining's l2: 3.92251\tvalid_1's rmse: 1.39198\tvalid_1's l2: 1.93762\n",
      "[500]\ttraining's rmse: 1.82922\ttraining's l2: 3.34604\tvalid_1's rmse: 1.21985\tvalid_1's l2: 1.48803\n",
      "[600]\ttraining's rmse: 1.74709\ttraining's l2: 3.05231\tvalid_1's rmse: 1.12999\tvalid_1's l2: 1.27688\n",
      "[700]\ttraining's rmse: 1.70087\ttraining's l2: 2.89296\tvalid_1's rmse: 1.08282\tvalid_1's l2: 1.17249\n",
      "[800]\ttraining's rmse: 1.67349\ttraining's l2: 2.80056\tvalid_1's rmse: 1.05752\tvalid_1's l2: 1.11835\n",
      "[900]\ttraining's rmse: 1.65082\ttraining's l2: 2.72521\tvalid_1's rmse: 1.03691\tvalid_1's l2: 1.07518\n",
      "[1000]\ttraining's rmse: 1.63311\ttraining's l2: 2.66704\tvalid_1's rmse: 1.02621\tvalid_1's l2: 1.05311\n",
      "[1100]\ttraining's rmse: 1.61807\ttraining's l2: 2.61816\tvalid_1's rmse: 1.01253\tvalid_1's l2: 1.02522\n",
      "[1200]\ttraining's rmse: 1.60456\ttraining's l2: 2.5746\tvalid_1's rmse: 1.00536\tvalid_1's l2: 1.01076\n",
      "[1300]\ttraining's rmse: 1.5949\ttraining's l2: 2.54371\tvalid_1's rmse: 0.994764\tvalid_1's l2: 0.989555\n",
      "[1400]\ttraining's rmse: 1.58559\ttraining's l2: 2.5141\tvalid_1's rmse: 0.987941\tvalid_1's l2: 0.976028\n",
      "[1500]\ttraining's rmse: 1.57648\ttraining's l2: 2.48528\tvalid_1's rmse: 0.982698\tvalid_1's l2: 0.965694\n",
      "[1600]\ttraining's rmse: 1.56809\ttraining's l2: 2.4589\tvalid_1's rmse: 0.97714\tvalid_1's l2: 0.954803\n",
      "[1700]\ttraining's rmse: 1.55962\ttraining's l2: 2.43241\tvalid_1's rmse: 0.973635\tvalid_1's l2: 0.947966\n",
      "[1800]\ttraining's rmse: 1.55138\ttraining's l2: 2.40678\tvalid_1's rmse: 0.968652\tvalid_1's l2: 0.938286\n",
      "[1900]\ttraining's rmse: 1.54368\ttraining's l2: 2.38294\tvalid_1's rmse: 0.964312\tvalid_1's l2: 0.929898\n",
      "[2000]\ttraining's rmse: 1.53647\ttraining's l2: 2.36075\tvalid_1's rmse: 0.961164\tvalid_1's l2: 0.923837\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.53647\ttraining's l2: 2.36075\tvalid_1's rmse: 0.961164\tvalid_1's l2: 0.923837\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9612  \u001b[0m | \u001b[95m 0.6917  \u001b[0m | \u001b[95m 397.9   \u001b[0m | \u001b[95m 12.23   \u001b[0m | \u001b[95m 117.9   \u001b[0m | \u001b[95m 46.35   \u001b[0m | \u001b[95m 26.84   \u001b[0m | \u001b[95m 4.366   \u001b[0m | \u001b[95m 0.2032  \u001b[0m | \u001b[95m 0.9163  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 9.51893\ttraining's l2: 90.6101\tvalid_1's rmse: 9.34478\tvalid_1's l2: 87.3249\n",
      "[200]\ttraining's rmse: 2.53456\ttraining's l2: 6.42398\tvalid_1's rmse: 1.89903\tvalid_1's l2: 3.60633\n",
      "[300]\ttraining's rmse: 1.92893\ttraining's l2: 3.72077\tvalid_1's rmse: 1.12715\tvalid_1's l2: 1.27047\n",
      "[400]\ttraining's rmse: 1.85214\ttraining's l2: 3.43043\tvalid_1's rmse: 1.06786\tvalid_1's l2: 1.14032\n",
      "[500]\ttraining's rmse: 1.82334\ttraining's l2: 3.32458\tvalid_1's rmse: 1.04469\tvalid_1's l2: 1.09137\n",
      "[600]\ttraining's rmse: 1.80205\ttraining's l2: 3.2474\tvalid_1's rmse: 1.03327\tvalid_1's l2: 1.06764\n",
      "[700]\ttraining's rmse: 1.79136\ttraining's l2: 3.20899\tvalid_1's rmse: 1.02484\tvalid_1's l2: 1.0503\n",
      "[800]\ttraining's rmse: 1.78171\ttraining's l2: 3.1745\tvalid_1's rmse: 1.02165\tvalid_1's l2: 1.04377\n",
      "[900]\ttraining's rmse: 1.77373\ttraining's l2: 3.14613\tvalid_1's rmse: 1.01747\tvalid_1's l2: 1.03524\n",
      "[1000]\ttraining's rmse: 1.76619\ttraining's l2: 3.11942\tvalid_1's rmse: 1.01446\tvalid_1's l2: 1.02912\n",
      "[1100]\ttraining's rmse: 1.75925\ttraining's l2: 3.09496\tvalid_1's rmse: 1.01266\tvalid_1's l2: 1.02549\n",
      "[1200]\ttraining's rmse: 1.75216\ttraining's l2: 3.07007\tvalid_1's rmse: 1.01145\tvalid_1's l2: 1.02303\n",
      "[1300]\ttraining's rmse: 1.74597\ttraining's l2: 3.04841\tvalid_1's rmse: 1.01054\tvalid_1's l2: 1.02119\n",
      "[1400]\ttraining's rmse: 1.73953\ttraining's l2: 3.02596\tvalid_1's rmse: 1.00978\tvalid_1's l2: 1.01966\n",
      "Early stopping, best iteration is:\n",
      "[1365]\ttraining's rmse: 1.74197\ttraining's l2: 3.03446\tvalid_1's rmse: 1.0096\tvalid_1's l2: 1.01928\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 1.01    \u001b[0m | \u001b[95m 0.8891  \u001b[0m | \u001b[95m 436.3   \u001b[0m | \u001b[95m 15.83   \u001b[0m | \u001b[95m 161.8   \u001b[0m | \u001b[95m 23.61   \u001b[0m | \u001b[95m 55.22   \u001b[0m | \u001b[95m 5.923   \u001b[0m | \u001b[95m 6.4     \u001b[0m | \u001b[95m 0.5717  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.56766\ttraining's l2: 57.2695\tvalid_1's rmse: 7.4042\tvalid_1's l2: 54.8222\n",
      "[200]\ttraining's rmse: 1.8062\ttraining's l2: 3.26237\tvalid_1's rmse: 1.30036\tvalid_1's l2: 1.69095\n",
      "[300]\ttraining's rmse: 1.4242\ttraining's l2: 2.02835\tvalid_1's rmse: 0.916697\tvalid_1's l2: 0.840334\n",
      "[400]\ttraining's rmse: 1.39202\ttraining's l2: 1.93772\tvalid_1's rmse: 0.936106\tvalid_1's l2: 0.876294\n",
      "Early stopping, best iteration is:\n",
      "[300]\ttraining's rmse: 1.4242\ttraining's l2: 2.02835\tvalid_1's rmse: 0.916697\tvalid_1's l2: 0.840334\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9167  \u001b[0m | \u001b[0m 0.9723  \u001b[0m | \u001b[0m 265.7   \u001b[0m | \u001b[0m 11.32   \u001b[0m | \u001b[0m 60.27   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 42.25   \u001b[0m | \u001b[0m 28.43   \u001b[0m | \u001b[0m 0.1889  \u001b[0m | \u001b[0m 0.8088  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 10.7395\ttraining's l2: 115.337\tvalid_1's rmse: 10.6063\tvalid_1's l2: 112.493\n",
      "[200]\ttraining's rmse: 2.83881\ttraining's l2: 8.05884\tvalid_1's rmse: 2.30676\tvalid_1's l2: 5.32116\n",
      "[300]\ttraining's rmse: 1.99632\ttraining's l2: 3.9853\tvalid_1's rmse: 1.25564\tvalid_1's l2: 1.57663\n",
      "[400]\ttraining's rmse: 1.86774\ttraining's l2: 3.48844\tvalid_1's rmse: 1.13541\tvalid_1's l2: 1.28916\n",
      "[500]\ttraining's rmse: 1.81738\ttraining's l2: 3.30286\tvalid_1's rmse: 1.09294\tvalid_1's l2: 1.19451\n",
      "[600]\ttraining's rmse: 1.79004\ttraining's l2: 3.20423\tvalid_1's rmse: 1.07078\tvalid_1's l2: 1.14656\n",
      "[700]\ttraining's rmse: 1.75642\ttraining's l2: 3.08501\tvalid_1's rmse: 1.06209\tvalid_1's l2: 1.12804\n",
      "[800]\ttraining's rmse: 1.7432\ttraining's l2: 3.03875\tvalid_1's rmse: 1.05244\tvalid_1's l2: 1.10762\n",
      "[900]\ttraining's rmse: 1.73305\ttraining's l2: 3.00347\tvalid_1's rmse: 1.04281\tvalid_1's l2: 1.08745\n",
      "[1000]\ttraining's rmse: 1.72366\ttraining's l2: 2.97101\tvalid_1's rmse: 1.03566\tvalid_1's l2: 1.07259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\ttraining's rmse: 1.71552\ttraining's l2: 2.94301\tvalid_1's rmse: 1.03267\tvalid_1's l2: 1.06641\n",
      "[1200]\ttraining's rmse: 1.70763\ttraining's l2: 2.91601\tvalid_1's rmse: 1.0308\tvalid_1's l2: 1.06255\n",
      "[1300]\ttraining's rmse: 1.70019\ttraining's l2: 2.89063\tvalid_1's rmse: 1.02895\tvalid_1's l2: 1.05874\n",
      "[1400]\ttraining's rmse: 1.69244\ttraining's l2: 2.86437\tvalid_1's rmse: 1.02893\tvalid_1's l2: 1.05869\n",
      "Early stopping, best iteration is:\n",
      "[1330]\ttraining's rmse: 1.69849\ttraining's l2: 2.88486\tvalid_1's rmse: 1.02823\tvalid_1's l2: 1.05727\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 1.028   \u001b[0m | \u001b[95m 0.806   \u001b[0m | \u001b[95m 312.3   \u001b[0m | \u001b[95m 15.55   \u001b[0m | \u001b[95m 139.5   \u001b[0m | \u001b[95m 18.62   \u001b[0m | \u001b[95m 41.48   \u001b[0m | \u001b[95m 34.88   \u001b[0m | \u001b[95m 0.6032  \u001b[0m | \u001b[95m 0.8334  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 16.7527\ttraining's l2: 280.653\tvalid_1's rmse: 16.7385\tvalid_1's l2: 280.178\n",
      "[200]\ttraining's rmse: 4.96521\ttraining's l2: 24.6534\tvalid_1's rmse: 4.66485\tvalid_1's l2: 21.7609\n",
      "[300]\ttraining's rmse: 2.73266\ttraining's l2: 7.46741\tvalid_1's rmse: 2.18634\tvalid_1's l2: 4.78008\n",
      "[400]\ttraining's rmse: 2.31435\ttraining's l2: 5.35624\tvalid_1's rmse: 1.68985\tvalid_1's l2: 2.8556\n",
      "[500]\ttraining's rmse: 2.14469\ttraining's l2: 4.5997\tvalid_1's rmse: 1.49934\tvalid_1's l2: 2.24802\n",
      "[600]\ttraining's rmse: 2.05957\ttraining's l2: 4.24183\tvalid_1's rmse: 1.40607\tvalid_1's l2: 1.97703\n",
      "[700]\ttraining's rmse: 2.00627\ttraining's l2: 4.02511\tvalid_1's rmse: 1.34975\tvalid_1's l2: 1.82184\n",
      "[800]\ttraining's rmse: 1.96652\ttraining's l2: 3.86719\tvalid_1's rmse: 1.30694\tvalid_1's l2: 1.70809\n",
      "[900]\ttraining's rmse: 1.93679\ttraining's l2: 3.75114\tvalid_1's rmse: 1.27625\tvalid_1's l2: 1.62881\n",
      "[1000]\ttraining's rmse: 1.91298\ttraining's l2: 3.65948\tvalid_1's rmse: 1.25652\tvalid_1's l2: 1.57885\n",
      "[1100]\ttraining's rmse: 1.89413\ttraining's l2: 3.58774\tvalid_1's rmse: 1.23903\tvalid_1's l2: 1.53521\n",
      "[1200]\ttraining's rmse: 1.87797\ttraining's l2: 3.52676\tvalid_1's rmse: 1.22579\tvalid_1's l2: 1.50256\n",
      "[1300]\ttraining's rmse: 1.86374\ttraining's l2: 3.47352\tvalid_1's rmse: 1.21558\tvalid_1's l2: 1.47763\n",
      "[1400]\ttraining's rmse: 1.84974\ttraining's l2: 3.42152\tvalid_1's rmse: 1.20789\tvalid_1's l2: 1.45899\n",
      "[1500]\ttraining's rmse: 1.83699\ttraining's l2: 3.37454\tvalid_1's rmse: 1.20108\tvalid_1's l2: 1.4426\n",
      "[1600]\ttraining's rmse: 1.82535\ttraining's l2: 3.33189\tvalid_1's rmse: 1.19512\tvalid_1's l2: 1.4283\n",
      "[1700]\ttraining's rmse: 1.81406\ttraining's l2: 3.29082\tvalid_1's rmse: 1.19062\tvalid_1's l2: 1.41758\n",
      "[1800]\ttraining's rmse: 1.80297\ttraining's l2: 3.2507\tvalid_1's rmse: 1.18648\tvalid_1's l2: 1.40774\n",
      "[1900]\ttraining's rmse: 1.79287\ttraining's l2: 3.2144\tvalid_1's rmse: 1.18285\tvalid_1's l2: 1.39913\n",
      "[2000]\ttraining's rmse: 1.7839\ttraining's l2: 3.18229\tvalid_1's rmse: 1.17952\tvalid_1's l2: 1.39127\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.7839\ttraining's l2: 3.18229\tvalid_1's rmse: 1.17952\tvalid_1's l2: 1.39127\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 1.18    \u001b[0m | \u001b[95m 0.6405  \u001b[0m | \u001b[95m 435.0   \u001b[0m | \u001b[95m 14.0    \u001b[0m | \u001b[95m 169.3   \u001b[0m | \u001b[95m 26.92   \u001b[0m | \u001b[95m 57.69   \u001b[0m | \u001b[95m 5.768   \u001b[0m | \u001b[95m 9.196   \u001b[0m | \u001b[95m 0.613   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 21.9176\ttraining's l2: 480.38\tvalid_1's rmse: 21.9688\tvalid_1's l2: 482.627\n",
      "[200]\ttraining's rmse: 7.58856\ttraining's l2: 57.5862\tvalid_1's rmse: 7.40909\tvalid_1's l2: 54.8946\n",
      "[300]\ttraining's rmse: 3.70316\ttraining's l2: 13.7134\tvalid_1's rmse: 3.30062\tvalid_1's l2: 10.8941\n",
      "[400]\ttraining's rmse: 2.7242\ttraining's l2: 7.42125\tvalid_1's rmse: 2.18731\tvalid_1's l2: 4.78433\n",
      "[500]\ttraining's rmse: 2.38677\ttraining's l2: 5.69668\tvalid_1's rmse: 1.78781\tvalid_1's l2: 3.19625\n",
      "[600]\ttraining's rmse: 2.23425\ttraining's l2: 4.99188\tvalid_1's rmse: 1.61544\tvalid_1's l2: 2.60963\n",
      "[700]\ttraining's rmse: 2.14107\ttraining's l2: 4.5842\tvalid_1's rmse: 1.51266\tvalid_1's l2: 2.28813\n",
      "[800]\ttraining's rmse: 2.07729\ttraining's l2: 4.31513\tvalid_1's rmse: 1.44574\tvalid_1's l2: 2.09016\n",
      "[900]\ttraining's rmse: 2.03363\ttraining's l2: 4.13563\tvalid_1's rmse: 1.40109\tvalid_1's l2: 1.96305\n",
      "[1000]\ttraining's rmse: 1.99909\ttraining's l2: 3.99635\tvalid_1's rmse: 1.36562\tvalid_1's l2: 1.86491\n",
      "[1100]\ttraining's rmse: 1.9676\ttraining's l2: 3.87144\tvalid_1's rmse: 1.33527\tvalid_1's l2: 1.78295\n",
      "[1200]\ttraining's rmse: 1.94394\ttraining's l2: 3.77891\tvalid_1's rmse: 1.31164\tvalid_1's l2: 1.72039\n",
      "[1300]\ttraining's rmse: 1.92254\ttraining's l2: 3.69615\tvalid_1's rmse: 1.29124\tvalid_1's l2: 1.66731\n",
      "[1400]\ttraining's rmse: 1.90446\ttraining's l2: 3.62696\tvalid_1's rmse: 1.27455\tvalid_1's l2: 1.62447\n",
      "[1500]\ttraining's rmse: 1.88967\ttraining's l2: 3.57086\tvalid_1's rmse: 1.26305\tvalid_1's l2: 1.59531\n",
      "[1600]\ttraining's rmse: 1.87704\ttraining's l2: 3.52328\tvalid_1's rmse: 1.25337\tvalid_1's l2: 1.57093\n",
      "[1700]\ttraining's rmse: 1.86419\ttraining's l2: 3.4752\tvalid_1's rmse: 1.2441\tvalid_1's l2: 1.54777\n",
      "[1800]\ttraining's rmse: 1.85196\ttraining's l2: 3.42977\tvalid_1's rmse: 1.23682\tvalid_1's l2: 1.52973\n",
      "[1900]\ttraining's rmse: 1.84219\ttraining's l2: 3.39365\tvalid_1's rmse: 1.23028\tvalid_1's l2: 1.51358\n",
      "[2000]\ttraining's rmse: 1.83184\ttraining's l2: 3.35564\tvalid_1's rmse: 1.22559\tvalid_1's l2: 1.50207\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.83184\ttraining's l2: 3.35564\tvalid_1's rmse: 1.22559\tvalid_1's l2: 1.50207\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 1.226   \u001b[0m | \u001b[95m 0.5058  \u001b[0m | \u001b[95m 436.6   \u001b[0m | \u001b[95m 10.95   \u001b[0m | \u001b[95m 180.5   \u001b[0m | \u001b[95m 31.02   \u001b[0m | \u001b[95m 52.37   \u001b[0m | \u001b[95m 7.436   \u001b[0m | \u001b[95m 7.924   \u001b[0m | \u001b[95m 0.9515  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 21.9264\ttraining's l2: 480.769\tvalid_1's rmse: 21.9831\tvalid_1's l2: 483.256\n",
      "[200]\ttraining's rmse: 7.61318\ttraining's l2: 57.9605\tvalid_1's rmse: 7.44349\tvalid_1's l2: 55.4056\n",
      "[300]\ttraining's rmse: 3.73301\ttraining's l2: 13.9354\tvalid_1's rmse: 3.34061\tvalid_1's l2: 11.1597\n",
      "[400]\ttraining's rmse: 2.74904\ttraining's l2: 7.55724\tvalid_1's rmse: 2.22483\tvalid_1's l2: 4.94986\n",
      "[500]\ttraining's rmse: 2.40875\ttraining's l2: 5.80206\tvalid_1's rmse: 1.82472\tvalid_1's l2: 3.32962\n",
      "[600]\ttraining's rmse: 2.25228\ttraining's l2: 5.07276\tvalid_1's rmse: 1.64947\tvalid_1's l2: 2.72074\n",
      "[700]\ttraining's rmse: 2.15305\ttraining's l2: 4.63563\tvalid_1's rmse: 1.54166\tvalid_1's l2: 2.37671\n",
      "[800]\ttraining's rmse: 2.08702\ttraining's l2: 4.35567\tvalid_1's rmse: 1.47164\tvalid_1's l2: 2.16572\n",
      "[900]\ttraining's rmse: 2.03996\ttraining's l2: 4.16144\tvalid_1's rmse: 1.42237\tvalid_1's l2: 2.02313\n",
      "[1000]\ttraining's rmse: 2.00174\ttraining's l2: 4.00694\tvalid_1's rmse: 1.38327\tvalid_1's l2: 1.91345\n",
      "[1100]\ttraining's rmse: 1.96949\ttraining's l2: 3.87889\tvalid_1's rmse: 1.35133\tvalid_1's l2: 1.82608\n",
      "[1200]\ttraining's rmse: 1.94389\ttraining's l2: 3.77873\tvalid_1's rmse: 1.32463\tvalid_1's l2: 1.75464\n",
      "[1300]\ttraining's rmse: 1.92051\ttraining's l2: 3.68837\tvalid_1's rmse: 1.30481\tvalid_1's l2: 1.70253\n",
      "[1400]\ttraining's rmse: 1.8999\ttraining's l2: 3.60963\tvalid_1's rmse: 1.28815\tvalid_1's l2: 1.65934\n",
      "[1500]\ttraining's rmse: 1.8829\ttraining's l2: 3.54529\tvalid_1's rmse: 1.2759\tvalid_1's l2: 1.62791\n",
      "[1600]\ttraining's rmse: 1.86784\ttraining's l2: 3.48882\tvalid_1's rmse: 1.26591\tvalid_1's l2: 1.60252\n",
      "[1700]\ttraining's rmse: 1.85475\ttraining's l2: 3.4401\tvalid_1's rmse: 1.25595\tvalid_1's l2: 1.57742\n",
      "[1800]\ttraining's rmse: 1.84262\ttraining's l2: 3.39526\tvalid_1's rmse: 1.24914\tvalid_1's l2: 1.56036\n",
      "[1900]\ttraining's rmse: 1.83264\ttraining's l2: 3.35856\tvalid_1's rmse: 1.24278\tvalid_1's l2: 1.54449\n",
      "[2000]\ttraining's rmse: 1.82195\ttraining's l2: 3.31951\tvalid_1's rmse: 1.23806\tvalid_1's l2: 1.53279\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.82195\ttraining's l2: 3.31951\tvalid_1's rmse: 1.23806\tvalid_1's l2: 1.53279\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 1.238   \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 432.8   \u001b[0m | \u001b[95m 11.57   \u001b[0m | \u001b[95m 179.4   \u001b[0m | \u001b[95m 31.52   \u001b[0m | \u001b[95m 62.33   \u001b[0m | \u001b[95m 5.286   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.6346  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 13.5137\ttraining's l2: 182.619\tvalid_1's rmse: 13.4412\tvalid_1's l2: 180.666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 3.85456\ttraining's l2: 14.8577\tvalid_1's rmse: 3.44705\tvalid_1's l2: 11.8821\n",
      "[300]\ttraining's rmse: 2.35961\ttraining's l2: 5.56776\tvalid_1's rmse: 1.70648\tvalid_1's l2: 2.91206\n",
      "[400]\ttraining's rmse: 2.1153\ttraining's l2: 4.47451\tvalid_1's rmse: 1.41293\tvalid_1's l2: 1.99638\n",
      "[500]\ttraining's rmse: 2.02206\ttraining's l2: 4.08874\tvalid_1's rmse: 1.30982\tvalid_1's l2: 1.71562\n",
      "[600]\ttraining's rmse: 1.96741\ttraining's l2: 3.87069\tvalid_1's rmse: 1.25135\tvalid_1's l2: 1.56588\n",
      "[700]\ttraining's rmse: 1.93574\ttraining's l2: 3.7471\tvalid_1's rmse: 1.21873\tvalid_1's l2: 1.48531\n",
      "[800]\ttraining's rmse: 1.90992\ttraining's l2: 3.64781\tvalid_1's rmse: 1.1964\tvalid_1's l2: 1.43136\n",
      "[900]\ttraining's rmse: 1.89034\ttraining's l2: 3.57338\tvalid_1's rmse: 1.18169\tvalid_1's l2: 1.39638\n",
      "[1000]\ttraining's rmse: 1.87428\ttraining's l2: 3.51291\tvalid_1's rmse: 1.1698\tvalid_1's l2: 1.36844\n",
      "[1100]\ttraining's rmse: 1.8625\ttraining's l2: 3.4689\tvalid_1's rmse: 1.16064\tvalid_1's l2: 1.34708\n",
      "[1200]\ttraining's rmse: 1.85131\ttraining's l2: 3.42736\tvalid_1's rmse: 1.15376\tvalid_1's l2: 1.33116\n",
      "[1300]\ttraining's rmse: 1.84082\ttraining's l2: 3.38864\tvalid_1's rmse: 1.14893\tvalid_1's l2: 1.32005\n",
      "[1400]\ttraining's rmse: 1.83002\ttraining's l2: 3.34898\tvalid_1's rmse: 1.1445\tvalid_1's l2: 1.30988\n",
      "[1500]\ttraining's rmse: 1.81855\ttraining's l2: 3.30714\tvalid_1's rmse: 1.14116\tvalid_1's l2: 1.30225\n",
      "[1600]\ttraining's rmse: 1.80788\ttraining's l2: 3.26844\tvalid_1's rmse: 1.13831\tvalid_1's l2: 1.29576\n",
      "[1700]\ttraining's rmse: 1.79825\ttraining's l2: 3.2337\tvalid_1's rmse: 1.13557\tvalid_1's l2: 1.28952\n",
      "[1800]\ttraining's rmse: 1.78916\ttraining's l2: 3.20108\tvalid_1's rmse: 1.13293\tvalid_1's l2: 1.28352\n",
      "[1900]\ttraining's rmse: 1.78086\ttraining's l2: 3.17145\tvalid_1's rmse: 1.13095\tvalid_1's l2: 1.27905\n",
      "[2000]\ttraining's rmse: 1.77223\ttraining's l2: 3.14079\tvalid_1's rmse: 1.13002\tvalid_1's l2: 1.27694\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.77223\ttraining's l2: 3.14079\tvalid_1's rmse: 1.13002\tvalid_1's l2: 1.27694\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 1.13    \u001b[0m | \u001b[0m 0.7445  \u001b[0m | \u001b[0m 427.6   \u001b[0m | \u001b[0m 14.06   \u001b[0m | \u001b[0m 173.4   \u001b[0m | \u001b[0m 42.57   \u001b[0m | \u001b[0m 62.6    \u001b[0m | \u001b[0m 10.95   \u001b[0m | \u001b[0m 8.893   \u001b[0m | \u001b[0m 0.6811  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 21.9591\ttraining's l2: 482.201\tvalid_1's rmse: 22.013\tvalid_1's l2: 484.574\n",
      "[200]\ttraining's rmse: 7.6047\ttraining's l2: 57.8315\tvalid_1's rmse: 7.42232\tvalid_1's l2: 55.0908\n",
      "[300]\ttraining's rmse: 3.68151\ttraining's l2: 13.5535\tvalid_1's rmse: 3.2742\tvalid_1's l2: 10.7204\n",
      "[400]\ttraining's rmse: 2.70826\ttraining's l2: 7.33468\tvalid_1's rmse: 2.16503\tvalid_1's l2: 4.68737\n",
      "[500]\ttraining's rmse: 2.38363\ttraining's l2: 5.68171\tvalid_1's rmse: 1.7798\tvalid_1's l2: 3.16768\n",
      "[600]\ttraining's rmse: 2.23713\ttraining's l2: 5.00474\tvalid_1's rmse: 1.61449\tvalid_1's l2: 2.60656\n",
      "[700]\ttraining's rmse: 2.14906\ttraining's l2: 4.61845\tvalid_1's rmse: 1.52161\tvalid_1's l2: 2.31531\n",
      "[800]\ttraining's rmse: 2.09035\ttraining's l2: 4.36956\tvalid_1's rmse: 1.46014\tvalid_1's l2: 2.13201\n",
      "[900]\ttraining's rmse: 2.04712\ttraining's l2: 4.19069\tvalid_1's rmse: 1.41291\tvalid_1's l2: 1.99632\n",
      "[1000]\ttraining's rmse: 2.01407\ttraining's l2: 4.05649\tvalid_1's rmse: 1.37902\tvalid_1's l2: 1.9017\n",
      "[1100]\ttraining's rmse: 1.98817\ttraining's l2: 3.95282\tvalid_1's rmse: 1.35346\tvalid_1's l2: 1.83185\n",
      "[1200]\ttraining's rmse: 1.96672\ttraining's l2: 3.86797\tvalid_1's rmse: 1.33113\tvalid_1's l2: 1.77191\n",
      "[1300]\ttraining's rmse: 1.94587\ttraining's l2: 3.78641\tvalid_1's rmse: 1.31347\tvalid_1's l2: 1.7252\n",
      "[1400]\ttraining's rmse: 1.92799\ttraining's l2: 3.71714\tvalid_1's rmse: 1.29699\tvalid_1's l2: 1.68219\n",
      "[1500]\ttraining's rmse: 1.91324\ttraining's l2: 3.66047\tvalid_1's rmse: 1.2864\tvalid_1's l2: 1.65482\n",
      "[1600]\ttraining's rmse: 1.90124\ttraining's l2: 3.61471\tvalid_1's rmse: 1.27681\tvalid_1's l2: 1.63024\n",
      "[1700]\ttraining's rmse: 1.88944\ttraining's l2: 3.57\tvalid_1's rmse: 1.26883\tvalid_1's l2: 1.60994\n",
      "[1800]\ttraining's rmse: 1.87788\ttraining's l2: 3.52644\tvalid_1's rmse: 1.2632\tvalid_1's l2: 1.59567\n",
      "[1900]\ttraining's rmse: 1.8682\ttraining's l2: 3.49015\tvalid_1's rmse: 1.25785\tvalid_1's l2: 1.58218\n",
      "[2000]\ttraining's rmse: 1.85855\ttraining's l2: 3.45421\tvalid_1's rmse: 1.25385\tvalid_1's l2: 1.57215\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.85855\ttraining's l2: 3.45421\tvalid_1's rmse: 1.25385\tvalid_1's l2: 1.57215\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 1.254   \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 448.3   \u001b[0m | \u001b[95m 8.0     \u001b[0m | \u001b[95m 180.4   \u001b[0m | \u001b[95m 29.28   \u001b[0m | \u001b[95m 63.86   \u001b[0m | \u001b[95m 4.669   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.5798  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 11.7574\ttraining's l2: 138.237\tvalid_1's rmse: 11.656\tvalid_1's l2: 135.863\n",
      "[200]\ttraining's rmse: 3.0731\ttraining's l2: 9.44395\tvalid_1's rmse: 2.60289\tvalid_1's l2: 6.77504\n",
      "[300]\ttraining's rmse: 2.01902\ttraining's l2: 4.07643\tvalid_1's rmse: 1.30978\tvalid_1's l2: 1.71552\n",
      "[400]\ttraining's rmse: 1.84468\ttraining's l2: 3.40285\tvalid_1's rmse: 1.11283\tvalid_1's l2: 1.23838\n",
      "[500]\ttraining's rmse: 1.77409\ttraining's l2: 3.14738\tvalid_1's rmse: 1.05069\tvalid_1's l2: 1.10395\n",
      "[600]\ttraining's rmse: 1.73282\ttraining's l2: 3.00268\tvalid_1's rmse: 1.01215\tvalid_1's l2: 1.02445\n",
      "[700]\ttraining's rmse: 1.706\ttraining's l2: 2.91043\tvalid_1's rmse: 0.992428\tvalid_1's l2: 0.984914\n",
      "[800]\ttraining's rmse: 1.68864\ttraining's l2: 2.85151\tvalid_1's rmse: 0.98645\tvalid_1's l2: 0.973083\n",
      "[900]\ttraining's rmse: 1.67454\ttraining's l2: 2.80409\tvalid_1's rmse: 0.976036\tvalid_1's l2: 0.952646\n",
      "[1000]\ttraining's rmse: 1.66426\ttraining's l2: 2.76975\tvalid_1's rmse: 0.968358\tvalid_1's l2: 0.937717\n",
      "[1100]\ttraining's rmse: 1.65519\ttraining's l2: 2.73966\tvalid_1's rmse: 0.959606\tvalid_1's l2: 0.920843\n",
      "[1200]\ttraining's rmse: 1.64761\ttraining's l2: 2.71462\tvalid_1's rmse: 0.954016\tvalid_1's l2: 0.910146\n",
      "[1300]\ttraining's rmse: 1.63923\ttraining's l2: 2.68706\tvalid_1's rmse: 0.949992\tvalid_1's l2: 0.902485\n",
      "[1400]\ttraining's rmse: 1.63094\ttraining's l2: 2.65997\tvalid_1's rmse: 0.948393\tvalid_1's l2: 0.899449\n",
      "Early stopping, best iteration is:\n",
      "[1366]\ttraining's rmse: 1.63406\ttraining's l2: 2.67014\tvalid_1's rmse: 0.947886\tvalid_1's l2: 0.898487\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9479  \u001b[0m | \u001b[0m 0.8032  \u001b[0m | \u001b[0m 289.9   \u001b[0m | \u001b[0m 14.48   \u001b[0m | \u001b[0m 135.2   \u001b[0m | \u001b[0m 29.54   \u001b[0m | \u001b[0m 49.69   \u001b[0m | \u001b[0m 9.132   \u001b[0m | \u001b[0m 6.842   \u001b[0m | \u001b[0m 0.9468  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 21.9306\ttraining's l2: 480.953\tvalid_1's rmse: 21.9872\tvalid_1's l2: 483.435\n",
      "[200]\ttraining's rmse: 7.61768\ttraining's l2: 58.0291\tvalid_1's rmse: 7.44665\tvalid_1's l2: 55.4525\n",
      "[300]\ttraining's rmse: 3.72258\ttraining's l2: 13.8576\tvalid_1's rmse: 3.3281\tvalid_1's l2: 11.0762\n",
      "[400]\ttraining's rmse: 2.74126\ttraining's l2: 7.5145\tvalid_1's rmse: 2.214\tvalid_1's l2: 4.90179\n",
      "[500]\ttraining's rmse: 2.40532\ttraining's l2: 5.78558\tvalid_1's rmse: 1.8188\tvalid_1's l2: 3.30805\n",
      "[600]\ttraining's rmse: 2.25332\ttraining's l2: 5.07746\tvalid_1's rmse: 1.64928\tvalid_1's l2: 2.72011\n",
      "[700]\ttraining's rmse: 2.15815\ttraining's l2: 4.65762\tvalid_1's rmse: 1.54496\tvalid_1's l2: 2.38689\n",
      "[800]\ttraining's rmse: 2.09335\ttraining's l2: 4.38213\tvalid_1's rmse: 1.47647\tvalid_1's l2: 2.17997\n",
      "[900]\ttraining's rmse: 2.05072\ttraining's l2: 4.20547\tvalid_1's rmse: 1.43185\tvalid_1's l2: 2.05021\n",
      "[1000]\ttraining's rmse: 2.01378\ttraining's l2: 4.05532\tvalid_1's rmse: 1.39194\tvalid_1's l2: 1.9375\n",
      "[1100]\ttraining's rmse: 1.98501\ttraining's l2: 3.94028\tvalid_1's rmse: 1.36328\tvalid_1's l2: 1.85853\n",
      "[1200]\ttraining's rmse: 1.95993\ttraining's l2: 3.84132\tvalid_1's rmse: 1.3365\tvalid_1's l2: 1.78622\n",
      "[1300]\ttraining's rmse: 1.93601\ttraining's l2: 3.74814\tvalid_1's rmse: 1.31624\tvalid_1's l2: 1.73249\n",
      "[1400]\ttraining's rmse: 1.91656\ttraining's l2: 3.67318\tvalid_1's rmse: 1.29983\tvalid_1's l2: 1.68957\n",
      "[1500]\ttraining's rmse: 1.9001\ttraining's l2: 3.61038\tvalid_1's rmse: 1.28852\tvalid_1's l2: 1.66028\n",
      "[1600]\ttraining's rmse: 1.88693\ttraining's l2: 3.56051\tvalid_1's rmse: 1.27856\tvalid_1's l2: 1.63471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1700]\ttraining's rmse: 1.8749\ttraining's l2: 3.51526\tvalid_1's rmse: 1.27063\tvalid_1's l2: 1.6145\n",
      "[1800]\ttraining's rmse: 1.86284\ttraining's l2: 3.47019\tvalid_1's rmse: 1.26259\tvalid_1's l2: 1.59413\n",
      "[1900]\ttraining's rmse: 1.85235\ttraining's l2: 3.4312\tvalid_1's rmse: 1.25597\tvalid_1's l2: 1.57747\n",
      "[2000]\ttraining's rmse: 1.84213\ttraining's l2: 3.39345\tvalid_1's rmse: 1.25065\tvalid_1's l2: 1.56413\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.84213\ttraining's l2: 3.39345\tvalid_1's rmse: 1.25065\tvalid_1's l2: 1.56413\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 1.251   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 440.0   \u001b[0m | \u001b[0m 9.872   \u001b[0m | \u001b[0m 188.9   \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 63.9    \u001b[0m | \u001b[0m 9.861   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 10.9324\ttraining's l2: 119.518\tvalid_1's rmse: 10.8125\tvalid_1's l2: 116.91\n",
      "[200]\ttraining's rmse: 2.76633\ttraining's l2: 7.65259\tvalid_1's rmse: 2.42179\tvalid_1's l2: 5.86505\n",
      "[300]\ttraining's rmse: 1.63743\ttraining's l2: 2.68117\tvalid_1's rmse: 1.29214\tvalid_1's l2: 1.66963\n",
      "[400]\ttraining's rmse: 1.4557\ttraining's l2: 2.11907\tvalid_1's rmse: 1.15409\tvalid_1's l2: 1.33192\n",
      "[500]\ttraining's rmse: 1.38945\ttraining's l2: 1.93058\tvalid_1's rmse: 1.11667\tvalid_1's l2: 1.24695\n",
      "[600]\ttraining's rmse: 1.35628\ttraining's l2: 1.83949\tvalid_1's rmse: 1.09951\tvalid_1's l2: 1.20891\n",
      "[700]\ttraining's rmse: 1.33154\ttraining's l2: 1.773\tvalid_1's rmse: 1.09176\tvalid_1's l2: 1.19193\n",
      "[800]\ttraining's rmse: 1.31197\ttraining's l2: 1.72126\tvalid_1's rmse: 1.0851\tvalid_1's l2: 1.17744\n",
      "[900]\ttraining's rmse: 1.29075\ttraining's l2: 1.66603\tvalid_1's rmse: 1.08298\tvalid_1's l2: 1.17286\n",
      "[1000]\ttraining's rmse: 1.27571\ttraining's l2: 1.62744\tvalid_1's rmse: 1.07774\tvalid_1's l2: 1.16153\n",
      "[1100]\ttraining's rmse: 1.264\ttraining's l2: 1.59771\tvalid_1's rmse: 1.0704\tvalid_1's l2: 1.14575\n",
      "[1200]\ttraining's rmse: 1.25389\ttraining's l2: 1.57225\tvalid_1's rmse: 1.06429\tvalid_1's l2: 1.13272\n",
      "[1300]\ttraining's rmse: 1.24479\ttraining's l2: 1.54951\tvalid_1's rmse: 1.06011\tvalid_1's l2: 1.12383\n",
      "[1400]\ttraining's rmse: 1.23737\ttraining's l2: 1.53109\tvalid_1's rmse: 1.05703\tvalid_1's l2: 1.1173\n",
      "[1500]\ttraining's rmse: 1.22902\ttraining's l2: 1.51049\tvalid_1's rmse: 1.05551\tvalid_1's l2: 1.1141\n",
      "[1600]\ttraining's rmse: 1.21938\ttraining's l2: 1.48688\tvalid_1's rmse: 1.05408\tvalid_1's l2: 1.11108\n",
      "[1700]\ttraining's rmse: 1.21198\ttraining's l2: 1.46889\tvalid_1's rmse: 1.05186\tvalid_1's l2: 1.1064\n",
      "[1800]\ttraining's rmse: 1.20327\ttraining's l2: 1.44786\tvalid_1's rmse: 1.05091\tvalid_1's l2: 1.10441\n",
      "[1900]\ttraining's rmse: 1.19649\ttraining's l2: 1.43159\tvalid_1's rmse: 1.04942\tvalid_1's l2: 1.10129\n",
      "[2000]\ttraining's rmse: 1.18999\ttraining's l2: 1.41607\tvalid_1's rmse: 1.04858\tvalid_1's l2: 1.09953\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.18999\ttraining's l2: 1.41607\tvalid_1's rmse: 1.04858\tvalid_1's l2: 1.09953\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 1.049   \u001b[0m | \u001b[0m 0.8227  \u001b[0m | \u001b[0m 418.8   \u001b[0m | \u001b[0m 9.865   \u001b[0m | \u001b[0m 51.9    \u001b[0m | \u001b[0m 10.05   \u001b[0m | \u001b[0m 55.87   \u001b[0m | \u001b[0m 15.55   \u001b[0m | \u001b[0m 8.403   \u001b[0m | \u001b[0m 0.9562  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 9.65949\ttraining's l2: 93.3058\tvalid_1's rmse: 9.49506\tvalid_1's l2: 90.1563\n",
      "[200]\ttraining's rmse: 2.693\ttraining's l2: 7.25226\tvalid_1's rmse: 2.03802\tvalid_1's l2: 4.15351\n",
      "[300]\ttraining's rmse: 2.1065\ttraining's l2: 4.43734\tvalid_1's rmse: 1.26594\tvalid_1's l2: 1.60262\n",
      "[400]\ttraining's rmse: 2.03754\ttraining's l2: 4.15156\tvalid_1's rmse: 1.19855\tvalid_1's l2: 1.43652\n",
      "[500]\ttraining's rmse: 2.00943\ttraining's l2: 4.03782\tvalid_1's rmse: 1.17255\tvalid_1's l2: 1.37488\n",
      "[600]\ttraining's rmse: 1.98906\ttraining's l2: 3.95637\tvalid_1's rmse: 1.15917\tvalid_1's l2: 1.34368\n",
      "[700]\ttraining's rmse: 1.97569\ttraining's l2: 3.90336\tvalid_1's rmse: 1.15182\tvalid_1's l2: 1.32669\n",
      "[800]\ttraining's rmse: 1.96624\ttraining's l2: 3.86608\tvalid_1's rmse: 1.1476\tvalid_1's l2: 1.31699\n",
      "[900]\ttraining's rmse: 1.9577\ttraining's l2: 3.83258\tvalid_1's rmse: 1.14479\tvalid_1's l2: 1.31054\n",
      "[1000]\ttraining's rmse: 1.94887\ttraining's l2: 3.7981\tvalid_1's rmse: 1.14268\tvalid_1's l2: 1.30571\n",
      "[1100]\ttraining's rmse: 1.94191\ttraining's l2: 3.771\tvalid_1's rmse: 1.14049\tvalid_1's l2: 1.30072\n",
      "[1200]\ttraining's rmse: 1.9353\ttraining's l2: 3.74539\tvalid_1's rmse: 1.13855\tvalid_1's l2: 1.2963\n",
      "[1300]\ttraining's rmse: 1.92839\ttraining's l2: 3.71867\tvalid_1's rmse: 1.13792\tvalid_1's l2: 1.29485\n",
      "[1400]\ttraining's rmse: 1.92112\ttraining's l2: 3.69069\tvalid_1's rmse: 1.13751\tvalid_1's l2: 1.29393\n",
      "Early stopping, best iteration is:\n",
      "[1382]\ttraining's rmse: 1.92284\ttraining's l2: 3.69731\tvalid_1's rmse: 1.13714\tvalid_1's l2: 1.29309\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 1.137   \u001b[0m | \u001b[0m 0.8724  \u001b[0m | \u001b[0m 453.7   \u001b[0m | \u001b[0m 14.56   \u001b[0m | \u001b[0m 197.2   \u001b[0m | \u001b[0m 20.31   \u001b[0m | \u001b[0m 51.93   \u001b[0m | \u001b[0m 12.21   \u001b[0m | \u001b[0m 2.734   \u001b[0m | \u001b[0m 0.9713  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 8.64424\ttraining's l2: 74.723\tvalid_1's rmse: 8.46702\tvalid_1's l2: 71.6904\n",
      "[200]\ttraining's rmse: 2.14198\ttraining's l2: 4.58807\tvalid_1's rmse: 1.45241\tvalid_1's l2: 2.10949\n",
      "[300]\ttraining's rmse: 1.71299\ttraining's l2: 2.93433\tvalid_1's rmse: 0.89076\tvalid_1's l2: 0.793453\n",
      "[400]\ttraining's rmse: 1.66149\ttraining's l2: 2.76054\tvalid_1's rmse: 0.881395\tvalid_1's l2: 0.776858\n",
      "[500]\ttraining's rmse: 1.64251\ttraining's l2: 2.69784\tvalid_1's rmse: 0.873457\tvalid_1's l2: 0.762927\n",
      "[600]\ttraining's rmse: 1.62048\ttraining's l2: 2.62595\tvalid_1's rmse: 0.884958\tvalid_1's l2: 0.783151\n",
      "Early stopping, best iteration is:\n",
      "[510]\ttraining's rmse: 1.64101\ttraining's l2: 2.69293\tvalid_1's rmse: 0.872444\tvalid_1's l2: 0.761158\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8724  \u001b[0m | \u001b[0m 0.9303  \u001b[0m | \u001b[0m 325.1   \u001b[0m | \u001b[0m 15.93   \u001b[0m | \u001b[0m 120.2   \u001b[0m | \u001b[0m 1.1     \u001b[0m | \u001b[0m 29.0    \u001b[0m | \u001b[0m 25.81   \u001b[0m | \u001b[0m 5.161   \u001b[0m | \u001b[0m 0.5704  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 12.3402\ttraining's l2: 152.281\tvalid_1's rmse: 12.2752\tvalid_1's l2: 150.681\n",
      "[200]\ttraining's rmse: 3.32363\ttraining's l2: 11.0465\tvalid_1's rmse: 3.08172\tvalid_1's l2: 9.49702\n",
      "[300]\ttraining's rmse: 1.81064\ttraining's l2: 3.27843\tvalid_1's rmse: 1.5287\tvalid_1's l2: 2.33691\n",
      "[400]\ttraining's rmse: 1.5184\ttraining's l2: 2.30555\tvalid_1's rmse: 1.26441\tvalid_1's l2: 1.59874\n",
      "[500]\ttraining's rmse: 1.41124\ttraining's l2: 1.99159\tvalid_1's rmse: 1.17989\tvalid_1's l2: 1.39215\n",
      "[600]\ttraining's rmse: 1.35669\ttraining's l2: 1.84062\tvalid_1's rmse: 1.14357\tvalid_1's l2: 1.30774\n",
      "[700]\ttraining's rmse: 1.32236\ttraining's l2: 1.74863\tvalid_1's rmse: 1.12633\tvalid_1's l2: 1.26862\n",
      "[800]\ttraining's rmse: 1.29314\ttraining's l2: 1.67222\tvalid_1's rmse: 1.11515\tvalid_1's l2: 1.24355\n",
      "[900]\ttraining's rmse: 1.26818\ttraining's l2: 1.60827\tvalid_1's rmse: 1.10769\tvalid_1's l2: 1.22699\n",
      "[1000]\ttraining's rmse: 1.24836\ttraining's l2: 1.5584\tvalid_1's rmse: 1.10352\tvalid_1's l2: 1.21775\n",
      "[1100]\ttraining's rmse: 1.23308\ttraining's l2: 1.52049\tvalid_1's rmse: 1.09413\tvalid_1's l2: 1.19712\n",
      "[1200]\ttraining's rmse: 1.2222\ttraining's l2: 1.49378\tvalid_1's rmse: 1.08682\tvalid_1's l2: 1.18118\n",
      "[1300]\ttraining's rmse: 1.21194\ttraining's l2: 1.4688\tvalid_1's rmse: 1.08136\tvalid_1's l2: 1.16934\n",
      "[1400]\ttraining's rmse: 1.20064\ttraining's l2: 1.44154\tvalid_1's rmse: 1.07975\tvalid_1's l2: 1.16586\n",
      "[1500]\ttraining's rmse: 1.19127\ttraining's l2: 1.41913\tvalid_1's rmse: 1.0764\tvalid_1's l2: 1.15863\n",
      "[1600]\ttraining's rmse: 1.18102\ttraining's l2: 1.39481\tvalid_1's rmse: 1.0748\tvalid_1's l2: 1.15519\n",
      "[1700]\ttraining's rmse: 1.17013\ttraining's l2: 1.36921\tvalid_1's rmse: 1.07273\tvalid_1's l2: 1.15074\n",
      "[1800]\ttraining's rmse: 1.16075\ttraining's l2: 1.34733\tvalid_1's rmse: 1.07155\tvalid_1's l2: 1.14821\n",
      "[1900]\ttraining's rmse: 1.15172\ttraining's l2: 1.32645\tvalid_1's rmse: 1.06979\tvalid_1's l2: 1.14445\n",
      "[2000]\ttraining's rmse: 1.14472\ttraining's l2: 1.31039\tvalid_1's rmse: 1.06689\tvalid_1's l2: 1.13826\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.14472\ttraining's l2: 1.31039\tvalid_1's rmse: 1.06689\tvalid_1's l2: 1.13826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 1.067   \u001b[0m | \u001b[0m 0.7405  \u001b[0m | \u001b[0m 120.1   \u001b[0m | \u001b[0m 12.94   \u001b[0m | \u001b[0m 53.76   \u001b[0m | \u001b[0m 42.68   \u001b[0m | \u001b[0m 47.66   \u001b[0m | \u001b[0m 10.66   \u001b[0m | \u001b[0m 1.986   \u001b[0m | \u001b[0m 0.8184  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 16.8908\ttraining's l2: 285.301\tvalid_1's rmse: 16.9083\tvalid_1's l2: 285.891\n",
      "[200]\ttraining's rmse: 6.34501\ttraining's l2: 40.2591\tvalid_1's rmse: 6.17211\tvalid_1's l2: 38.0949\n",
      "[300]\ttraining's rmse: 3.14998\ttraining's l2: 9.92237\tvalid_1's rmse: 2.78334\tvalid_1's l2: 7.74697\n",
      "[400]\ttraining's rmse: 2.27796\ttraining's l2: 5.18912\tvalid_1's rmse: 1.79265\tvalid_1's l2: 3.2136\n",
      "[500]\ttraining's rmse: 1.99118\ttraining's l2: 3.9648\tvalid_1's rmse: 1.45787\tvalid_1's l2: 2.12539\n",
      "[600]\ttraining's rmse: 1.85497\ttraining's l2: 3.44091\tvalid_1's rmse: 1.30732\tvalid_1's l2: 1.70907\n",
      "[700]\ttraining's rmse: 1.76828\ttraining's l2: 3.12683\tvalid_1's rmse: 1.22284\tvalid_1's l2: 1.49535\n",
      "[800]\ttraining's rmse: 1.71477\ttraining's l2: 2.94043\tvalid_1's rmse: 1.17344\tvalid_1's l2: 1.37695\n",
      "[900]\ttraining's rmse: 1.67524\ttraining's l2: 2.80643\tvalid_1's rmse: 1.13885\tvalid_1's l2: 1.29699\n",
      "[1000]\ttraining's rmse: 1.64751\ttraining's l2: 2.71428\tvalid_1's rmse: 1.1128\tvalid_1's l2: 1.23833\n",
      "[1100]\ttraining's rmse: 1.62255\ttraining's l2: 2.63265\tvalid_1's rmse: 1.09504\tvalid_1's l2: 1.19911\n",
      "[1200]\ttraining's rmse: 1.59462\ttraining's l2: 2.54282\tvalid_1's rmse: 1.08765\tvalid_1's l2: 1.18298\n",
      "[1300]\ttraining's rmse: 1.57118\ttraining's l2: 2.4686\tvalid_1's rmse: 1.08125\tvalid_1's l2: 1.16911\n",
      "[1400]\ttraining's rmse: 1.55446\ttraining's l2: 2.41634\tvalid_1's rmse: 1.07322\tvalid_1's l2: 1.1518\n",
      "[1500]\ttraining's rmse: 1.53801\ttraining's l2: 2.36546\tvalid_1's rmse: 1.06732\tvalid_1's l2: 1.13916\n",
      "[1600]\ttraining's rmse: 1.52252\ttraining's l2: 2.31805\tvalid_1's rmse: 1.06217\tvalid_1's l2: 1.1282\n",
      "[1700]\ttraining's rmse: 1.50778\ttraining's l2: 2.27339\tvalid_1's rmse: 1.06005\tvalid_1's l2: 1.1237\n",
      "[1800]\ttraining's rmse: 1.49409\ttraining's l2: 2.23231\tvalid_1's rmse: 1.05533\tvalid_1's l2: 1.11373\n",
      "[1900]\ttraining's rmse: 1.48169\ttraining's l2: 2.1954\tvalid_1's rmse: 1.05094\tvalid_1's l2: 1.10449\n",
      "[2000]\ttraining's rmse: 1.4698\ttraining's l2: 2.16031\tvalid_1's rmse: 1.04741\tvalid_1's l2: 1.09707\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.4698\ttraining's l2: 2.16031\tvalid_1's rmse: 1.04741\tvalid_1's l2: 1.09707\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 1.047   \u001b[0m | \u001b[0m 0.5286  \u001b[0m | \u001b[0m 456.4   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 96.72   \u001b[0m | \u001b[0m 41.56   \u001b[0m | \u001b[0m 61.51   \u001b[0m | \u001b[0m 29.92   \u001b[0m | \u001b[0m 3.57    \u001b[0m | \u001b[0m 0.8466  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 21.9636\ttraining's l2: 482.402\tvalid_1's rmse: 22.0151\tvalid_1's l2: 484.665\n",
      "[200]\ttraining's rmse: 7.60337\ttraining's l2: 57.8112\tvalid_1's rmse: 7.42372\tvalid_1's l2: 55.1116\n",
      "[300]\ttraining's rmse: 3.68143\ttraining's l2: 13.5529\tvalid_1's rmse: 3.27577\tvalid_1's l2: 10.7307\n",
      "[400]\ttraining's rmse: 2.70904\ttraining's l2: 7.33889\tvalid_1's rmse: 2.168\tvalid_1's l2: 4.70022\n",
      "[500]\ttraining's rmse: 2.38673\ttraining's l2: 5.69646\tvalid_1's rmse: 1.78978\tvalid_1's l2: 3.2033\n",
      "[600]\ttraining's rmse: 2.23838\ttraining's l2: 5.01034\tvalid_1's rmse: 1.62132\tvalid_1's l2: 2.62868\n",
      "[700]\ttraining's rmse: 2.14971\ttraining's l2: 4.62126\tvalid_1's rmse: 1.52625\tvalid_1's l2: 2.32944\n",
      "[800]\ttraining's rmse: 2.0877\ttraining's l2: 4.3585\tvalid_1's rmse: 1.46197\tvalid_1's l2: 2.13734\n",
      "[900]\ttraining's rmse: 2.04768\ttraining's l2: 4.19301\tvalid_1's rmse: 1.42003\tvalid_1's l2: 2.01649\n",
      "[1000]\ttraining's rmse: 2.01793\ttraining's l2: 4.07206\tvalid_1's rmse: 1.38893\tvalid_1's l2: 1.92912\n",
      "[1100]\ttraining's rmse: 1.99343\ttraining's l2: 3.97375\tvalid_1's rmse: 1.36591\tvalid_1's l2: 1.8657\n",
      "[1200]\ttraining's rmse: 1.96819\ttraining's l2: 3.87376\tvalid_1's rmse: 1.3404\tvalid_1's l2: 1.79668\n",
      "[1300]\ttraining's rmse: 1.94745\ttraining's l2: 3.79257\tvalid_1's rmse: 1.3218\tvalid_1's l2: 1.74715\n",
      "[1400]\ttraining's rmse: 1.928\ttraining's l2: 3.7172\tvalid_1's rmse: 1.30254\tvalid_1's l2: 1.6966\n",
      "[1500]\ttraining's rmse: 1.91366\ttraining's l2: 3.66209\tvalid_1's rmse: 1.29258\tvalid_1's l2: 1.67077\n",
      "[1600]\ttraining's rmse: 1.9016\ttraining's l2: 3.61608\tvalid_1's rmse: 1.28453\tvalid_1's l2: 1.65002\n",
      "[1700]\ttraining's rmse: 1.88985\ttraining's l2: 3.57152\tvalid_1's rmse: 1.27732\tvalid_1's l2: 1.63154\n",
      "[1800]\ttraining's rmse: 1.87819\ttraining's l2: 3.52759\tvalid_1's rmse: 1.27044\tvalid_1's l2: 1.61401\n",
      "[1900]\ttraining's rmse: 1.86818\ttraining's l2: 3.4901\tvalid_1's rmse: 1.26333\tvalid_1's l2: 1.59601\n",
      "[2000]\ttraining's rmse: 1.85822\ttraining's l2: 3.45297\tvalid_1's rmse: 1.25859\tvalid_1's l2: 1.58406\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.85822\ttraining's l2: 3.45297\tvalid_1's rmse: 1.25859\tvalid_1's l2: 1.58406\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 1.259   \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 441.7   \u001b[0m | \u001b[95m 8.0     \u001b[0m | \u001b[95m 182.1   \u001b[0m | \u001b[95m 25.47   \u001b[0m | \u001b[95m 64.0    \u001b[0m | \u001b[95m 25.36   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.70728\ttraining's l2: 59.4022\tvalid_1's rmse: 7.54697\tvalid_1's l2: 56.9568\n",
      "[200]\ttraining's rmse: 1.63554\ttraining's l2: 2.675\tvalid_1's rmse: 1.24711\tvalid_1's l2: 1.55529\n",
      "[300]\ttraining's rmse: 1.1348\ttraining's l2: 1.28778\tvalid_1's rmse: 0.774241\tvalid_1's l2: 0.59945\n",
      "Early stopping, best iteration is:\n",
      "[297]\ttraining's rmse: 1.13678\ttraining's l2: 1.29226\tvalid_1's rmse: 0.774035\tvalid_1's l2: 0.599131\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.774   \u001b[0m | \u001b[0m 0.9644  \u001b[0m | \u001b[0m 330.1   \u001b[0m | \u001b[0m 11.74   \u001b[0m | \u001b[0m 22.2    \u001b[0m | \u001b[0m 30.45   \u001b[0m | \u001b[0m 42.41   \u001b[0m | \u001b[0m 41.12   \u001b[0m | \u001b[0m 7.102   \u001b[0m | \u001b[0m 0.755   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 21.9688\ttraining's l2: 482.628\tvalid_1's rmse: 22.0193\tvalid_1's l2: 484.85\n",
      "[200]\ttraining's rmse: 7.63229\ttraining's l2: 58.2519\tvalid_1's rmse: 7.44677\tvalid_1's l2: 55.4543\n",
      "[300]\ttraining's rmse: 3.74391\ttraining's l2: 14.0169\tvalid_1's rmse: 3.31475\tvalid_1's l2: 10.9876\n",
      "[400]\ttraining's rmse: 2.7894\ttraining's l2: 7.78073\tvalid_1's rmse: 2.21618\tvalid_1's l2: 4.91147\n",
      "[500]\ttraining's rmse: 2.47556\ttraining's l2: 6.12838\tvalid_1's rmse: 1.84086\tvalid_1's l2: 3.38876\n",
      "[600]\ttraining's rmse: 2.32847\ttraining's l2: 5.42175\tvalid_1's rmse: 1.67379\tvalid_1's l2: 2.80157\n",
      "[700]\ttraining's rmse: 2.24252\ttraining's l2: 5.02889\tvalid_1's rmse: 1.58142\tvalid_1's l2: 2.50089\n",
      "[800]\ttraining's rmse: 2.1859\ttraining's l2: 4.77815\tvalid_1's rmse: 1.52101\tvalid_1's l2: 2.31346\n",
      "[900]\ttraining's rmse: 2.14818\ttraining's l2: 4.61468\tvalid_1's rmse: 1.47895\tvalid_1's l2: 2.18729\n",
      "[1000]\ttraining's rmse: 2.11688\ttraining's l2: 4.4812\tvalid_1's rmse: 1.44541\tvalid_1's l2: 2.0892\n",
      "[1100]\ttraining's rmse: 2.09179\ttraining's l2: 4.37557\tvalid_1's rmse: 1.4198\tvalid_1's l2: 2.01582\n",
      "[1200]\ttraining's rmse: 2.07017\ttraining's l2: 4.28558\tvalid_1's rmse: 1.39662\tvalid_1's l2: 1.95055\n",
      "[1300]\ttraining's rmse: 2.04899\ttraining's l2: 4.19837\tvalid_1's rmse: 1.37652\tvalid_1's l2: 1.89482\n",
      "[1400]\ttraining's rmse: 2.03136\ttraining's l2: 4.12641\tvalid_1's rmse: 1.36204\tvalid_1's l2: 1.85515\n",
      "[1500]\ttraining's rmse: 2.01542\ttraining's l2: 4.0619\tvalid_1's rmse: 1.34956\tvalid_1's l2: 1.8213\n",
      "[1600]\ttraining's rmse: 2.00171\ttraining's l2: 4.00683\tvalid_1's rmse: 1.33888\tvalid_1's l2: 1.79259\n",
      "[1700]\ttraining's rmse: 1.98956\ttraining's l2: 3.95835\tvalid_1's rmse: 1.3295\tvalid_1's l2: 1.76756\n",
      "[1800]\ttraining's rmse: 1.97755\ttraining's l2: 3.91072\tvalid_1's rmse: 1.32361\tvalid_1's l2: 1.75193\n",
      "[1900]\ttraining's rmse: 1.96632\ttraining's l2: 3.86641\tvalid_1's rmse: 1.31563\tvalid_1's l2: 1.73088\n",
      "[2000]\ttraining's rmse: 1.956\ttraining's l2: 3.82593\tvalid_1's rmse: 1.3101\tvalid_1's l2: 1.71636\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.956\ttraining's l2: 3.82593\tvalid_1's rmse: 1.3101\tvalid_1's l2: 1.71636\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m 1.31    \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 419.0   \u001b[0m | \u001b[95m 8.0     \u001b[0m | \u001b[95m 196.0   \u001b[0m | \u001b[95m 12.23   \u001b[0m | \u001b[95m 64.0    \u001b[0m | \u001b[95m 32.88   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 16.1678\ttraining's l2: 261.397\tvalid_1's rmse: 16.1384\tvalid_1's l2: 260.449\n",
      "[200]\ttraining's rmse: 4.72622\ttraining's l2: 22.3371\tvalid_1's rmse: 4.42065\tvalid_1's l2: 19.5421\n",
      "[300]\ttraining's rmse: 2.48286\ttraining's l2: 6.1646\tvalid_1's rmse: 1.94735\tvalid_1's l2: 3.79218\n",
      "[400]\ttraining's rmse: 2.04293\ttraining's l2: 4.17354\tvalid_1's rmse: 1.4449\tvalid_1's l2: 2.08774\n",
      "[500]\ttraining's rmse: 1.87079\ttraining's l2: 3.49985\tvalid_1's rmse: 1.25494\tvalid_1's l2: 1.57488\n",
      "[600]\ttraining's rmse: 1.78199\ttraining's l2: 3.17549\tvalid_1's rmse: 1.17202\tvalid_1's l2: 1.37364\n",
      "[700]\ttraining's rmse: 1.7282\ttraining's l2: 2.98669\tvalid_1's rmse: 1.1288\tvalid_1's l2: 1.2742\n",
      "[800]\ttraining's rmse: 1.69498\ttraining's l2: 2.87295\tvalid_1's rmse: 1.09758\tvalid_1's l2: 1.20468\n",
      "[900]\ttraining's rmse: 1.67058\ttraining's l2: 2.79083\tvalid_1's rmse: 1.07488\tvalid_1's l2: 1.15538\n",
      "[1000]\ttraining's rmse: 1.64836\ttraining's l2: 2.71708\tvalid_1's rmse: 1.05798\tvalid_1's l2: 1.11932\n",
      "[1100]\ttraining's rmse: 1.63266\ttraining's l2: 2.66558\tvalid_1's rmse: 1.04558\tvalid_1's l2: 1.09323\n",
      "[1200]\ttraining's rmse: 1.61713\ttraining's l2: 2.61513\tvalid_1's rmse: 1.03742\tvalid_1's l2: 1.07625\n",
      "[1300]\ttraining's rmse: 1.60422\ttraining's l2: 2.57352\tvalid_1's rmse: 1.02994\tvalid_1's l2: 1.06078\n",
      "[1400]\ttraining's rmse: 1.58974\ttraining's l2: 2.52728\tvalid_1's rmse: 1.02305\tvalid_1's l2: 1.04663\n",
      "[1500]\ttraining's rmse: 1.57826\ttraining's l2: 2.4909\tvalid_1's rmse: 1.01758\tvalid_1's l2: 1.03546\n",
      "[1600]\ttraining's rmse: 1.56811\ttraining's l2: 2.45897\tvalid_1's rmse: 1.01147\tvalid_1's l2: 1.02307\n",
      "[1700]\ttraining's rmse: 1.55886\ttraining's l2: 2.43005\tvalid_1's rmse: 1.00501\tvalid_1's l2: 1.01004\n",
      "[1800]\ttraining's rmse: 1.54984\ttraining's l2: 2.402\tvalid_1's rmse: 1.00192\tvalid_1's l2: 1.00384\n",
      "[1900]\ttraining's rmse: 1.54161\ttraining's l2: 2.37656\tvalid_1's rmse: 1.00051\tvalid_1's l2: 1.00103\n",
      "Early stopping, best iteration is:\n",
      "[1852]\ttraining's rmse: 1.54575\ttraining's l2: 2.38933\tvalid_1's rmse: 0.999497\tvalid_1's l2: 0.998994\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9995  \u001b[0m | \u001b[0m 0.6587  \u001b[0m | \u001b[0m 250.5   \u001b[0m | \u001b[0m 11.19   \u001b[0m | \u001b[0m 100.8   \u001b[0m | \u001b[0m 48.75   \u001b[0m | \u001b[0m 36.58   \u001b[0m | \u001b[0m 41.15   \u001b[0m | \u001b[0m 9.618   \u001b[0m | \u001b[0m 0.6229  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.41701\ttraining's l2: 55.012\tvalid_1's rmse: 7.17068\tvalid_1's l2: 51.4187\n",
      "[200]\ttraining's rmse: 2.17267\ttraining's l2: 4.72048\tvalid_1's rmse: 1.3517\tvalid_1's l2: 1.8271\n",
      "[300]\ttraining's rmse: 1.90777\ttraining's l2: 3.63959\tvalid_1's rmse: 1.01988\tvalid_1's l2: 1.04015\n",
      "Early stopping, best iteration is:\n",
      "[299]\ttraining's rmse: 1.90807\ttraining's l2: 3.64072\tvalid_1's rmse: 1.01984\tvalid_1's l2: 1.04007\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 1.02    \u001b[0m | \u001b[0m 0.9983  \u001b[0m | \u001b[0m 254.0   \u001b[0m | \u001b[0m 15.72   \u001b[0m | \u001b[0m 172.3   \u001b[0m | \u001b[0m 4.75    \u001b[0m | \u001b[0m 36.0    \u001b[0m | \u001b[0m 34.22   \u001b[0m | \u001b[0m 8.13    \u001b[0m | \u001b[0m 0.8197  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 7.68224\ttraining's l2: 59.0167\tvalid_1's rmse: 7.48363\tvalid_1's l2: 56.0047\n",
      "[200]\ttraining's rmse: 1.75752\ttraining's l2: 3.08887\tvalid_1's rmse: 1.28734\tvalid_1's l2: 1.65726\n",
      "[300]\ttraining's rmse: 1.32212\ttraining's l2: 1.74799\tvalid_1's rmse: 0.921812\tvalid_1's l2: 0.849737\n",
      "Early stopping, best iteration is:\n",
      "[272]\ttraining's rmse: 1.34696\ttraining's l2: 1.81429\tvalid_1's rmse: 0.913404\tvalid_1's l2: 0.834307\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.9134  \u001b[0m | \u001b[0m 0.9707  \u001b[0m | \u001b[0m 151.7   \u001b[0m | \u001b[0m 13.9    \u001b[0m | \u001b[0m 46.18   \u001b[0m | \u001b[0m 37.89   \u001b[0m | \u001b[0m 38.31   \u001b[0m | \u001b[0m 47.9    \u001b[0m | \u001b[0m 5.181   \u001b[0m | \u001b[0m 0.5227  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 10.6676\ttraining's l2: 113.797\tvalid_1's rmse: 10.5408\tvalid_1's l2: 111.109\n",
      "[200]\ttraining's rmse: 2.70437\ttraining's l2: 7.31363\tvalid_1's rmse: 2.19062\tvalid_1's l2: 4.7988\n",
      "[300]\ttraining's rmse: 1.84156\ttraining's l2: 3.39135\tvalid_1's rmse: 1.11839\tvalid_1's l2: 1.2508\n",
      "[400]\ttraining's rmse: 1.71298\ttraining's l2: 2.93429\tvalid_1's rmse: 1.00166\tvalid_1's l2: 1.00333\n",
      "[500]\ttraining's rmse: 1.65872\ttraining's l2: 2.75136\tvalid_1's rmse: 0.967399\tvalid_1's l2: 0.93586\n",
      "[600]\ttraining's rmse: 1.62776\ttraining's l2: 2.6496\tvalid_1's rmse: 0.948352\tvalid_1's l2: 0.899371\n",
      "[700]\ttraining's rmse: 1.6071\ttraining's l2: 2.58276\tvalid_1's rmse: 0.933185\tvalid_1's l2: 0.870835\n",
      "[800]\ttraining's rmse: 1.59327\ttraining's l2: 2.53852\tvalid_1's rmse: 0.922093\tvalid_1's l2: 0.850256\n",
      "[900]\ttraining's rmse: 1.58142\ttraining's l2: 2.50088\tvalid_1's rmse: 0.914195\tvalid_1's l2: 0.835752\n",
      "[1000]\ttraining's rmse: 1.57114\ttraining's l2: 2.4685\tvalid_1's rmse: 0.907399\tvalid_1's l2: 0.823373\n",
      "[1100]\ttraining's rmse: 1.56217\ttraining's l2: 2.44039\tvalid_1's rmse: 0.901947\tvalid_1's l2: 0.813508\n",
      "[1200]\ttraining's rmse: 1.55375\ttraining's l2: 2.41413\tvalid_1's rmse: 0.899335\tvalid_1's l2: 0.808804\n",
      "[1300]\ttraining's rmse: 1.54474\ttraining's l2: 2.38621\tvalid_1's rmse: 0.89896\tvalid_1's l2: 0.808129\n",
      "[1400]\ttraining's rmse: 1.53576\ttraining's l2: 2.35857\tvalid_1's rmse: 0.899888\tvalid_1's l2: 0.809799\n",
      "Early stopping, best iteration is:\n",
      "[1355]\ttraining's rmse: 1.54028\ttraining's l2: 2.37247\tvalid_1's rmse: 0.898013\tvalid_1's l2: 0.806428\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.898   \u001b[0m | \u001b[0m 0.8324  \u001b[0m | \u001b[0m 52.63   \u001b[0m | \u001b[0m 14.83   \u001b[0m | \u001b[0m 100.8   \u001b[0m | \u001b[0m 22.84   \u001b[0m | \u001b[0m 59.28   \u001b[0m | \u001b[0m 25.3    \u001b[0m | \u001b[0m 7.74    \u001b[0m | \u001b[0m 0.9656  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 21.9726\ttraining's l2: 482.794\tvalid_1's rmse: 22.0235\tvalid_1's l2: 485.032\n",
      "[200]\ttraining's rmse: 7.6371\ttraining's l2: 58.3253\tvalid_1's rmse: 7.44786\tvalid_1's l2: 55.4707\n",
      "[300]\ttraining's rmse: 3.74717\ttraining's l2: 14.0413\tvalid_1's rmse: 3.31514\tvalid_1's l2: 10.9902\n",
      "[400]\ttraining's rmse: 2.79167\ttraining's l2: 7.79343\tvalid_1's rmse: 2.21583\tvalid_1's l2: 4.90988\n",
      "[500]\ttraining's rmse: 2.47662\ttraining's l2: 6.13363\tvalid_1's rmse: 1.84039\tvalid_1's l2: 3.38705\n",
      "[600]\ttraining's rmse: 2.33328\ttraining's l2: 5.44419\tvalid_1's rmse: 1.67883\tvalid_1's l2: 2.81847\n",
      "[700]\ttraining's rmse: 2.24921\ttraining's l2: 5.05893\tvalid_1's rmse: 1.58717\tvalid_1's l2: 2.51911\n",
      "[800]\ttraining's rmse: 2.19377\ttraining's l2: 4.81262\tvalid_1's rmse: 1.52874\tvalid_1's l2: 2.33706\n",
      "[900]\ttraining's rmse: 2.15509\ttraining's l2: 4.64441\tvalid_1's rmse: 1.48657\tvalid_1's l2: 2.20988\n",
      "[1000]\ttraining's rmse: 2.12373\ttraining's l2: 4.51023\tvalid_1's rmse: 1.45277\tvalid_1's l2: 2.11053\n",
      "[1100]\ttraining's rmse: 2.09727\ttraining's l2: 4.39856\tvalid_1's rmse: 1.4257\tvalid_1's l2: 2.03261\n",
      "[1200]\ttraining's rmse: 2.07656\ttraining's l2: 4.3121\tvalid_1's rmse: 1.40475\tvalid_1's l2: 1.97333\n",
      "[1300]\ttraining's rmse: 2.05247\ttraining's l2: 4.21264\tvalid_1's rmse: 1.38225\tvalid_1's l2: 1.91061\n",
      "[1400]\ttraining's rmse: 2.03508\ttraining's l2: 4.14155\tvalid_1's rmse: 1.3661\tvalid_1's l2: 1.86622\n",
      "[1500]\ttraining's rmse: 2.019\ttraining's l2: 4.07635\tvalid_1's rmse: 1.35398\tvalid_1's l2: 1.83325\n",
      "[1600]\ttraining's rmse: 2.00466\ttraining's l2: 4.01868\tvalid_1's rmse: 1.34412\tvalid_1's l2: 1.80665\n",
      "[1700]\ttraining's rmse: 1.99231\ttraining's l2: 3.9693\tvalid_1's rmse: 1.33563\tvalid_1's l2: 1.78392\n",
      "[1800]\ttraining's rmse: 1.97892\ttraining's l2: 3.91614\tvalid_1's rmse: 1.32608\tvalid_1's l2: 1.75848\n",
      "[1900]\ttraining's rmse: 1.96873\ttraining's l2: 3.8759\tvalid_1's rmse: 1.31872\tvalid_1's l2: 1.73902\n",
      "[2000]\ttraining's rmse: 1.95752\ttraining's l2: 3.83188\tvalid_1's rmse: 1.31332\tvalid_1's l2: 1.7248\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.95752\ttraining's l2: 3.83188\tvalid_1's rmse: 1.31332\tvalid_1's l2: 1.7248\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m 1.313   \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 435.4   \u001b[0m | \u001b[95m 8.0     \u001b[0m | \u001b[95m 196.8   \u001b[0m | \u001b[95m 1.135   \u001b[0m | \u001b[95m 64.0    \u001b[0m | \u001b[95m 47.14   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 21.7112\ttraining's l2: 471.377\tvalid_1's rmse: 21.7716\tvalid_1's l2: 474.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 7.48049\ttraining's l2: 55.9577\tvalid_1's rmse: 7.30272\tvalid_1's l2: 53.3297\n",
      "[300]\ttraining's rmse: 3.70213\ttraining's l2: 13.7058\tvalid_1's rmse: 3.28369\tvalid_1's l2: 10.7826\n",
      "[400]\ttraining's rmse: 2.78613\ttraining's l2: 7.76251\tvalid_1's rmse: 2.22962\tvalid_1's l2: 4.97122\n",
      "[500]\ttraining's rmse: 2.47455\ttraining's l2: 6.12338\tvalid_1's rmse: 1.85533\tvalid_1's l2: 3.44226\n",
      "[600]\ttraining's rmse: 2.33256\ttraining's l2: 5.44084\tvalid_1's rmse: 1.69152\tvalid_1's l2: 2.86125\n",
      "[700]\ttraining's rmse: 2.24467\ttraining's l2: 5.03855\tvalid_1's rmse: 1.59549\tvalid_1's l2: 2.54559\n",
      "[800]\ttraining's rmse: 2.19002\ttraining's l2: 4.79617\tvalid_1's rmse: 1.53675\tvalid_1's l2: 2.36159\n",
      "[900]\ttraining's rmse: 2.15278\ttraining's l2: 4.63446\tvalid_1's rmse: 1.49529\tvalid_1's l2: 2.23588\n",
      "[1000]\ttraining's rmse: 2.12235\ttraining's l2: 4.50435\tvalid_1's rmse: 1.46292\tvalid_1's l2: 2.14013\n",
      "[1100]\ttraining's rmse: 2.09422\ttraining's l2: 4.38576\tvalid_1's rmse: 1.43258\tvalid_1's l2: 2.05229\n",
      "[1200]\ttraining's rmse: 2.06458\ttraining's l2: 4.26251\tvalid_1's rmse: 1.40164\tvalid_1's l2: 1.96458\n",
      "[1300]\ttraining's rmse: 2.04244\ttraining's l2: 4.17157\tvalid_1's rmse: 1.38008\tvalid_1's l2: 1.90463\n",
      "[1400]\ttraining's rmse: 2.02603\ttraining's l2: 4.1048\tvalid_1's rmse: 1.36518\tvalid_1's l2: 1.86371\n",
      "[1500]\ttraining's rmse: 2.00967\ttraining's l2: 4.03879\tvalid_1's rmse: 1.35322\tvalid_1's l2: 1.83122\n",
      "[1600]\ttraining's rmse: 1.99679\ttraining's l2: 3.98718\tvalid_1's rmse: 1.34318\tvalid_1's l2: 1.80414\n",
      "[1700]\ttraining's rmse: 1.9859\ttraining's l2: 3.94382\tvalid_1's rmse: 1.33653\tvalid_1's l2: 1.78632\n",
      "[1800]\ttraining's rmse: 1.97465\ttraining's l2: 3.89925\tvalid_1's rmse: 1.33044\tvalid_1's l2: 1.77008\n",
      "[1900]\ttraining's rmse: 1.96343\ttraining's l2: 3.85508\tvalid_1's rmse: 1.32424\tvalid_1's l2: 1.75362\n",
      "[2000]\ttraining's rmse: 1.95259\ttraining's l2: 3.81261\tvalid_1's rmse: 1.31784\tvalid_1's l2: 1.7367\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.95259\ttraining's l2: 3.81261\tvalid_1's rmse: 1.31784\tvalid_1's l2: 1.7367\n",
      "| \u001b[95m 26      \u001b[0m | \u001b[95m 1.318   \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 428.5   \u001b[0m | \u001b[95m 8.0     \u001b[0m | \u001b[95m 200.0   \u001b[0m | \u001b[95m 24.22   \u001b[0m | \u001b[95m 64.0    \u001b[0m | \u001b[95m 50.0    \u001b[0m | \u001b[95m 0.001   \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 22.027\ttraining's l2: 485.187\tvalid_1's rmse: 22.0612\tvalid_1's l2: 486.696\n",
      "[200]\ttraining's rmse: 7.65466\ttraining's l2: 58.5938\tvalid_1's rmse: 7.44306\tvalid_1's l2: 55.3991\n",
      "[300]\ttraining's rmse: 3.75746\ttraining's l2: 14.1185\tvalid_1's rmse: 3.29904\tvalid_1's l2: 10.8837\n",
      "[400]\ttraining's rmse: 2.78606\ttraining's l2: 7.76211\tvalid_1's rmse: 2.1822\tvalid_1's l2: 4.76201\n",
      "[500]\ttraining's rmse: 2.46099\ttraining's l2: 6.05649\tvalid_1's rmse: 1.79523\tvalid_1's l2: 3.22287\n",
      "[600]\ttraining's rmse: 2.31962\ttraining's l2: 5.38064\tvalid_1's rmse: 1.63143\tvalid_1's l2: 2.66157\n",
      "[700]\ttraining's rmse: 2.23204\ttraining's l2: 4.98199\tvalid_1's rmse: 1.53459\tvalid_1's l2: 2.35497\n",
      "[800]\ttraining's rmse: 2.17634\ttraining's l2: 4.73645\tvalid_1's rmse: 1.47372\tvalid_1's l2: 2.17185\n",
      "[900]\ttraining's rmse: 2.13754\ttraining's l2: 4.56909\tvalid_1's rmse: 1.43207\tvalid_1's l2: 2.05083\n",
      "[1000]\ttraining's rmse: 2.10593\ttraining's l2: 4.43493\tvalid_1's rmse: 1.39732\tvalid_1's l2: 1.95249\n",
      "[1100]\ttraining's rmse: 2.08188\ttraining's l2: 4.33421\tvalid_1's rmse: 1.37093\tvalid_1's l2: 1.87944\n",
      "[1200]\ttraining's rmse: 2.06243\ttraining's l2: 4.25363\tvalid_1's rmse: 1.35189\tvalid_1's l2: 1.82759\n",
      "[1300]\ttraining's rmse: 2.04475\ttraining's l2: 4.18102\tvalid_1's rmse: 1.33595\tvalid_1's l2: 1.78476\n",
      "[1400]\ttraining's rmse: 2.02998\ttraining's l2: 4.12082\tvalid_1's rmse: 1.32359\tvalid_1's l2: 1.75188\n",
      "[1500]\ttraining's rmse: 2.01667\ttraining's l2: 4.06697\tvalid_1's rmse: 1.3146\tvalid_1's l2: 1.72817\n",
      "[1600]\ttraining's rmse: 2.00499\ttraining's l2: 4.01998\tvalid_1's rmse: 1.30778\tvalid_1's l2: 1.71028\n",
      "[1700]\ttraining's rmse: 1.99348\ttraining's l2: 3.97395\tvalid_1's rmse: 1.30168\tvalid_1's l2: 1.69436\n",
      "[1800]\ttraining's rmse: 1.9822\ttraining's l2: 3.92912\tvalid_1's rmse: 1.29648\tvalid_1's l2: 1.68085\n",
      "[1900]\ttraining's rmse: 1.97181\ttraining's l2: 3.88804\tvalid_1's rmse: 1.28986\tvalid_1's l2: 1.66375\n",
      "[2000]\ttraining's rmse: 1.96214\ttraining's l2: 3.84999\tvalid_1's rmse: 1.28479\tvalid_1's l2: 1.65068\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.96214\ttraining's l2: 3.84999\tvalid_1's rmse: 1.28479\tvalid_1's l2: 1.65068\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 1.285   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 421.6   \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 12.34   \u001b[0m | \u001b[0m 38.85   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 21.7112\ttraining's l2: 471.377\tvalid_1's rmse: 21.7716\tvalid_1's l2: 474.004\n",
      "[200]\ttraining's rmse: 7.48049\ttraining's l2: 55.9577\tvalid_1's rmse: 7.30272\tvalid_1's l2: 53.3297\n",
      "[300]\ttraining's rmse: 3.70213\ttraining's l2: 13.7058\tvalid_1's rmse: 3.28369\tvalid_1's l2: 10.7826\n",
      "[400]\ttraining's rmse: 2.78613\ttraining's l2: 7.76251\tvalid_1's rmse: 2.22962\tvalid_1's l2: 4.97122\n",
      "[500]\ttraining's rmse: 2.47455\ttraining's l2: 6.12338\tvalid_1's rmse: 1.85533\tvalid_1's l2: 3.44226\n",
      "[600]\ttraining's rmse: 2.33256\ttraining's l2: 5.44084\tvalid_1's rmse: 1.69152\tvalid_1's l2: 2.86125\n",
      "[700]\ttraining's rmse: 2.24467\ttraining's l2: 5.03855\tvalid_1's rmse: 1.59549\tvalid_1's l2: 2.54559\n",
      "[800]\ttraining's rmse: 2.19002\ttraining's l2: 4.79617\tvalid_1's rmse: 1.53675\tvalid_1's l2: 2.36159\n",
      "[900]\ttraining's rmse: 2.15278\ttraining's l2: 4.63446\tvalid_1's rmse: 1.49529\tvalid_1's l2: 2.23588\n",
      "[1000]\ttraining's rmse: 2.12235\ttraining's l2: 4.50435\tvalid_1's rmse: 1.46292\tvalid_1's l2: 2.14013\n",
      "[1100]\ttraining's rmse: 2.09422\ttraining's l2: 4.38576\tvalid_1's rmse: 1.43258\tvalid_1's l2: 2.05229\n",
      "[1200]\ttraining's rmse: 2.06458\ttraining's l2: 4.26251\tvalid_1's rmse: 1.40164\tvalid_1's l2: 1.96458\n",
      "[1300]\ttraining's rmse: 2.04244\ttraining's l2: 4.17157\tvalid_1's rmse: 1.38008\tvalid_1's l2: 1.90463\n",
      "[1400]\ttraining's rmse: 2.02603\ttraining's l2: 4.1048\tvalid_1's rmse: 1.36518\tvalid_1's l2: 1.86371\n",
      "[1500]\ttraining's rmse: 2.00967\ttraining's l2: 4.03879\tvalid_1's rmse: 1.35322\tvalid_1's l2: 1.83122\n",
      "[1600]\ttraining's rmse: 1.99679\ttraining's l2: 3.98718\tvalid_1's rmse: 1.34318\tvalid_1's l2: 1.80414\n",
      "[1700]\ttraining's rmse: 1.9859\ttraining's l2: 3.94382\tvalid_1's rmse: 1.33653\tvalid_1's l2: 1.78632\n",
      "[1800]\ttraining's rmse: 1.97465\ttraining's l2: 3.89925\tvalid_1's rmse: 1.33044\tvalid_1's l2: 1.77008\n",
      "[1900]\ttraining's rmse: 1.96343\ttraining's l2: 3.85508\tvalid_1's rmse: 1.32424\tvalid_1's l2: 1.75362\n",
      "[2000]\ttraining's rmse: 1.95259\ttraining's l2: 3.81261\tvalid_1's rmse: 1.31784\tvalid_1's l2: 1.7367\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.95259\ttraining's l2: 3.81261\tvalid_1's rmse: 1.31784\tvalid_1's l2: 1.7367\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 1.318   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 401.3   \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 21.9724\ttraining's l2: 482.786\tvalid_1's rmse: 22.0241\tvalid_1's l2: 485.062\n",
      "[200]\ttraining's rmse: 7.63731\ttraining's l2: 58.3285\tvalid_1's rmse: 7.44924\tvalid_1's l2: 55.4912\n",
      "[300]\ttraining's rmse: 3.74646\ttraining's l2: 14.036\tvalid_1's rmse: 3.31483\tvalid_1's l2: 10.9881\n",
      "[400]\ttraining's rmse: 2.79293\ttraining's l2: 7.80048\tvalid_1's rmse: 2.21716\tvalid_1's l2: 4.91579\n",
      "[500]\ttraining's rmse: 2.47734\ttraining's l2: 6.13723\tvalid_1's rmse: 1.84001\tvalid_1's l2: 3.38565\n",
      "[600]\ttraining's rmse: 2.33497\ttraining's l2: 5.4521\tvalid_1's rmse: 1.67747\tvalid_1's l2: 2.81389\n",
      "[700]\ttraining's rmse: 2.24788\ttraining's l2: 5.05296\tvalid_1's rmse: 1.58317\tvalid_1's l2: 2.50644\n",
      "[800]\ttraining's rmse: 2.19004\ttraining's l2: 4.79628\tvalid_1's rmse: 1.52103\tvalid_1's l2: 2.31353\n",
      "[900]\ttraining's rmse: 2.15281\ttraining's l2: 4.6346\tvalid_1's rmse: 1.47882\tvalid_1's l2: 2.18691\n",
      "[1000]\ttraining's rmse: 2.1202\ttraining's l2: 4.49524\tvalid_1's rmse: 1.44485\tvalid_1's l2: 2.08758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1100]\ttraining's rmse: 2.09535\ttraining's l2: 4.39051\tvalid_1's rmse: 1.42063\tvalid_1's l2: 2.0182\n",
      "[1200]\ttraining's rmse: 2.07203\ttraining's l2: 4.29332\tvalid_1's rmse: 1.39539\tvalid_1's l2: 1.94712\n",
      "[1300]\ttraining's rmse: 2.04948\ttraining's l2: 4.20039\tvalid_1's rmse: 1.37312\tvalid_1's l2: 1.88546\n",
      "[1400]\ttraining's rmse: 2.03165\ttraining's l2: 4.12761\tvalid_1's rmse: 1.35664\tvalid_1's l2: 1.84048\n",
      "[1500]\ttraining's rmse: 2.01674\ttraining's l2: 4.06723\tvalid_1's rmse: 1.34505\tvalid_1's l2: 1.80916\n",
      "[1600]\ttraining's rmse: 2.00124\ttraining's l2: 4.00496\tvalid_1's rmse: 1.33358\tvalid_1's l2: 1.77844\n",
      "[1700]\ttraining's rmse: 1.98848\ttraining's l2: 3.95404\tvalid_1's rmse: 1.32673\tvalid_1's l2: 1.76022\n",
      "[1800]\ttraining's rmse: 1.97674\ttraining's l2: 3.90752\tvalid_1's rmse: 1.32134\tvalid_1's l2: 1.74593\n",
      "[1900]\ttraining's rmse: 1.96584\ttraining's l2: 3.86454\tvalid_1's rmse: 1.31526\tvalid_1's l2: 1.7299\n",
      "[2000]\ttraining's rmse: 1.95535\ttraining's l2: 3.8234\tvalid_1's rmse: 1.31041\tvalid_1's l2: 1.71718\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.95535\ttraining's l2: 3.8234\tvalid_1's rmse: 1.31041\tvalid_1's l2: 1.71718\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 1.31    \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 390.6   \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 32.29   \u001b[0m | \u001b[0m 64.0    \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 22.0347\ttraining's l2: 485.526\tvalid_1's rmse: 22.0658\tvalid_1's l2: 486.901\n",
      "[200]\ttraining's rmse: 7.65493\ttraining's l2: 58.5979\tvalid_1's rmse: 7.44269\tvalid_1's l2: 55.3936\n",
      "[300]\ttraining's rmse: 3.75829\ttraining's l2: 14.1247\tvalid_1's rmse: 3.29988\tvalid_1's l2: 10.8892\n",
      "[400]\ttraining's rmse: 2.78469\ttraining's l2: 7.75452\tvalid_1's rmse: 2.18168\tvalid_1's l2: 4.75973\n",
      "[500]\ttraining's rmse: 2.46017\ttraining's l2: 6.05245\tvalid_1's rmse: 1.79327\tvalid_1's l2: 3.21582\n",
      "[600]\ttraining's rmse: 2.3172\ttraining's l2: 5.36943\tvalid_1's rmse: 1.62594\tvalid_1's l2: 2.64367\n",
      "[700]\ttraining's rmse: 2.22745\ttraining's l2: 4.96155\tvalid_1's rmse: 1.5255\tvalid_1's l2: 2.32714\n",
      "[800]\ttraining's rmse: 2.17287\ttraining's l2: 4.72138\tvalid_1's rmse: 1.46674\tvalid_1's l2: 2.15133\n",
      "[900]\ttraining's rmse: 2.13521\ttraining's l2: 4.55913\tvalid_1's rmse: 1.42554\tvalid_1's l2: 2.03218\n",
      "[1000]\ttraining's rmse: 2.10354\ttraining's l2: 4.42487\tvalid_1's rmse: 1.3906\tvalid_1's l2: 1.93377\n",
      "[1100]\ttraining's rmse: 2.07778\ttraining's l2: 4.31717\tvalid_1's rmse: 1.36396\tvalid_1's l2: 1.86039\n",
      "[1200]\ttraining's rmse: 2.05779\ttraining's l2: 4.2345\tvalid_1's rmse: 1.34208\tvalid_1's l2: 1.80118\n",
      "[1300]\ttraining's rmse: 2.041\ttraining's l2: 4.16569\tvalid_1's rmse: 1.32749\tvalid_1's l2: 1.76223\n",
      "[1400]\ttraining's rmse: 2.02588\ttraining's l2: 4.1042\tvalid_1's rmse: 1.31355\tvalid_1's l2: 1.72541\n",
      "[1500]\ttraining's rmse: 2.01363\ttraining's l2: 4.0547\tvalid_1's rmse: 1.30442\tvalid_1's l2: 1.70151\n",
      "[1600]\ttraining's rmse: 2.00182\ttraining's l2: 4.00728\tvalid_1's rmse: 1.29721\tvalid_1's l2: 1.68275\n",
      "[1700]\ttraining's rmse: 1.99117\ttraining's l2: 3.96477\tvalid_1's rmse: 1.29122\tvalid_1's l2: 1.66725\n",
      "[1800]\ttraining's rmse: 1.98042\ttraining's l2: 3.92208\tvalid_1's rmse: 1.28686\tvalid_1's l2: 1.65601\n",
      "[1900]\ttraining's rmse: 1.9707\ttraining's l2: 3.88367\tvalid_1's rmse: 1.28161\tvalid_1's l2: 1.64253\n",
      "[2000]\ttraining's rmse: 1.96127\ttraining's l2: 3.84656\tvalid_1's rmse: 1.27765\tvalid_1's l2: 1.63239\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.96127\ttraining's l2: 3.84656\tvalid_1's rmse: 1.27765\tvalid_1's l2: 1.63239\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 1.278   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 372.7   \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 9.671   \u001b[0m | \u001b[0m 36.75   \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(f=lgb_rmse_eval, pbounds=bayesian_params, random_state=0)\n",
    "lgbBO.maximize(init_points=5, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 0.9161836673708834,\n",
       "  'params': {'colsample_bytree': 0.7744067519636624,\n",
       "   'max_bin': 360.44278952248555,\n",
       "   'max_depth': 12.822107008573152,\n",
       "   'min_child_samples': 113.52780476941041,\n",
       "   'min_child_weight': 21.75908516760633,\n",
       "   'num_leaves': 49.835764522666246,\n",
       "   'reg_alpha': 21.884984691022,\n",
       "   'reg_lambda': 8.917838234820016,\n",
       "   'subsample': 0.9818313802505146}},\n",
       " {'target': 0.9611643394160162,\n",
       "  'params': {'colsample_bytree': 0.6917207594128889,\n",
       "   'max_bin': 397.94526866050563,\n",
       "   'max_depth': 12.231159358023236,\n",
       "   'min_child_samples': 117.92846660784714,\n",
       "   'min_child_weight': 46.35423527634039,\n",
       "   'num_leaves': 26.841442327915477,\n",
       "   'reg_alpha': 4.36559369208002,\n",
       "   'reg_lambda': 0.20316375600581688,\n",
       "   'subsample': 0.916309922773969}},\n",
       " {'target': 1.0095951856424543,\n",
       "  'params': {'colsample_bytree': 0.8890783754749252,\n",
       "   'max_bin': 436.30595264094137,\n",
       "   'max_depth': 15.828946737862111,\n",
       "   'min_child_samples': 161.8401272011775,\n",
       "   'min_child_weight': 23.61248875039366,\n",
       "   'num_leaves': 55.22116705145822,\n",
       "   'reg_alpha': 5.922538549187972,\n",
       "   'reg_lambda': 6.3995702922539115,\n",
       "   'subsample': 0.5716766437045232}},\n",
       " {'target': 0.9166972406402161,\n",
       "  'params': {'colsample_bytree': 0.972334458524792,\n",
       "   'max_bin': 265.70567765753515,\n",
       "   'max_depth': 11.317295519924189,\n",
       "   'min_child_samples': 60.265566299879126,\n",
       "   'min_child_weight': 38.93745078227661,\n",
       "   'num_leaves': 42.24601328866194,\n",
       "   'reg_alpha': 28.426013103943742,\n",
       "   'reg_lambda': 0.18887921456311507,\n",
       "   'subsample': 0.8088177485379385}},\n",
       " {'target': 1.0282347581873081,\n",
       "  'params': {'colsample_bytree': 0.8060478613612108,\n",
       "   'max_bin': 312.2976584686309,\n",
       "   'max_depth': 15.549984628116993,\n",
       "   'min_child_samples': 139.54585682966186,\n",
       "   'min_child_weight': 18.615887128115514,\n",
       "   'num_leaves': 41.481278151973655,\n",
       "   'reg_alpha': 34.88458348440397,\n",
       "   'reg_lambda': 0.6031944908210691,\n",
       "   'subsample': 0.8333833577228338}},\n",
       " {'target': 1.1795221649596168,\n",
       "  'params': {'colsample_bytree': 0.640481830861817,\n",
       "   'max_bin': 435.0379450370509,\n",
       "   'max_depth': 13.997795806557395,\n",
       "   'min_child_samples': 169.30259380663517,\n",
       "   'min_child_weight': 26.924368410534857,\n",
       "   'num_leaves': 57.69153705029583,\n",
       "   'reg_alpha': 5.7675960060342195,\n",
       "   'reg_lambda': 9.196441703351635,\n",
       "   'subsample': 0.6129607288812317}},\n",
       " {'target': 1.2255910364161122,\n",
       "  'params': {'colsample_bytree': 0.5057905179653097,\n",
       "   'max_bin': 436.5838325858336,\n",
       "   'max_depth': 10.945788850199705,\n",
       "   'min_child_samples': 180.51173092545656,\n",
       "   'min_child_weight': 31.018248592552787,\n",
       "   'num_leaves': 52.36797794972381,\n",
       "   'reg_alpha': 7.435585845221661,\n",
       "   'reg_lambda': 7.923722138834772,\n",
       "   'subsample': 0.9514888390584397}},\n",
       " {'target': 1.2380606206964697,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 432.83456644964514,\n",
       "   'max_depth': 11.567769197870538,\n",
       "   'min_child_samples': 179.38382341846116,\n",
       "   'min_child_weight': 31.521558680765605,\n",
       "   'num_leaves': 62.32621087009169,\n",
       "   'reg_alpha': 5.285657276499761,\n",
       "   'reg_lambda': 10.0,\n",
       "   'subsample': 0.6345931468176225}},\n",
       " {'target': 1.130015544464695,\n",
       "  'params': {'colsample_bytree': 0.7445443659465836,\n",
       "   'max_bin': 427.6465264400541,\n",
       "   'max_depth': 14.063766815276484,\n",
       "   'min_child_samples': 173.44149617736284,\n",
       "   'min_child_weight': 42.56979092527457,\n",
       "   'num_leaves': 62.59942739345444,\n",
       "   'reg_alpha': 10.947696626844769,\n",
       "   'reg_lambda': 8.892654326001686,\n",
       "   'subsample': 0.6811311732705709}},\n",
       " {'target': 1.253852537738404,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 448.28686895909385,\n",
       "   'max_depth': 8.0,\n",
       "   'min_child_samples': 180.37511612464988,\n",
       "   'min_child_weight': 29.275041722835102,\n",
       "   'num_leaves': 63.8618992763844,\n",
       "   'reg_alpha': 4.6686329617118085,\n",
       "   'reg_lambda': 10.0,\n",
       "   'subsample': 0.5798088717032176}},\n",
       " {'target': 0.9478855880552536,\n",
       "  'params': {'colsample_bytree': 0.8031537441267949,\n",
       "   'max_bin': 289.92296623985186,\n",
       "   'max_depth': 14.480654564477074,\n",
       "   'min_child_samples': 135.1967905535792,\n",
       "   'min_child_weight': 29.536179613453207,\n",
       "   'num_leaves': 49.69191101606991,\n",
       "   'reg_alpha': 9.131879237349736,\n",
       "   'reg_lambda': 6.842268153732579,\n",
       "   'subsample': 0.9468287787285936}},\n",
       " {'target': 1.2506507828736044,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 439.97496743919834,\n",
       "   'max_depth': 9.871832186962282,\n",
       "   'min_child_samples': 188.87343605915987,\n",
       "   'min_child_weight': 14.488253892048165,\n",
       "   'num_leaves': 63.901670621053825,\n",
       "   'reg_alpha': 9.861064332670058,\n",
       "   'reg_lambda': 10.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 1.048583825402263,\n",
       "  'params': {'colsample_bytree': 0.8226559961213534,\n",
       "   'max_bin': 418.8178956430658,\n",
       "   'max_depth': 9.865169179254032,\n",
       "   'min_child_samples': 51.89988947054562,\n",
       "   'min_child_weight': 10.053642747626913,\n",
       "   'num_leaves': 55.874070044144354,\n",
       "   'reg_alpha': 15.548395899893334,\n",
       "   'reg_lambda': 8.402663194291186,\n",
       "   'subsample': 0.9561864958093883}},\n",
       " {'target': 1.1371425604827516,\n",
       "  'params': {'colsample_bytree': 0.8723651731475863,\n",
       "   'max_bin': 453.7100985892724,\n",
       "   'max_depth': 14.560664704479588,\n",
       "   'min_child_samples': 197.1863523116683,\n",
       "   'min_child_weight': 20.30988682410932,\n",
       "   'num_leaves': 51.93370863456427,\n",
       "   'reg_alpha': 12.212966785926973,\n",
       "   'reg_lambda': 2.734310477060308,\n",
       "   'subsample': 0.9713376058378826}},\n",
       " {'target': 0.8724439760943207,\n",
       "  'params': {'colsample_bytree': 0.9303434996072725,\n",
       "   'max_bin': 325.13104736053697,\n",
       "   'max_depth': 15.93151047882213,\n",
       "   'min_child_samples': 120.17905412333756,\n",
       "   'min_child_weight': 1.1001671428372037,\n",
       "   'num_leaves': 29.00095276907647,\n",
       "   'reg_alpha': 25.80923156197473,\n",
       "   'reg_lambda': 5.160869697422219,\n",
       "   'subsample': 0.5703560414423314}},\n",
       " {'target': 1.0668918846090056,\n",
       "  'params': {'colsample_bytree': 0.7405498719224073,\n",
       "   'max_bin': 120.09126734365545,\n",
       "   'max_depth': 12.941725031356032,\n",
       "   'min_child_samples': 53.75607426089902,\n",
       "   'min_child_weight': 42.67674438905004,\n",
       "   'num_leaves': 47.65645884299404,\n",
       "   'reg_alpha': 10.657030784872696,\n",
       "   'reg_lambda': 1.9862443324975898,\n",
       "   'subsample': 0.8183674135844643}},\n",
       " {'target': 1.0474101450761488,\n",
       "  'params': {'colsample_bytree': 0.5285839690801153,\n",
       "   'max_bin': 456.3688492632358,\n",
       "   'max_depth': 13.973563539578148,\n",
       "   'min_child_samples': 96.71934046157652,\n",
       "   'min_child_weight': 41.56458449914903,\n",
       "   'num_leaves': 61.51356737319794,\n",
       "   'reg_alpha': 29.916479237807728,\n",
       "   'reg_lambda': 3.569830892060643,\n",
       "   'subsample': 0.8466234848633365}},\n",
       " {'target': 1.2585941641683374,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 441.7021881506573,\n",
       "   'max_depth': 8.0,\n",
       "   'min_child_samples': 182.11952162698427,\n",
       "   'min_child_weight': 25.465635296592048,\n",
       "   'num_leaves': 64.0,\n",
       "   'reg_alpha': 25.35737831936375,\n",
       "   'reg_lambda': 10.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 0.7740354711307526,\n",
       "  'params': {'colsample_bytree': 0.9644030062523238,\n",
       "   'max_bin': 330.0928781095815,\n",
       "   'max_depth': 11.73763609663307,\n",
       "   'min_child_samples': 22.200684457930734,\n",
       "   'min_child_weight': 30.449321845606374,\n",
       "   'num_leaves': 42.41391927150943,\n",
       "   'reg_alpha': 41.1241425119106,\n",
       "   'reg_lambda': 7.101780863951866,\n",
       "   'subsample': 0.7549971229139905}},\n",
       " {'target': 1.3100990519116082,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 418.99080983050015,\n",
       "   'max_depth': 8.0,\n",
       "   'min_child_samples': 196.03625950508527,\n",
       "   'min_child_weight': 12.227144323417194,\n",
       "   'num_leaves': 64.0,\n",
       "   'reg_alpha': 32.88271219851881,\n",
       "   'reg_lambda': 10.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 0.9994966803260473,\n",
       "  'params': {'colsample_bytree': 0.6587283396471605,\n",
       "   'max_bin': 250.5286386374607,\n",
       "   'max_depth': 11.189562282462193,\n",
       "   'min_child_samples': 100.81813684545703,\n",
       "   'min_child_weight': 48.75445679344283,\n",
       "   'num_leaves': 36.577758318770336,\n",
       "   'reg_alpha': 41.14778812699356,\n",
       "   'reg_lambda': 9.618286668999609,\n",
       "   'subsample': 0.6229366817412965}},\n",
       " {'target': 1.0198372799007125,\n",
       "  'params': {'colsample_bytree': 0.9982660890256111,\n",
       "   'max_bin': 254.03913543906165,\n",
       "   'max_depth': 15.72064662080102,\n",
       "   'min_child_samples': 172.25633471197003,\n",
       "   'min_child_weight': 4.749826121182029,\n",
       "   'num_leaves': 35.99850836024811,\n",
       "   'reg_alpha': 34.224816343148206,\n",
       "   'reg_lambda': 8.12950340865832,\n",
       "   'subsample': 0.8197334217464274}},\n",
       " {'target': 0.913403802008834,\n",
       "  'params': {'colsample_bytree': 0.9707101482347569,\n",
       "   'max_bin': 151.73780030563316,\n",
       "   'max_depth': 13.90288866933377,\n",
       "   'min_child_samples': 46.182587729009526,\n",
       "   'min_child_weight': 37.888812663146865,\n",
       "   'num_leaves': 38.30708609406997,\n",
       "   'reg_alpha': 47.89761393961768,\n",
       "   'reg_lambda': 5.180723493699807,\n",
       "   'subsample': 0.5226788318286884}},\n",
       " {'target': 0.8980131561767597,\n",
       "  'params': {'colsample_bytree': 0.8323626633911705,\n",
       "   'max_bin': 52.630796011433475,\n",
       "   'max_depth': 14.834088173954108,\n",
       "   'min_child_samples': 100.82697953897299,\n",
       "   'min_child_weight': 22.84390430193939,\n",
       "   'num_leaves': 59.277532034313865,\n",
       "   'reg_alpha': 25.29624148656783,\n",
       "   'reg_lambda': 7.740368689783408,\n",
       "   'subsample': 0.9655823792101785}},\n",
       " {'target': 1.3133171134826225,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 435.3976088269417,\n",
       "   'max_depth': 8.0,\n",
       "   'min_child_samples': 196.83473321698418,\n",
       "   'min_child_weight': 1.1346157367857843,\n",
       "   'num_leaves': 64.0,\n",
       "   'reg_alpha': 47.14026537643615,\n",
       "   'reg_lambda': 10.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 1.3178398234203763,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 428.5179112711697,\n",
       "   'max_depth': 8.0,\n",
       "   'min_child_samples': 200.0,\n",
       "   'min_child_weight': 24.21830873622828,\n",
       "   'num_leaves': 64.0,\n",
       "   'reg_alpha': 50.0,\n",
       "   'reg_lambda': 0.001,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 1.2847877457379298,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 421.58939805436813,\n",
       "   'max_depth': 8.0,\n",
       "   'min_child_samples': 200.0,\n",
       "   'min_child_weight': 12.341487473834961,\n",
       "   'num_leaves': 38.853634607219746,\n",
       "   'reg_alpha': 50.0,\n",
       "   'reg_lambda': 10.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 1.3178398234203763,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 401.2729057868997,\n",
       "   'max_depth': 8.0,\n",
       "   'min_child_samples': 200.0,\n",
       "   'min_child_weight': 1.0,\n",
       "   'num_leaves': 64.0,\n",
       "   'reg_alpha': 50.0,\n",
       "   'reg_lambda': 0.001,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 1.3104133591290943,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 390.61362680989794,\n",
       "   'max_depth': 8.0,\n",
       "   'min_child_samples': 200.0,\n",
       "   'min_child_weight': 32.29364323417329,\n",
       "   'num_leaves': 64.0,\n",
       "   'reg_alpha': 50.0,\n",
       "   'reg_lambda': 10.0,\n",
       "   'subsample': 0.5}},\n",
       " {'target': 1.2776502636614695,\n",
       "  'params': {'colsample_bytree': 0.5,\n",
       "   'max_bin': 372.6559546783523,\n",
       "   'max_depth': 8.0,\n",
       "   'min_child_samples': 200.0,\n",
       "   'min_child_weight': 9.671461530624807,\n",
       "   'num_leaves': 36.75269843252276,\n",
       "   'reg_alpha': 50.0,\n",
       "   'reg_lambda': 10.0,\n",
       "   'subsample': 1.0}}]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbBO.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9161836673708834, 0.9611643394160162, 1.0095951856424543, 0.9166972406402161, 1.0282347581873081, 1.1795221649596168, 1.2255910364161122, 1.2380606206964697, 1.130015544464695, 1.253852537738404, 0.9478855880552536, 1.2506507828736044, 1.048583825402263, 1.1371425604827516, 0.8724439760943207, 1.0668918846090056, 1.0474101450761488, 1.2585941641683374, 0.7740354711307526, 1.3100990519116082, 0.9994966803260473, 1.0198372799007125, 0.913403802008834, 0.8980131561767597, 1.3133171134826225, 1.3178398234203763, 1.2847877457379298, 1.3178398234203763, 1.3104133591290943, 1.2776502636614695]\n",
      "maximum target index: 18\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('maximum target index:', np.argmin(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.7740354711307526, 'params': {'colsample_bytree': 0.9644030062523238, 'max_bin': 330.0928781095815, 'max_depth': 11.73763609663307, 'min_child_samples': 22.200684457930734, 'min_child_weight': 30.449321845606374, 'num_leaves': 42.41391927150943, 'reg_alpha': 41.1241425119106, 'reg_lambda': 7.101780863951866, 'subsample': 0.7549971229139905}}\n"
     ]
    }
   ],
   "source": [
    "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
    "max_dict = lgbBO.res[np.argmin(np.array(target_list))]\n",
    "print(max_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = train_data\n",
    "target =  train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_apps_all_with_oof(ftr, target, nfolds=5):\n",
    "    ftr = ftr\n",
    "    target = target\n",
    "\n",
    "    # nfolds 개의 cross validatin fold set을 가지는 KFold 생성 \n",
    "    folds = KFold(n_splits=nfolds, shuffle=True, random_state=0)\n",
    "    \n",
    "    # Out of Folds로 학습된 모델의 validation set을 예측하여 결과 확률을 담을 array 생성.\n",
    "    # validation set가 n_split갯수만큼 있으므로 크기는 ftr_app의 크기가 되어야 함. \n",
    "    oof_preds = np.zeros((ftr.shape[0],))  \n",
    "    \n",
    "    # Ouf of Folds로 학습된 모델의 test dataset을 예측하여 결과 확률을 담을 array 생성. \n",
    "    test_preds = np.zeros(((test_data.shape[0],)))\n",
    "    \n",
    "    # n_estimators를 4000까지 확대. \n",
    "    clf = LGBMRegressor(\n",
    "                nthread=4,\n",
    "                n_estimators=4000,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=12,\n",
    "                num_leaves=42,\n",
    "                colsample_bytree=0.9644030062523238,\n",
    "                subsample=0.7549971229139905,\n",
    "                max_bin=330,\n",
    "                reg_alpha=41.1241425119106,\n",
    "                reg_lambda=7.101780863951866,\n",
    "                min_child_weight=30.449321845606374,\n",
    "                min_child_samples=22,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                )\n",
    "\n",
    "\n",
    "    # nfolds 번 cross validation Iteration 반복하면서 OOF 방식으로 학습 및 테스트 데이터 예측\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(folds.split(ftr)):\n",
    "        print('##### iteration ', fold_idx, ' 시작')\n",
    "        # 학습용 데이터 세트의 인덱스와 검증용 데이터 세트의 인덱스 추출하여 이를 기반으로 학습/검증 데이터 추출\n",
    "        train_x = ftr.iloc[train_idx, :]\n",
    "        train_y = target.iloc[train_idx]\n",
    "        valid_x = ftr.iloc[valid_idx, :]\n",
    "        valid_y = target.iloc[valid_idx]\n",
    "        \n",
    "        # 추출된 학습/검증 데이터 세트로 모델 학습. early_stopping은 200으로 증가. \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'RMSE', verbose= 200, \n",
    "                early_stopping_rounds= 200)\n",
    "        # 검증 데이터 세트로 예측된 확률 저장. 사용되지는 않음. \n",
    "        #oof_preds[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration_)       \n",
    "        # 학습된 모델로 테스트 데이터 세트에 예측 확률 계산. \n",
    "        # nfolds 번 반복 실행하므로 평균 확률을 구하기 위해 개별 수행시 마다 수행 횟수로 나눈 확률을 추후에 더해서 최종 평균 확률 계산. \n",
    "        test_preds += clf.predict(test_data, num_iteration=clf.best_iteration_)/folds.n_splits\n",
    "        \n",
    "        \n",
    "    return clf, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### iteration  0  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 7.75622\ttraining's l2: 60.1589\tvalid_1's rmse: 7.59719\tvalid_1's l2: 57.7173\n",
      "[400]\ttraining's rmse: 1.56599\ttraining's l2: 2.45232\tvalid_1's rmse: 1.23687\tvalid_1's l2: 1.52985\n",
      "[600]\ttraining's rmse: 1.044\ttraining's l2: 1.08993\tvalid_1's rmse: 0.772974\tvalid_1's l2: 0.597489\n",
      "Early stopping, best iteration is:\n",
      "[582]\ttraining's rmse: 1.05437\ttraining's l2: 1.11169\tvalid_1's rmse: 0.77014\tvalid_1's l2: 0.593116\n",
      "##### iteration  1  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 7.74703\ttraining's l2: 60.0164\tvalid_1's rmse: 7.71766\tvalid_1's l2: 59.5623\n",
      "[400]\ttraining's rmse: 1.51972\ttraining's l2: 2.30954\tvalid_1's rmse: 1.56001\tvalid_1's l2: 2.43364\n",
      "[600]\ttraining's rmse: 0.973824\ttraining's l2: 0.948333\tvalid_1's rmse: 1.11938\tvalid_1's l2: 1.253\n",
      "[800]\ttraining's rmse: 0.936801\ttraining's l2: 0.877596\tvalid_1's rmse: 1.10072\tvalid_1's l2: 1.21157\n",
      "[1000]\ttraining's rmse: 0.926813\ttraining's l2: 0.858982\tvalid_1's rmse: 1.09658\tvalid_1's l2: 1.20248\n",
      "[1200]\ttraining's rmse: 0.922499\ttraining's l2: 0.851005\tvalid_1's rmse: 1.09417\tvalid_1's l2: 1.19722\n",
      "[1400]\ttraining's rmse: 0.919273\ttraining's l2: 0.845063\tvalid_1's rmse: 1.09229\tvalid_1's l2: 1.19309\n",
      "[1600]\ttraining's rmse: 0.914901\ttraining's l2: 0.837044\tvalid_1's rmse: 1.09248\tvalid_1's l2: 1.19352\n",
      "Early stopping, best iteration is:\n",
      "[1453]\ttraining's rmse: 0.918508\ttraining's l2: 0.843657\tvalid_1's rmse: 1.09188\tvalid_1's l2: 1.1922\n",
      "##### iteration  2  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 7.72114\ttraining's l2: 59.616\tvalid_1's rmse: 7.85531\tvalid_1's l2: 61.7059\n",
      "[400]\ttraining's rmse: 1.55974\ttraining's l2: 2.43278\tvalid_1's rmse: 1.54575\tvalid_1's l2: 2.38934\n",
      "[600]\ttraining's rmse: 1.05741\ttraining's l2: 1.11811\tvalid_1's rmse: 1.05189\tvalid_1's l2: 1.10647\n",
      "[800]\ttraining's rmse: 1.01832\ttraining's l2: 1.03698\tvalid_1's rmse: 1.03431\tvalid_1's l2: 1.06979\n",
      "[1000]\ttraining's rmse: 0.995042\ttraining's l2: 0.990108\tvalid_1's rmse: 1.03799\tvalid_1's l2: 1.07742\n",
      "Early stopping, best iteration is:\n",
      "[851]\ttraining's rmse: 1.01554\ttraining's l2: 1.03131\tvalid_1's rmse: 1.0337\tvalid_1's l2: 1.06853\n",
      "##### iteration  3  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 7.73485\ttraining's l2: 59.8279\tvalid_1's rmse: 7.92854\tvalid_1's l2: 62.8617\n",
      "[400]\ttraining's rmse: 1.45332\ttraining's l2: 2.11213\tvalid_1's rmse: 2.04048\tvalid_1's l2: 4.16356\n",
      "[600]\ttraining's rmse: 0.902242\ttraining's l2: 0.814041\tvalid_1's rmse: 1.56628\tvalid_1's l2: 2.45322\n",
      "[800]\ttraining's rmse: 0.864335\ttraining's l2: 0.747074\tvalid_1's rmse: 1.52307\tvalid_1's l2: 2.31973\n",
      "[1000]\ttraining's rmse: 0.856376\ttraining's l2: 0.733381\tvalid_1's rmse: 1.51181\tvalid_1's l2: 2.28558\n",
      "[1200]\ttraining's rmse: 0.851058\ttraining's l2: 0.7243\tvalid_1's rmse: 1.51021\tvalid_1's l2: 2.28073\n",
      "Early stopping, best iteration is:\n",
      "[1129]\ttraining's rmse: 0.852856\ttraining's l2: 0.727363\tvalid_1's rmse: 1.51002\tvalid_1's l2: 2.28015\n",
      "##### iteration  4  시작\n",
      "[LightGBM] [Warning] num_threads is set with n_jobs=-1, nthread=4 will be ignored. Current value: num_threads=-1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 7.75526\ttraining's l2: 60.144\tvalid_1's rmse: 7.6466\tvalid_1's l2: 58.4705\n",
      "[400]\ttraining's rmse: 1.54133\ttraining's l2: 2.3757\tvalid_1's rmse: 1.37307\tvalid_1's l2: 1.88533\n",
      "[600]\ttraining's rmse: 1.01924\ttraining's l2: 1.03885\tvalid_1's rmse: 0.853499\tvalid_1's l2: 0.72846\n",
      "[800]\ttraining's rmse: 0.955949\ttraining's l2: 0.913838\tvalid_1's rmse: 0.832341\tvalid_1's l2: 0.692791\n",
      "[1000]\ttraining's rmse: 0.910648\ttraining's l2: 0.82928\tvalid_1's rmse: 0.834515\tvalid_1's l2: 0.696416\n",
      "Early stopping, best iteration is:\n",
      "[802]\ttraining's rmse: 0.955838\ttraining's l2: 0.913627\tvalid_1's rmse: 0.832313\tvalid_1's l2: 0.692745\n"
     ]
    }
   ],
   "source": [
    "clf, test_preds = train_apps_all_with_oof(ftr, target, nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255.06485511, 559.14334568, 232.04668006, ..., 856.53037582,\n",
       "        18.95766583,   7.47416056])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255.13542954, 559.55498699, 232.13264084, ..., 853.98756537,\n",
       "        18.98660213,   7.44441985])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"hold_d\"] = np.round(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"dacon_baseline_1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
